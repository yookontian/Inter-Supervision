{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_trainable_parameters(model):\n",
    "    \"\"\"\n",
    "    Prints the number of trainable parameters in the model.\n",
    "    \"\"\"\n",
    "    trainable_params = 0\n",
    "    all_param = 0\n",
    "    for _, param in model.named_parameters():\n",
    "        all_param += param.numel()\n",
    "        if param.requires_grad:\n",
    "            trainable_params += param.numel()\n",
    "    print(\n",
    "        f\"trainable params: {trainable_params} || all params: {all_param} || trainable%: {100 * trainable_params / all_param}\"\n",
    "    )"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# model, tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "additional_tokens = {'additional_special_tokens': ['[learn1]', '[learn2]', '[learn3]', '[learn4]', '[learn5]', '[learn6]']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    }
   ],
   "source": [
    "from transformers import GPT2LMHeadModel,  GPT2Tokenizer, GPT2Config, GPT2LMHeadModel\n",
    "tokenizer = GPT2Tokenizer.from_pretrained('gpt2', bos_token='<|startoftext|>', eos_token='<|endoftext|>', pad_token='<|pad|>')\n",
    "\n",
    "configuration = GPT2Config.from_pretrained('gpt2', output_hidden_states=False)\n",
    "\n",
    "model = GPT2LMHeadModel.from_pretrained(\"gpt2\", config=configuration)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 124439808 || all params: 124439808 || trainable%: 100.0\n"
     ]
    }
   ],
   "source": [
    "print_trainable_parameters(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_added_toks = tokenizer.add_special_tokens(additional_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Embedding(50265, 768)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.resize_token_embeddings(len(tokenizer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('DocRED/GPT_w_ner_short_relation/gpt2_tokenizer/tokenizer_config.json',\n",
       " 'DocRED/GPT_w_ner_short_relation/gpt2_tokenizer/special_tokens_map.json',\n",
       " 'DocRED/GPT_w_ner_short_relation/gpt2_tokenizer/vocab.json',\n",
       " 'DocRED/GPT_w_ner_short_relation/gpt2_tokenizer/merges.txt',\n",
       " 'DocRED/GPT_w_ner_short_relation/gpt2_tokenizer/added_tokens.json')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# save the tokenizer\n",
    "\n",
    "tokenizer.save_pretrained('DocRED/GPT_w_ner_short_relation/gpt2_tokenizer')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the json file from DocRED/data/test.json and DocRED/data/rel_info.json\n",
    "\n",
    "import json\n",
    "\n",
    "with open('DocRED/data/train_annotated.json') as f:\n",
    "    train_set = json.load(f)\n",
    "\n",
    "\n",
    "with open('DocRED/data/rel_info.json') as f:\n",
    "    rel_info = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'vertexSet': [[{'pos': [0, 4],\n",
       "    'type': 'ORG',\n",
       "    'sent_id': 0,\n",
       "    'name': 'Zest Airways, Inc.'},\n",
       "   {'sent_id': 0,\n",
       "    'type': 'ORG',\n",
       "    'pos': [10, 15],\n",
       "    'name': 'Asian Spirit and Zest Air'},\n",
       "   {'name': 'AirAsia Zest', 'pos': [6, 8], 'sent_id': 0, 'type': 'ORG'},\n",
       "   {'name': 'AirAsia Zest', 'pos': [19, 21], 'sent_id': 6, 'type': 'ORG'}],\n",
       "  [{'name': 'Ninoy Aquino International Airport',\n",
       "    'pos': [4, 8],\n",
       "    'sent_id': 3,\n",
       "    'type': 'LOC'},\n",
       "   {'name': 'Ninoy Aquino International Airport',\n",
       "    'pos': [26, 30],\n",
       "    'sent_id': 0,\n",
       "    'type': 'LOC'}],\n",
       "  [{'name': 'Pasay City', 'pos': [31, 33], 'sent_id': 0, 'type': 'LOC'}],\n",
       "  [{'name': 'Metro Manila', 'pos': [34, 36], 'sent_id': 0, 'type': 'LOC'}],\n",
       "  [{'name': 'Philippines', 'pos': [38, 39], 'sent_id': 0, 'type': 'LOC'},\n",
       "   {'name': 'Philippines', 'pos': [13, 14], 'sent_id': 4, 'type': 'LOC'},\n",
       "   {'sent_id': 5,\n",
       "    'type': 'LOC',\n",
       "    'pos': [25, 29],\n",
       "    'name': 'Republic of the Philippines'}],\n",
       "  [{'name': 'Manila', 'pos': [13, 14], 'sent_id': 1, 'type': 'LOC'},\n",
       "   {'name': 'Manila', 'pos': [9, 10], 'sent_id': 3, 'type': 'LOC'}],\n",
       "  [{'name': 'Cebu', 'pos': [15, 16], 'sent_id': 1, 'type': 'LOC'}],\n",
       "  [{'pos': [17, 18], 'type': 'NUM', 'sent_id': 1, 'name': '24'}],\n",
       "  [{'pos': [1, 2], 'type': 'TIME', 'sent_id': 2, 'name': '2013'},\n",
       "   {'pos': [1, 5], 'type': 'TIME', 'sent_id': 5, 'name': 'August 16, 2013'}],\n",
       "  [{'pos': [9, 11],\n",
       "    'type': 'ORG',\n",
       "    'name': 'Philippines AirAsia',\n",
       "    'sent_id': 2}],\n",
       "  [{'pos': [5, 7], 'type': 'ORG', 'sent_id': 4, 'name': 'Asian Spirit'}],\n",
       "  [{'pos': [7, 13],\n",
       "    'type': 'ORG',\n",
       "    'sent_id': 5,\n",
       "    'name': 'Civil Aviation Authority of the Philippines'},\n",
       "   {'name': 'CAAP', 'pos': [14, 15], 'sent_id': 5, 'type': 'ORG'}],\n",
       "  [{'name': 'Zest Air', 'pos': [34, 36], 'sent_id': 5, 'type': 'ORG'},\n",
       "   {'pos': [7, 9], 'type': 'ORG', 'sent_id': 6, 'name': 'Zest Air'}],\n",
       "  [{'sent_id': 6, 'type': 'NUM', 'pos': [2, 4], 'name': 'a year'}],\n",
       "  [{'name': 'AirAsia', 'pos': [5, 6], 'sent_id': 6, 'type': 'ORG'}],\n",
       "  [{'pos': [5, 7],\n",
       "    'type': 'ORG',\n",
       "    'name': 'AirAsia Philippines',\n",
       "    'sent_id': 7}],\n",
       "  [{'pos': [8, 10], 'type': 'TIME', 'sent_id': 7, 'name': 'January 2016'}]],\n",
       " 'labels': [{'r': 'P159', 'h': 0, 't': 2, 'evidence': [0]},\n",
       "  {'r': 'P17', 'h': 0, 't': 4, 'evidence': [2, 4, 7]},\n",
       "  {'r': 'P17', 'h': 12, 't': 4, 'evidence': [6, 7]},\n",
       "  {'r': 'P17', 'h': 2, 't': 4, 'evidence': [0]},\n",
       "  {'r': 'P131', 'h': 2, 't': 3, 'evidence': [0]},\n",
       "  {'r': 'P150', 'h': 4, 't': 3, 'evidence': [0]},\n",
       "  {'r': 'P17', 'h': 5, 't': 4, 'evidence': [0, 3]},\n",
       "  {'r': 'P150', 'h': 3, 't': 2, 'evidence': [0]},\n",
       "  {'r': 'P131', 'h': 3, 't': 4, 'evidence': [0, 3]},\n",
       "  {'r': 'P17', 'h': 3, 't': 4, 'evidence': [0, 3]},\n",
       "  {'r': 'P131', 'h': 1, 't': 2, 'evidence': [0, 3]},\n",
       "  {'r': 'P17', 'h': 1, 't': 4, 'evidence': [0, 3]},\n",
       "  {'r': 'P17', 'h': 10, 't': 4, 'evidence': [4]}],\n",
       " 'title': 'AirAsia Zest',\n",
       " 'sents': [['Zest',\n",
       "   'Airways',\n",
       "   ',',\n",
       "   'Inc.',\n",
       "   'operated',\n",
       "   'as',\n",
       "   'AirAsia',\n",
       "   'Zest',\n",
       "   '(',\n",
       "   'formerly',\n",
       "   'Asian',\n",
       "   'Spirit',\n",
       "   'and',\n",
       "   'Zest',\n",
       "   'Air',\n",
       "   ')',\n",
       "   ',',\n",
       "   'was',\n",
       "   'a',\n",
       "   'low',\n",
       "   '-',\n",
       "   'cost',\n",
       "   'airline',\n",
       "   'based',\n",
       "   'at',\n",
       "   'the',\n",
       "   'Ninoy',\n",
       "   'Aquino',\n",
       "   'International',\n",
       "   'Airport',\n",
       "   'in',\n",
       "   'Pasay',\n",
       "   'City',\n",
       "   ',',\n",
       "   'Metro',\n",
       "   'Manila',\n",
       "   'in',\n",
       "   'the',\n",
       "   'Philippines',\n",
       "   '.'],\n",
       "  ['It',\n",
       "   'operated',\n",
       "   'scheduled',\n",
       "   'domestic',\n",
       "   'and',\n",
       "   'international',\n",
       "   'tourist',\n",
       "   'services',\n",
       "   ',',\n",
       "   'mainly',\n",
       "   'feeder',\n",
       "   'services',\n",
       "   'linking',\n",
       "   'Manila',\n",
       "   'and',\n",
       "   'Cebu',\n",
       "   'with',\n",
       "   '24',\n",
       "   'domestic',\n",
       "   'destinations',\n",
       "   'in',\n",
       "   'support',\n",
       "   'of',\n",
       "   'the',\n",
       "   'trunk',\n",
       "   'route',\n",
       "   'operations',\n",
       "   'of',\n",
       "   'other',\n",
       "   'airlines',\n",
       "   '.'],\n",
       "  ['In',\n",
       "   '2013',\n",
       "   ',',\n",
       "   'the',\n",
       "   'airline',\n",
       "   'became',\n",
       "   'an',\n",
       "   'affiliate',\n",
       "   'of',\n",
       "   'Philippines',\n",
       "   'AirAsia',\n",
       "   'operating',\n",
       "   'their',\n",
       "   'brand',\n",
       "   'separately',\n",
       "   '.'],\n",
       "  ['Its',\n",
       "   'main',\n",
       "   'base',\n",
       "   'was',\n",
       "   'Ninoy',\n",
       "   'Aquino',\n",
       "   'International',\n",
       "   'Airport',\n",
       "   ',',\n",
       "   'Manila',\n",
       "   '.'],\n",
       "  ['The',\n",
       "   'airline',\n",
       "   'was',\n",
       "   'founded',\n",
       "   'as',\n",
       "   'Asian',\n",
       "   'Spirit',\n",
       "   ',',\n",
       "   'the',\n",
       "   'first',\n",
       "   'airline',\n",
       "   'in',\n",
       "   'the',\n",
       "   'Philippines',\n",
       "   'to',\n",
       "   'be',\n",
       "   'run',\n",
       "   'as',\n",
       "   'a',\n",
       "   'cooperative',\n",
       "   '.'],\n",
       "  ['On',\n",
       "   'August',\n",
       "   '16',\n",
       "   ',',\n",
       "   '2013',\n",
       "   ',',\n",
       "   'the',\n",
       "   'Civil',\n",
       "   'Aviation',\n",
       "   'Authority',\n",
       "   'of',\n",
       "   'the',\n",
       "   'Philippines',\n",
       "   '(',\n",
       "   'CAAP',\n",
       "   ')',\n",
       "   ',',\n",
       "   'the',\n",
       "   'regulating',\n",
       "   'body',\n",
       "   'of',\n",
       "   'the',\n",
       "   'Government',\n",
       "   'of',\n",
       "   'the',\n",
       "   'Republic',\n",
       "   'of',\n",
       "   'the',\n",
       "   'Philippines',\n",
       "   'for',\n",
       "   'civil',\n",
       "   'aviation',\n",
       "   ',',\n",
       "   'suspended',\n",
       "   'Zest',\n",
       "   'Air',\n",
       "   'flights',\n",
       "   'until',\n",
       "   'further',\n",
       "   'notice',\n",
       "   'because',\n",
       "   'of',\n",
       "   'safety',\n",
       "   'issues',\n",
       "   '.'],\n",
       "  ['Less',\n",
       "   'than',\n",
       "   'a',\n",
       "   'year',\n",
       "   'after',\n",
       "   'AirAsia',\n",
       "   'and',\n",
       "   'Zest',\n",
       "   'Air',\n",
       "   \"'s\",\n",
       "   'strategic',\n",
       "   'alliance',\n",
       "   ',',\n",
       "   'the',\n",
       "   'airline',\n",
       "   'has',\n",
       "   'been',\n",
       "   'rebranded',\n",
       "   'as',\n",
       "   'AirAsia',\n",
       "   'Zest',\n",
       "   '.'],\n",
       "  ['The',\n",
       "   'airline',\n",
       "   'was',\n",
       "   'merged',\n",
       "   'into',\n",
       "   'AirAsia',\n",
       "   'Philippines',\n",
       "   'in',\n",
       "   'January',\n",
       "   '2016',\n",
       "   '.']]}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_set[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nthe names of vertextSet can be the same, but the pos should be different\\nstructure:\\n'vertexSet': \\n    [\\n        {\\n            'pos':[start, end],\\n            'type': 'NER',\\n            'sent_id': 0,\\n            'name': 'string',\\n        },\\n        {}\\n    ]\\n'labels':\\n    [\\n        {\\n            'r': 'Pxx',\\n            'h': 0,\\n            't': 1,\\n            'evidence': [2, 3, 4],\\n        },\\n        {}\\n    ]\\n'title': 'string',\\n'sents':\\n    [\\n        ['word0', 'word1',]\\n        ['word0', 'word1',]\\n    ]\\n\""
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "the names of vertextSet can be the same, but the pos should be different\n",
    "structure:\n",
    "'vertexSet': \n",
    "    [\n",
    "        (for the same entity but in different synonyms and different sentences)\n",
    "        [\n",
    "            {\n",
    "                'pos':[start, end],\n",
    "                'type': 'NER',\n",
    "                'sent_id': 0,\n",
    "                'name': 'string',\n",
    "            },\n",
    "            {}\n",
    "        ],\n",
    "        [entity-2]\n",
    "    ]\n",
    "'labels':\n",
    "    [\n",
    "        {\n",
    "            'r': 'Pxx',\n",
    "            'h': 0,\n",
    "            't': 1,\n",
    "            'evidence': [2, 3, 4],\n",
    "        },\n",
    "        {}\n",
    "    ]\n",
    "'title': 'string',\n",
    "'sents':\n",
    "    [\n",
    "        ['word0', 'word1',]\n",
    "        ['word0', 'word1',]\n",
    "    ]\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('DocRED/data/ner_info.json') as f:\n",
    "    ner_info = json.load(f)\n",
    "\n",
    "with open('DocRED/data/rel_info.json') as f:\n",
    "    relation_info = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"# doc-level is too long for gpt-2, so we need to split the doc-level into bi-sent-level\n",
    "\n",
    "relation_dict = {\n",
    "    'id': [],\n",
    "    'text':[],\n",
    "    'entity': [],\n",
    "    'relation': []\n",
    "}\n",
    "\n",
    "for i in range(len(train_set)):\n",
    "    # id\n",
    "    relation_dict['id'].append(i)\n",
    "\n",
    "    # text\n",
    "    sents = \"\"\n",
    "    for sent in train_set[i]['sents']:\n",
    "        # flatten the sent list\n",
    "        a = \" \".join(sent)\n",
    "        sents += a.lower() + \" \"\n",
    "    # if there are space, delete the first and last space of the sents\n",
    "    sents = sents.strip()\n",
    "    # delete double space in the sents\n",
    "    sents = sents.replace(\"  \", \" \")\n",
    "    relation_dict['text'].append(sents)\n",
    "    del sents\n",
    "\n",
    "    # entity\n",
    "    entity = []\n",
    "    entity_list = []\n",
    "    entity_flat = {}\n",
    "    entity_count = 0\n",
    "    for sent_item in train_set[i]['vertexSet']:\n",
    "        for item in sent_item:\n",
    "            entity_item = []\n",
    "            if item['name'].lower() not in entity_list:\n",
    "                entity_list.append(item['name'].lower().strip())\n",
    "                entity_item.append(item['name'].lower().strip())\n",
    "                entity_item.append(ner_info[item['type']])\n",
    "\n",
    "                entity.append(entity_item)\n",
    "            \n",
    "            # add the entity_flat\n",
    "            entity_flat[entity_count] = item['name'].lower().strip()\n",
    "            entity_count += 1\n",
    "\n",
    "    # release the entity_list and entity_item\n",
    "    del entity_item\n",
    "    del entity_count\n",
    "        \n",
    "\n",
    "    # relation pairs\n",
    "    relation_pairs = {}\n",
    "    for relation_item in train_set[i]['labels']:\n",
    "        pair = []\n",
    "        head = entity_flat[relation_item['h']]\n",
    "        tail = entity_flat[relation_item['t']]\n",
    "        pair.append(head)\n",
    "        pair.append(tail)\n",
    "\n",
    "        relation  = relation_info[relation_item['r']]\n",
    "        if relation not in relation_pairs.keys():\n",
    "            relation_pairs[relation] = []\n",
    "\n",
    "        relation_pairs[relation].append(pair)\n",
    "    del pair\n",
    "    del head\n",
    "    del tail\n",
    "\n",
    "    # add the entity and relation pairs to the relation_dict\n",
    "    relation_dict['entity'].append(entity)\n",
    "    relation_dict['relation'].append(relation_pairs)\n",
    "    break\n",
    "\n",
    "\n",
    "# save the relation_dict to a json file\n",
    "\n",
    "# with open('DocRED/data/DocRED_baseline_metadata/relation_dict.json', 'w') as f:\n",
    "#     json.dump(relation_dict, f)\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "relation_dict = {\n",
    "    'text':[],\n",
    "    'entity': [],\n",
    "    'relation': []\n",
    "}\n",
    "id_count = 0\n",
    "\n",
    "for i in range(len(train_set)):\n",
    "    \n",
    "\n",
    "    # text\n",
    "    sent_pairs = []\n",
    "    for sent_index, sent in enumerate(train_set[i]['sents']):\n",
    "        sents = \"\"\n",
    "\n",
    "        # flatten the sent list\n",
    "        a = \" \".join(sent)\n",
    "        sents += a.lower() + \" \"\n",
    "\n",
    "        # and the next_sent if it exists\n",
    "        try:\n",
    "            next_sent = train_set[i]['sents'][sent_index + 1]\n",
    "            b = \" \".join(next_sent)\n",
    "            sents += b.lower() + \" \"\n",
    "        except:\n",
    "            pass\n",
    "        # post process the sents for some spaces\n",
    "        sents = sents.strip()\n",
    "        sents = sents.replace(\"  \", \" \")\n",
    "\n",
    "        relation_dict['text'].append(sents)\n",
    "            \n",
    "    del sents\n",
    "\n",
    "\n",
    "    # entity\n",
    "    entity = []\n",
    "    for index in range(len(train_set[i]['sents'])):\n",
    "        # focus on the current sent and the next sent if it exists\n",
    "        if index + 1 < len(train_set[i]['sents']):\n",
    "            next_index = index + 1\n",
    "        else:\n",
    "            next_index = index\n",
    "        # group the entities for every 2 sents, no repeated entities in one group\n",
    "        c_sent_entity_lists = []\n",
    "        next_sent_entity_lists = []\n",
    "        entity_for_each_2_sents = []\n",
    "\n",
    "        for entity_spans in train_set[i]['vertexSet']:\n",
    "            for item in entity_spans:\n",
    "                entity_item = []\n",
    "                # if neither in the current sent nor in the next sent, continue\n",
    "                if item['sent_id'] != index and item['sent_id'] != next_index:\n",
    "                    continue\n",
    "                # also store the first pos of the entity in the entity_item\n",
    "                # it will look like this: [[entity_name, sent_index, pos1, ner_type]]\n",
    "                entity_item = [item['name'].lower().strip(), item['sent_id'], item['pos'][0], ner_info[item['type']]]\n",
    "\n",
    "                if entity_item[1] == index:\n",
    "                    c_sent_entity_lists.append(entity_item)\n",
    "                else:\n",
    "                    next_sent_entity_lists.append(entity_item)\n",
    "\n",
    "        # sort the c_sent_entity_lists and next_sent_entity_lists by the pos in ascending order\n",
    "        c_sent_entity_lists.sort(key=lambda x: x[2])\n",
    "        if index != next_index:\n",
    "            next_sent_entity_lists.sort(key=lambda x: x[2])\n",
    "        \n",
    "        entity_list = []\n",
    "        for item in c_sent_entity_lists:\n",
    "            if item[0] not in entity_list:\n",
    "                entity_list.append(item[0])\n",
    "                entity_for_each_2_sents.append([item[0], item[3]])\n",
    "            \n",
    "        if index != next_index:\n",
    "            for item in next_sent_entity_lists:\n",
    "                if item[0] not in entity_list:\n",
    "                    entity_list.append(item[0])\n",
    "                    entity_for_each_2_sents.append([item[0], item[3]])\n",
    "\n",
    "        relation_dict['entity'].append(entity_for_each_2_sents)\n",
    "\n",
    "    del entity_item\n",
    "    del c_sent_entity_lists\n",
    "    del next_sent_entity_lists\n",
    "    del entity_for_each_2_sents\n",
    "        \n",
    "\n",
    "    # relation pairs\n",
    "    relation_pairs = []\n",
    "\n",
    "    for index in range(len(train_set[i]['sents'])):\n",
    "        relation_pairs_for_each_2_sents = {}\n",
    "        # focus on the current sent and the next sent if it exists\n",
    "        if index + 1 < len(train_set[i]['vertexSet']):\n",
    "            next_index = index + 1\n",
    "        else:\n",
    "            next_index = index\n",
    "\n",
    "        # heads, tails: ['entity_name', start_pos]\n",
    "        for relation_item in train_set[i]['labels']:\n",
    "            heads = []\n",
    "            tails = []\n",
    "            \n",
    "            # head\n",
    "            head_exist = False\n",
    "            for head_span in train_set[i]['vertexSet'][relation_item['h']]:\n",
    "                if head_span['sent_id'] == index or head_span['sent_id'] == next_index:\n",
    "                    heads.append([head_span['name'].lower().strip(), head_span['pos'][0]])\n",
    "                    head_exist = True\n",
    "            if not head_exist:\n",
    "                continue\n",
    "    \n",
    "            # tail\n",
    "            tail_exist = False\n",
    "            for tail_span in train_set[i]['vertexSet'][relation_item['t']]:\n",
    "                if tail_span['sent_id'] == index or tail_span['sent_id'] == next_index:\n",
    "                    tails.append([tail_span['name'].lower().strip(), tail_span['pos'][0]])\n",
    "                    tail_exist = True\n",
    "            if not tail_exist:\n",
    "                continue\n",
    "            \n",
    "\n",
    "            if relation_info[relation_item['r']] not in relation_pairs_for_each_2_sents.keys():\n",
    "                relation_pairs_for_each_2_sents[relation_info[relation_item['r']]] = []\n",
    "            for head in heads:\n",
    "                for tail in tails:\n",
    "                    relation_pairs_for_each_2_sents[relation_info[relation_item['r']]].append([head[0], tail[0]])\n",
    "\n",
    "        relation_dict['relation'].append(relation_pairs_for_each_2_sents)\n",
    "\n",
    "\n",
    "    \n",
    "    # break\n",
    "\n",
    "\n",
    "# save the relation_dict to a json file\n",
    "\n",
    "# with open('DocRED/data/bi-sent-pre-process.json', 'w') as f:\n",
    "    # json.dump(relation_dict, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(relation_dict['text']) == len(relation_dict['entity']) == len(relation_dict['relation'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'headquarters location': [['zest airways, inc.', 'pasay city'],\n",
       "  ['asian spirit and zest air', 'pasay city'],\n",
       "  ['airasia zest', 'pasay city']],\n",
       " 'country': [['zest airways, inc.', 'philippines'],\n",
       "  ['asian spirit and zest air', 'philippines'],\n",
       "  ['airasia zest', 'philippines'],\n",
       "  ['pasay city', 'philippines'],\n",
       "  ['manila', 'philippines'],\n",
       "  ['metro manila', 'philippines'],\n",
       "  ['ninoy aquino international airport', 'philippines']],\n",
       " 'located in the administrative territorial entity': [['pasay city',\n",
       "   'metro manila'],\n",
       "  ['metro manila', 'philippines'],\n",
       "  ['ninoy aquino international airport', 'pasay city']],\n",
       " 'contains administrative territorial entity': [['philippines',\n",
       "   'metro manila'],\n",
       "  ['metro manila', 'pasay city']]}"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "relation_dict['relation'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "ner = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "\n",
    "from datasets import Dataset\n",
    "\n",
    "relation_dict = {}\n",
    "if ner:\n",
    "    with open('DocRED/data/bi-sent-pre-process.json') as f:\n",
    "        relation_dict = json.load(f)\n",
    "\n",
    "    dataset = Dataset.from_dict(\n",
    "        {\n",
    "            'text': relation_dict['text'],\n",
    "            'entity': relation_dict['entity'],\n",
    "            'relation': relation_dict['relation']\n",
    "        }\n",
    "    )\n",
    "\n",
    "else:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['text', 'entity', 'relation'],\n",
       "    num_rows: 24256\n",
       "})"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'text': 'zest airways , inc. operated as airasia zest ( formerly asian spirit and zest air ) , was a low - cost airline based at the ninoy aquino international airport in pasay city , metro manila in the philippines . it operated scheduled domestic and international tourist services , mainly feeder services linking manila and cebu with 24 domestic destinations in support of the trunk route operations of other airlines .',\n",
       " 'entity': [['zest airways, inc.', 'organization'],\n",
       "  ['airasia zest', 'organization'],\n",
       "  ['asian spirit and zest air', 'organization'],\n",
       "  ['ninoy aquino international airport', 'location'],\n",
       "  ['pasay city', 'location'],\n",
       "  ['metro manila', 'location'],\n",
       "  ['philippines', 'location'],\n",
       "  ['manila', 'location'],\n",
       "  ['cebu', 'location'],\n",
       "  ['24', 'number']],\n",
       " 'relation': {'applies to jurisdiction': None,\n",
       "  'author': None,\n",
       "  'award received': None,\n",
       "  'basin country': None,\n",
       "  'capital': None,\n",
       "  'capital of': None,\n",
       "  'cast member': None,\n",
       "  'chairperson': None,\n",
       "  'characters': None,\n",
       "  'child': None,\n",
       "  'composer': None,\n",
       "  'conflict': None,\n",
       "  'contains administrative territorial entity': [['philippines',\n",
       "    'metro manila'],\n",
       "   ['metro manila', 'pasay city']],\n",
       "  'continent': None,\n",
       "  'country': [['zest airways, inc.', 'philippines'],\n",
       "   ['asian spirit and zest air', 'philippines'],\n",
       "   ['airasia zest', 'philippines'],\n",
       "   ['pasay city', 'philippines'],\n",
       "   ['manila', 'philippines'],\n",
       "   ['metro manila', 'philippines'],\n",
       "   ['ninoy aquino international airport', 'philippines']],\n",
       "  'country of citizenship': None,\n",
       "  'country of origin': None,\n",
       "  'creator': None,\n",
       "  'date of birth': None,\n",
       "  'date of death': None,\n",
       "  'developer': None,\n",
       "  'director': None,\n",
       "  'dissolved, abolished or demolished': None,\n",
       "  'educated at': None,\n",
       "  'employer': None,\n",
       "  'end time': None,\n",
       "  'ethnic group': None,\n",
       "  'father': None,\n",
       "  'followed by': None,\n",
       "  'follows': None,\n",
       "  'founded by': None,\n",
       "  'genre': None,\n",
       "  'has part': None,\n",
       "  'head of government': None,\n",
       "  'head of state': None,\n",
       "  'headquarters location': [['zest airways, inc.', 'pasay city'],\n",
       "   ['asian spirit and zest air', 'pasay city'],\n",
       "   ['airasia zest', 'pasay city']],\n",
       "  'inception': None,\n",
       "  'influenced by': None,\n",
       "  'instance of': None,\n",
       "  'languages spoken, written or signed': None,\n",
       "  'league': None,\n",
       "  'legislative body': None,\n",
       "  'located in or next to body of water': None,\n",
       "  'located in the administrative territorial entity': [['pasay city',\n",
       "    'metro manila'],\n",
       "   ['metro manila', 'philippines'],\n",
       "   ['ninoy aquino international airport', 'pasay city']],\n",
       "  'located on terrain feature': None,\n",
       "  'location': None,\n",
       "  'location of formation': None,\n",
       "  'lyrics by': None,\n",
       "  'manufacturer': None,\n",
       "  'member of': None,\n",
       "  'member of political party': None,\n",
       "  'member of sports team': None,\n",
       "  'military branch': None,\n",
       "  'mother': None,\n",
       "  'mouth of the watercourse': None,\n",
       "  'narrative location': None,\n",
       "  'notable work': None,\n",
       "  'official language': None,\n",
       "  'operator': None,\n",
       "  'original language of work': None,\n",
       "  'original network': None,\n",
       "  'owned by': None,\n",
       "  'parent organization': None,\n",
       "  'parent taxon': None,\n",
       "  'part of': None,\n",
       "  'participant': None,\n",
       "  'participant of': None,\n",
       "  'performer': None,\n",
       "  'place of birth': None,\n",
       "  'place of death': None,\n",
       "  'platform': None,\n",
       "  'point in time': None,\n",
       "  'position held': None,\n",
       "  'present in work': None,\n",
       "  'producer': None,\n",
       "  'product or material produced': None,\n",
       "  'production company': None,\n",
       "  'publication date': None,\n",
       "  'publisher': None,\n",
       "  'record label': None,\n",
       "  'religion': None,\n",
       "  'replaced by': None,\n",
       "  'replaces': None,\n",
       "  'residence': None,\n",
       "  'screenwriter': None,\n",
       "  'separated from': None,\n",
       "  'series': None,\n",
       "  'sibling': None,\n",
       "  'sister city': None,\n",
       "  'spouse': None,\n",
       "  'start time': None,\n",
       "  'subclass of': None,\n",
       "  'subsidiary': None,\n",
       "  'territory claimed by': None,\n",
       "  'unemployment rate': None,\n",
       "  'work location': None}}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dataset['entity'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"relation_info_dict = {}\n",
    "for id, relation in enumerate(dataset[0]['relation'].keys()):\n",
    "    relation_info_dict[relation] = id\n",
    "\n",
    "with open('DocRED/data/relation-index.json', 'w') as f:\n",
    "    json.dump(relation_info_dict, f)\"\"\"\n",
    "\n",
    "with open('DocRED/data/relation-index.json') as f:\n",
    "    relation_info_dict = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pro_processing_ner(example, tokenizer, padding=True):\n",
    "    texts = example['text']\n",
    "    input_texts = []\n",
    "    for index in range(len(texts)):\n",
    "        # entity extraction and NER\n",
    "        text = texts[index].lower().strip() + \" [learn1] [learn2]\"\n",
    "        for entity in example['entity'][index]:\n",
    "            text = text + \" entity : \" + entity[0] + \" , type : \" + entity[1] + \" ;\"\n",
    "        text = text[:-1] + \".\"\n",
    "        # print(\"1\")\n",
    "        # add relation classificaiton\n",
    "        text = text.lower().strip() + \" [learn3] [learn4]\"\n",
    "        for relation_type, relation_pair in example['relation'][index].items():\n",
    "            if relation_pair:\n",
    "                text_w_relation = text + \" for the relation \" + relation_type + \" : 1 .\"\n",
    "                text_w_relation = text_w_relation.lower().strip() + \" [learn5] [learn6]\"\n",
    "                text_w_relation = text_w_relation + \" and the entity for the relation \" + relation_type + \" are :\"\n",
    "                for pair in relation_pair:\n",
    "                    text_w_relation = text_w_relation + \" head entity: \" + pair[0] + \" , tail entity: \" + pair[1] + \";\"\n",
    "                text_w_relation = text_w_relation[:-1] + \".\" + tokenizer.eos_token\n",
    "                input_texts.append(text_w_relation)\n",
    "\n",
    "            else:\n",
    "                text_w_relation = text + \" for the relation \" + relation_type + \" : 0 .\" + tokenizer.eos_token\n",
    "                input_texts.append(text_w_relation)\n",
    "\n",
    "    return {\n",
    "        'input_ids': input_texts\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "26a5e676d0b04808894a90b1ae7ca7a0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/24256 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/home/tian/Projects/intermediate-sv/try-short-relation.ipynb Cell 25\u001b[0m line \u001b[0;36m1\n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/tian/Projects/intermediate-sv/try-short-relation.ipynb#Y116sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m tokenized_dataset \u001b[39m=\u001b[39m dataset\u001b[39m.\u001b[39;49mmap(\u001b[39mlambda\u001b[39;49;00m example: pro_processing_ner(example, tokenizer), batched\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n",
      "File \u001b[0;32m~/mambaforge/envs/BioRED/lib/python3.10/site-packages/datasets/arrow_dataset.py:578\u001b[0m, in \u001b[0;36mtransmit_tasks.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    576\u001b[0m     \u001b[39mself\u001b[39m: \u001b[39m\"\u001b[39m\u001b[39mDataset\u001b[39m\u001b[39m\"\u001b[39m \u001b[39m=\u001b[39m kwargs\u001b[39m.\u001b[39mpop(\u001b[39m\"\u001b[39m\u001b[39mself\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    577\u001b[0m \u001b[39m# apply actual function\u001b[39;00m\n\u001b[0;32m--> 578\u001b[0m out: Union[\u001b[39m\"\u001b[39m\u001b[39mDataset\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mDatasetDict\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m func(\u001b[39mself\u001b[39;49m, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    579\u001b[0m datasets: List[\u001b[39m\"\u001b[39m\u001b[39mDataset\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m(out\u001b[39m.\u001b[39mvalues()) \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(out, \u001b[39mdict\u001b[39m) \u001b[39melse\u001b[39;00m [out]\n\u001b[1;32m    580\u001b[0m \u001b[39mfor\u001b[39;00m dataset \u001b[39min\u001b[39;00m datasets:\n\u001b[1;32m    581\u001b[0m     \u001b[39m# Remove task templates if a column mapping of the template is no longer valid\u001b[39;00m\n",
      "File \u001b[0;32m~/mambaforge/envs/BioRED/lib/python3.10/site-packages/datasets/arrow_dataset.py:543\u001b[0m, in \u001b[0;36mtransmit_format.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    536\u001b[0m self_format \u001b[39m=\u001b[39m {\n\u001b[1;32m    537\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mtype\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_format_type,\n\u001b[1;32m    538\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mformat_kwargs\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_format_kwargs,\n\u001b[1;32m    539\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mcolumns\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_format_columns,\n\u001b[1;32m    540\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39moutput_all_columns\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_output_all_columns,\n\u001b[1;32m    541\u001b[0m }\n\u001b[1;32m    542\u001b[0m \u001b[39m# apply actual function\u001b[39;00m\n\u001b[0;32m--> 543\u001b[0m out: Union[\u001b[39m\"\u001b[39m\u001b[39mDataset\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mDatasetDict\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m func(\u001b[39mself\u001b[39;49m, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    544\u001b[0m datasets: List[\u001b[39m\"\u001b[39m\u001b[39mDataset\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m(out\u001b[39m.\u001b[39mvalues()) \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(out, \u001b[39mdict\u001b[39m) \u001b[39melse\u001b[39;00m [out]\n\u001b[1;32m    545\u001b[0m \u001b[39m# re-apply format to the output\u001b[39;00m\n",
      "File \u001b[0;32m~/mambaforge/envs/BioRED/lib/python3.10/site-packages/datasets/arrow_dataset.py:3073\u001b[0m, in \u001b[0;36mDataset.map\u001b[0;34m(self, function, with_indices, with_rank, input_columns, batched, batch_size, drop_last_batch, remove_columns, keep_in_memory, load_from_cache_file, cache_file_name, writer_batch_size, features, disable_nullable, fn_kwargs, num_proc, suffix_template, new_fingerprint, desc)\u001b[0m\n\u001b[1;32m   3065\u001b[0m \u001b[39mif\u001b[39;00m transformed_dataset \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m   3066\u001b[0m     \u001b[39mwith\u001b[39;00m logging\u001b[39m.\u001b[39mtqdm(\n\u001b[1;32m   3067\u001b[0m         disable\u001b[39m=\u001b[39m\u001b[39mnot\u001b[39;00m logging\u001b[39m.\u001b[39mis_progress_bar_enabled(),\n\u001b[1;32m   3068\u001b[0m         unit\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m examples\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   3071\u001b[0m         desc\u001b[39m=\u001b[39mdesc \u001b[39mor\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mMap\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m   3072\u001b[0m     ) \u001b[39mas\u001b[39;00m pbar:\n\u001b[0;32m-> 3073\u001b[0m         \u001b[39mfor\u001b[39;00m rank, done, content \u001b[39min\u001b[39;00m Dataset\u001b[39m.\u001b[39m_map_single(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mdataset_kwargs):\n\u001b[1;32m   3074\u001b[0m             \u001b[39mif\u001b[39;00m done:\n\u001b[1;32m   3075\u001b[0m                 shards_done \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n",
      "File \u001b[0;32m~/mambaforge/envs/BioRED/lib/python3.10/site-packages/datasets/arrow_dataset.py:3449\u001b[0m, in \u001b[0;36mDataset._map_single\u001b[0;34m(shard, function, with_indices, with_rank, input_columns, batched, batch_size, drop_last_batch, remove_columns, keep_in_memory, cache_file_name, writer_batch_size, features, disable_nullable, fn_kwargs, new_fingerprint, rank, offset)\u001b[0m\n\u001b[1;32m   3445\u001b[0m indices \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m(\n\u001b[1;32m   3446\u001b[0m     \u001b[39mrange\u001b[39m(\u001b[39m*\u001b[39m(\u001b[39mslice\u001b[39m(i, i \u001b[39m+\u001b[39m batch_size)\u001b[39m.\u001b[39mindices(shard\u001b[39m.\u001b[39mnum_rows)))\n\u001b[1;32m   3447\u001b[0m )  \u001b[39m# Something simpler?\u001b[39;00m\n\u001b[1;32m   3448\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m-> 3449\u001b[0m     batch \u001b[39m=\u001b[39m apply_function_on_filtered_inputs(\n\u001b[1;32m   3450\u001b[0m         batch,\n\u001b[1;32m   3451\u001b[0m         indices,\n\u001b[1;32m   3452\u001b[0m         check_same_num_examples\u001b[39m=\u001b[39;49m\u001b[39mlen\u001b[39;49m(shard\u001b[39m.\u001b[39;49mlist_indexes()) \u001b[39m>\u001b[39;49m \u001b[39m0\u001b[39;49m,\n\u001b[1;32m   3453\u001b[0m         offset\u001b[39m=\u001b[39;49moffset,\n\u001b[1;32m   3454\u001b[0m     )\n\u001b[1;32m   3455\u001b[0m \u001b[39mexcept\u001b[39;00m NumExamplesMismatchError:\n\u001b[1;32m   3456\u001b[0m     \u001b[39mraise\u001b[39;00m DatasetTransformationNotAllowedError(\n\u001b[1;32m   3457\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mUsing `.map` in batched mode on a dataset with attached indexes is allowed only if it doesn\u001b[39m\u001b[39m'\u001b[39m\u001b[39mt create or remove existing examples. You can first run `.drop_index() to remove your index and then re-add it.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   3458\u001b[0m     ) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/mambaforge/envs/BioRED/lib/python3.10/site-packages/datasets/arrow_dataset.py:3330\u001b[0m, in \u001b[0;36mDataset._map_single.<locals>.apply_function_on_filtered_inputs\u001b[0;34m(pa_inputs, indices, check_same_num_examples, offset)\u001b[0m\n\u001b[1;32m   3328\u001b[0m \u001b[39mif\u001b[39;00m with_rank:\n\u001b[1;32m   3329\u001b[0m     additional_args \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m (rank,)\n\u001b[0;32m-> 3330\u001b[0m processed_inputs \u001b[39m=\u001b[39m function(\u001b[39m*\u001b[39;49mfn_args, \u001b[39m*\u001b[39;49madditional_args, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mfn_kwargs)\n\u001b[1;32m   3331\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(processed_inputs, LazyDict):\n\u001b[1;32m   3332\u001b[0m     processed_inputs \u001b[39m=\u001b[39m {\n\u001b[1;32m   3333\u001b[0m         k: v \u001b[39mfor\u001b[39;00m k, v \u001b[39min\u001b[39;00m processed_inputs\u001b[39m.\u001b[39mdata\u001b[39m.\u001b[39mitems() \u001b[39mif\u001b[39;00m k \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m processed_inputs\u001b[39m.\u001b[39mkeys_to_format\n\u001b[1;32m   3334\u001b[0m     }\n",
      "\u001b[1;32m/home/tian/Projects/intermediate-sv/try-short-relation.ipynb Cell 25\u001b[0m line \u001b[0;36m1\n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/tian/Projects/intermediate-sv/try-short-relation.ipynb#Y116sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m tokenized_dataset \u001b[39m=\u001b[39m dataset\u001b[39m.\u001b[39mmap(\u001b[39mlambda\u001b[39;00m example: pro_processing_ner(example, tokenizer), batched\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n",
      "\u001b[1;32m/home/tian/Projects/intermediate-sv/try-short-relation.ipynb Cell 25\u001b[0m line \u001b[0;36m2\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/tian/Projects/intermediate-sv/try-short-relation.ipynb#Y116sZmlsZQ%3D%3D?line=23'>24</a>\u001b[0m             text_w_relation \u001b[39m=\u001b[39m text \u001b[39m+\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m for the relation \u001b[39m\u001b[39m\"\u001b[39m \u001b[39m+\u001b[39m relation_type \u001b[39m+\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m : 0 .\u001b[39m\u001b[39m\"\u001b[39m \u001b[39m+\u001b[39m tokenizer\u001b[39m.\u001b[39meos_token\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/tian/Projects/intermediate-sv/try-short-relation.ipynb#Y116sZmlsZQ%3D%3D?line=24'>25</a>\u001b[0m             input_texts\u001b[39m.\u001b[39mappend(text_w_relation)\n\u001b[0;32m---> <a href='vscode-notebook-cell:/home/tian/Projects/intermediate-sv/try-short-relation.ipynb#Y116sZmlsZQ%3D%3D?line=26'>27</a>\u001b[0m output_ids \u001b[39m=\u001b[39m tokenizer(input_texts, add_special_tokens\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m)[\u001b[39m'\u001b[39m\u001b[39minput_ids\u001b[39m\u001b[39m'\u001b[39m]\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/tian/Projects/intermediate-sv/try-short-relation.ipynb#Y116sZmlsZQ%3D%3D?line=28'>29</a>\u001b[0m \u001b[39m# input_ids = []\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/tian/Projects/intermediate-sv/try-short-relation.ipynb#Y116sZmlsZQ%3D%3D?line=29'>30</a>\u001b[0m attention_mask \u001b[39m=\u001b[39m []\n",
      "File \u001b[0;32m~/mambaforge/envs/BioRED/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2548\u001b[0m, in \u001b[0;36mPreTrainedTokenizerBase.__call__\u001b[0;34m(self, text, text_pair, text_target, text_pair_target, add_special_tokens, padding, truncation, max_length, stride, is_split_into_words, pad_to_multiple_of, return_tensors, return_token_type_ids, return_attention_mask, return_overflowing_tokens, return_special_tokens_mask, return_offsets_mapping, return_length, verbose, **kwargs)\u001b[0m\n\u001b[1;32m   2546\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_in_target_context_manager:\n\u001b[1;32m   2547\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_switch_to_input_mode()\n\u001b[0;32m-> 2548\u001b[0m     encodings \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_one(text\u001b[39m=\u001b[39;49mtext, text_pair\u001b[39m=\u001b[39;49mtext_pair, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mall_kwargs)\n\u001b[1;32m   2549\u001b[0m \u001b[39mif\u001b[39;00m text_target \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m   2550\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_switch_to_target_mode()\n",
      "File \u001b[0;32m~/mambaforge/envs/BioRED/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2634\u001b[0m, in \u001b[0;36mPreTrainedTokenizerBase._call_one\u001b[0;34m(self, text, text_pair, add_special_tokens, padding, truncation, max_length, stride, is_split_into_words, pad_to_multiple_of, return_tensors, return_token_type_ids, return_attention_mask, return_overflowing_tokens, return_special_tokens_mask, return_offsets_mapping, return_length, verbose, **kwargs)\u001b[0m\n\u001b[1;32m   2629\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m   2630\u001b[0m             \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mbatch length of `text`: \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mlen\u001b[39m(text)\u001b[39m}\u001b[39;00m\u001b[39m does not match batch length of `text_pair`:\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   2631\u001b[0m             \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mlen\u001b[39m(text_pair)\u001b[39m}\u001b[39;00m\u001b[39m.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   2632\u001b[0m         )\n\u001b[1;32m   2633\u001b[0m     batch_text_or_text_pairs \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m(\u001b[39mzip\u001b[39m(text, text_pair)) \u001b[39mif\u001b[39;00m text_pair \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m text\n\u001b[0;32m-> 2634\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbatch_encode_plus(\n\u001b[1;32m   2635\u001b[0m         batch_text_or_text_pairs\u001b[39m=\u001b[39;49mbatch_text_or_text_pairs,\n\u001b[1;32m   2636\u001b[0m         add_special_tokens\u001b[39m=\u001b[39;49madd_special_tokens,\n\u001b[1;32m   2637\u001b[0m         padding\u001b[39m=\u001b[39;49mpadding,\n\u001b[1;32m   2638\u001b[0m         truncation\u001b[39m=\u001b[39;49mtruncation,\n\u001b[1;32m   2639\u001b[0m         max_length\u001b[39m=\u001b[39;49mmax_length,\n\u001b[1;32m   2640\u001b[0m         stride\u001b[39m=\u001b[39;49mstride,\n\u001b[1;32m   2641\u001b[0m         is_split_into_words\u001b[39m=\u001b[39;49mis_split_into_words,\n\u001b[1;32m   2642\u001b[0m         pad_to_multiple_of\u001b[39m=\u001b[39;49mpad_to_multiple_of,\n\u001b[1;32m   2643\u001b[0m         return_tensors\u001b[39m=\u001b[39;49mreturn_tensors,\n\u001b[1;32m   2644\u001b[0m         return_token_type_ids\u001b[39m=\u001b[39;49mreturn_token_type_ids,\n\u001b[1;32m   2645\u001b[0m         return_attention_mask\u001b[39m=\u001b[39;49mreturn_attention_mask,\n\u001b[1;32m   2646\u001b[0m         return_overflowing_tokens\u001b[39m=\u001b[39;49mreturn_overflowing_tokens,\n\u001b[1;32m   2647\u001b[0m         return_special_tokens_mask\u001b[39m=\u001b[39;49mreturn_special_tokens_mask,\n\u001b[1;32m   2648\u001b[0m         return_offsets_mapping\u001b[39m=\u001b[39;49mreturn_offsets_mapping,\n\u001b[1;32m   2649\u001b[0m         return_length\u001b[39m=\u001b[39;49mreturn_length,\n\u001b[1;32m   2650\u001b[0m         verbose\u001b[39m=\u001b[39;49mverbose,\n\u001b[1;32m   2651\u001b[0m         \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs,\n\u001b[1;32m   2652\u001b[0m     )\n\u001b[1;32m   2653\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   2654\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mencode_plus(\n\u001b[1;32m   2655\u001b[0m         text\u001b[39m=\u001b[39mtext,\n\u001b[1;32m   2656\u001b[0m         text_pair\u001b[39m=\u001b[39mtext_pair,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2672\u001b[0m         \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs,\n\u001b[1;32m   2673\u001b[0m     )\n",
      "File \u001b[0;32m~/mambaforge/envs/BioRED/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2825\u001b[0m, in \u001b[0;36mPreTrainedTokenizerBase.batch_encode_plus\u001b[0;34m(self, batch_text_or_text_pairs, add_special_tokens, padding, truncation, max_length, stride, is_split_into_words, pad_to_multiple_of, return_tensors, return_token_type_ids, return_attention_mask, return_overflowing_tokens, return_special_tokens_mask, return_offsets_mapping, return_length, verbose, **kwargs)\u001b[0m\n\u001b[1;32m   2815\u001b[0m \u001b[39m# Backward compatibility for 'truncation_strategy', 'pad_to_max_length'\u001b[39;00m\n\u001b[1;32m   2816\u001b[0m padding_strategy, truncation_strategy, max_length, kwargs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_get_padding_truncation_strategies(\n\u001b[1;32m   2817\u001b[0m     padding\u001b[39m=\u001b[39mpadding,\n\u001b[1;32m   2818\u001b[0m     truncation\u001b[39m=\u001b[39mtruncation,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2822\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs,\n\u001b[1;32m   2823\u001b[0m )\n\u001b[0;32m-> 2825\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_batch_encode_plus(\n\u001b[1;32m   2826\u001b[0m     batch_text_or_text_pairs\u001b[39m=\u001b[39;49mbatch_text_or_text_pairs,\n\u001b[1;32m   2827\u001b[0m     add_special_tokens\u001b[39m=\u001b[39;49madd_special_tokens,\n\u001b[1;32m   2828\u001b[0m     padding_strategy\u001b[39m=\u001b[39;49mpadding_strategy,\n\u001b[1;32m   2829\u001b[0m     truncation_strategy\u001b[39m=\u001b[39;49mtruncation_strategy,\n\u001b[1;32m   2830\u001b[0m     max_length\u001b[39m=\u001b[39;49mmax_length,\n\u001b[1;32m   2831\u001b[0m     stride\u001b[39m=\u001b[39;49mstride,\n\u001b[1;32m   2832\u001b[0m     is_split_into_words\u001b[39m=\u001b[39;49mis_split_into_words,\n\u001b[1;32m   2833\u001b[0m     pad_to_multiple_of\u001b[39m=\u001b[39;49mpad_to_multiple_of,\n\u001b[1;32m   2834\u001b[0m     return_tensors\u001b[39m=\u001b[39;49mreturn_tensors,\n\u001b[1;32m   2835\u001b[0m     return_token_type_ids\u001b[39m=\u001b[39;49mreturn_token_type_ids,\n\u001b[1;32m   2836\u001b[0m     return_attention_mask\u001b[39m=\u001b[39;49mreturn_attention_mask,\n\u001b[1;32m   2837\u001b[0m     return_overflowing_tokens\u001b[39m=\u001b[39;49mreturn_overflowing_tokens,\n\u001b[1;32m   2838\u001b[0m     return_special_tokens_mask\u001b[39m=\u001b[39;49mreturn_special_tokens_mask,\n\u001b[1;32m   2839\u001b[0m     return_offsets_mapping\u001b[39m=\u001b[39;49mreturn_offsets_mapping,\n\u001b[1;32m   2840\u001b[0m     return_length\u001b[39m=\u001b[39;49mreturn_length,\n\u001b[1;32m   2841\u001b[0m     verbose\u001b[39m=\u001b[39;49mverbose,\n\u001b[1;32m   2842\u001b[0m     \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs,\n\u001b[1;32m   2843\u001b[0m )\n",
      "File \u001b[0;32m~/mambaforge/envs/BioRED/lib/python3.10/site-packages/transformers/tokenization_utils.py:733\u001b[0m, in \u001b[0;36mPreTrainedTokenizer._batch_encode_plus\u001b[0;34m(self, batch_text_or_text_pairs, add_special_tokens, padding_strategy, truncation_strategy, max_length, stride, is_split_into_words, pad_to_multiple_of, return_tensors, return_token_type_ids, return_attention_mask, return_overflowing_tokens, return_special_tokens_mask, return_offsets_mapping, return_length, verbose, **kwargs)\u001b[0m\n\u001b[1;32m    730\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    731\u001b[0m     ids, pair_ids \u001b[39m=\u001b[39m ids_or_pair_ids\n\u001b[0;32m--> 733\u001b[0m first_ids \u001b[39m=\u001b[39m get_input_ids(ids)\n\u001b[1;32m    734\u001b[0m second_ids \u001b[39m=\u001b[39m get_input_ids(pair_ids) \u001b[39mif\u001b[39;00m pair_ids \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    735\u001b[0m input_ids\u001b[39m.\u001b[39mappend((first_ids, second_ids))\n",
      "File \u001b[0;32m~/mambaforge/envs/BioRED/lib/python3.10/site-packages/transformers/tokenization_utils.py:701\u001b[0m, in \u001b[0;36mPreTrainedTokenizer._batch_encode_plus.<locals>.get_input_ids\u001b[0;34m(text)\u001b[0m\n\u001b[1;32m    699\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(text, \u001b[39mstr\u001b[39m):\n\u001b[1;32m    700\u001b[0m     tokens \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtokenize(text, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m--> 701\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mconvert_tokens_to_ids(tokens)\n\u001b[1;32m    702\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39misinstance\u001b[39m(text, (\u001b[39mlist\u001b[39m, \u001b[39mtuple\u001b[39m)) \u001b[39mand\u001b[39;00m \u001b[39mlen\u001b[39m(text) \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m \u001b[39mand\u001b[39;00m \u001b[39misinstance\u001b[39m(text[\u001b[39m0\u001b[39m], \u001b[39mstr\u001b[39m):\n\u001b[1;32m    703\u001b[0m     \u001b[39mif\u001b[39;00m is_split_into_words:\n",
      "File \u001b[0;32m~/mambaforge/envs/BioRED/lib/python3.10/site-packages/transformers/tokenization_utils.py:579\u001b[0m, in \u001b[0;36mPreTrainedTokenizer.convert_tokens_to_ids\u001b[0;34m(self, tokens)\u001b[0m\n\u001b[1;32m    577\u001b[0m ids \u001b[39m=\u001b[39m []\n\u001b[1;32m    578\u001b[0m \u001b[39mfor\u001b[39;00m token \u001b[39min\u001b[39;00m tokens:\n\u001b[0;32m--> 579\u001b[0m     ids\u001b[39m.\u001b[39mappend(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_convert_token_to_id_with_added_voc(token))\n\u001b[1;32m    580\u001b[0m \u001b[39mreturn\u001b[39;00m ids\n",
      "File \u001b[0;32m~/mambaforge/envs/BioRED/lib/python3.10/site-packages/transformers/tokenization_utils.py:586\u001b[0m, in \u001b[0;36mPreTrainedTokenizer._convert_token_to_id_with_added_voc\u001b[0;34m(self, token)\u001b[0m\n\u001b[1;32m    583\u001b[0m \u001b[39mif\u001b[39;00m token \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    584\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m--> 586\u001b[0m \u001b[39mif\u001b[39;00m token \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39madded_tokens_encoder:\n\u001b[1;32m    587\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39madded_tokens_encoder[token]\n\u001b[1;32m    588\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_convert_token_to_id(token)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "tokenized_dataset = dataset.map(lambda example: pro_processing_ner(example, tokenizer), batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 809/809 [00:21<00:00, 37.95it/s]\n"
     ]
    }
   ],
   "source": [
    "# feed the dataset:dataset to the pro_processing_ner() function with tokenizer, at each time, we feed 30 examples to the function, and then save the output to a json file\n",
    "# each time the return of the function is a dict, we need to save the dict to a list, and then save the list to a json file\n",
    "\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "output = {\"input_texts\": []}\n",
    "\n",
    "for i in tqdm(range(0, len(dataset), 30)):\n",
    "    result = pro_processing_ner(dataset[i:i+30], tokenizer)\n",
    "    output[\"input_texts\"].extend(result[\"input_ids\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2328576"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(output['input_texts'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'output' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/home/tian/Projects/intermediate-sv/try-short-relation.ipynb Cell 28\u001b[0m line \u001b[0;36m7\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/tian/Projects/intermediate-sv/try-short-relation.ipynb#X36sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39m# make the output[\"input_texts\"] into a dataset\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/tian/Projects/intermediate-sv/try-short-relation.ipynb#X36sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mdatasets\u001b[39;00m \u001b[39mimport\u001b[39;00m Dataset\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/tian/Projects/intermediate-sv/try-short-relation.ipynb#X36sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m input_text_dataset \u001b[39m=\u001b[39m Dataset\u001b[39m.\u001b[39mfrom_dict(\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/tian/Projects/intermediate-sv/try-short-relation.ipynb#X36sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m     {\n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/tian/Projects/intermediate-sv/try-short-relation.ipynb#X36sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m         \u001b[39m'\u001b[39m\u001b[39minput_texts\u001b[39m\u001b[39m'\u001b[39m: output[\u001b[39m'\u001b[39m\u001b[39minput_texts\u001b[39m\u001b[39m'\u001b[39m],\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/tian/Projects/intermediate-sv/try-short-relation.ipynb#X36sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m     }\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/tian/Projects/intermediate-sv/try-short-relation.ipynb#X36sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m )\n",
      "\u001b[0;31mNameError\u001b[0m: name 'output' is not defined"
     ]
    }
   ],
   "source": [
    "# make the output[\"input_texts\"] into a dataset\n",
    "from datasets import Dataset\n",
    "\n",
    "input_text_dataset = Dataset.from_dict(\n",
    "    {\n",
    "        'input_texts': output['input_texts'],\n",
    "    }\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4afe369465214b9ca4a343670d237807",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/2328576 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokenized_dataset = input_text_dataset.map(lambda example: tokenizer(example['input_texts'], padding='max_length', truncation=True, max_length=1024, pad_to_max_length=True), batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['input_texts', 'input_ids', 'attention_mask'],\n",
       "    num_rows: 2328576\n",
       "})"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# remove the column of input_texts in the tokenized_dataset\n",
    "tokenized_dataset.remove_columns('input_texts')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5de64efb8e974320afbcbd97875863ab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/27 shards):   0%|          | 0/2328576 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# save the tokenized_dataset\n",
    "\n",
    "tokenized_dataset.save_to_disk('DocRED/GPT_w_ner_short_relation/train_data_ner_short_relation')\n",
    "# with open('DocRED/data/train_ner_short_relation.json', 'w') as f:\n",
    "#     json.dump(tokenized_dataset, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "from datasets import Dataset\n",
    "\n",
    "tokenized_dataset = Dataset.load_from_disk('DocRED/GPT_w_ner_short_relation/train_data_ner_short_relation')\n",
    "tokenized_dataset = tokenized_dataset.remove_columns('input_texts')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# only take the first len(tokenized_dataset) // 50 examples to train the model\n",
    "\n",
    "tokenized_dataset = tokenized_dataset.select(range(len(tokenized_dataset) // 50))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_dataset.set_format(type='torch', columns=['input_ids', 'attention_mask'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'zest airways, inc. operated as airasia zest ( formerly asian spirit and zest air ), was a low - cost airline based at the ninoy aquino international airport in pasay city, metro manila in the philippines. it operated scheduled domestic and international tourist services, mainly feeder services linking manila and cebu with 24 domestic destinations in support of the trunk route operations of other airlines. [learn1] [learn2] entity : zest airways, inc., type : organization ; entity : airasia zest, type : organization ; entity : asian spirit and zest air, type : organization ; entity : ninoy aquino international airport, type : location ; entity : pasay city, type : location ; entity : metro manila, type : location ; entity : philippines, type : location ; entity : manila, type : location ; entity : cebu, type : location ; entity : 24, type : number. [learn3] [learn4] for the relation participant of : 0.<|endoftext|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|>'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(tokenized_dataset[66]['input_ids'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'input_ids': tensor([   89,   395,  1633,  ..., 50258, 50258, 50258]),\n",
       "  'attention_mask': tensor([1, 1, 1,  ..., 0, 0, 0])},\n",
       " {'input_ids': tensor([   89,   395,  1633,  ..., 50258, 50258, 50258]),\n",
       "  'attention_mask': tensor([1, 1, 1,  ..., 0, 0, 0])}]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_dataset.__getitems__([1,4])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33m309439737\u001b[0m (\u001b[33mtian1995\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.15.11 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.4"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/tian/Projects/intermediate-sv/wandb/run-20230925_032334-5sxfyy02</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/tian1995/GPT2-intermediate/runs/5sxfyy02' target=\"_blank\">GPT2-short_relation_DocRED-w-ner-5epochs</a></strong> to <a href='https://wandb.ai/tian1995/GPT2-intermediate' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/tian1995/GPT2-intermediate' target=\"_blank\">https://wandb.ai/tian1995/GPT2-intermediate</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/tian1995/GPT2-intermediate/runs/5sxfyy02' target=\"_blank\">https://wandb.ai/tian1995/GPT2-intermediate/runs/5sxfyy02</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src='https://wandb.ai/tian1995/GPT2-intermediate/runs/5sxfyy02?jupyter=true' style='border:none;width:100%;height:420px;display:none;'></iframe>"
      ],
      "text/plain": [
       "<wandb.sdk.wandb_run.Run at 0x7f16df4387f0>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import wandb\n",
    "\n",
    "wandb.init(\n",
    "    # set the wandb project where this run will be logged\n",
    "    project=\"GPT2-intermediate\",\n",
    "    # notes=\"PubmedBERT-FT-NER_w_NERin_10epochs\",\n",
    "    name=\"GPT2-short_relation_DocRED-w-ner-5epochs\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import transformers\n",
    "from transformers import DataCollatorForLanguageModeling\n",
    "\n",
    "trainer = transformers.Trainer(\n",
    "    model=model, \n",
    "    train_dataset=tokenized_dataset,\n",
    "    args=transformers.TrainingArguments(\n",
    "        per_device_train_batch_size=2, \n",
    "        gradient_accumulation_steps=2,\n",
    "        warmup_steps=1000, \n",
    "        num_train_epochs=5,\n",
    "        learning_rate=2e-4, \n",
    "        # fp16=True,\n",
    "        logging_steps=100, \n",
    "        report_to=\"wandb\",\n",
    "        save_strategy=\"epoch\",\n",
    "        output_dir='DocRED/GPT_w_ner_short_relation'\n",
    "    ),\n",
    "    data_collator=DataCollatorForLanguageModeling(tokenizer, mlm=False)\n",
    ")\n",
    "model.config.use_cache = False  # silence the warnings. Please re-enable for inference!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tian/mambaforge/envs/BioRED/lib/python3.10/site-packages/transformers/optimization.py:407: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d3d5ae3bfd0e4d40802faf9b230d5b87",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/58215 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 28.2435, 'learning_rate': 2e-05, 'epoch': 0.01}\n",
      "{'loss': 2.7659, 'learning_rate': 4e-05, 'epoch': 0.02}\n",
      "{'loss': 1.9937, 'learning_rate': 6e-05, 'epoch': 0.03}\n",
      "{'loss': 1.6083, 'learning_rate': 8e-05, 'epoch': 0.03}\n",
      "{'loss': 1.3042, 'learning_rate': 0.0001, 'epoch': 0.04}\n",
      "{'loss': 1.0588, 'learning_rate': 0.00012, 'epoch': 0.05}\n",
      "{'loss': 0.7999, 'learning_rate': 0.00014, 'epoch': 0.06}\n",
      "{'loss': 0.6312, 'learning_rate': 0.00016, 'epoch': 0.07}\n",
      "{'loss': 0.4804, 'learning_rate': 0.00018, 'epoch': 0.08}\n",
      "{'loss': 0.4285, 'learning_rate': 0.0002, 'epoch': 0.09}\n",
      "{'loss': 0.3386, 'learning_rate': 0.00019965044131783623, 'epoch': 0.09}\n",
      "{'loss': 0.2831, 'learning_rate': 0.00019930088263567247, 'epoch': 0.1}\n",
      "{'loss': 0.2668, 'learning_rate': 0.0001989513239535087, 'epoch': 0.11}\n",
      "{'loss': 0.2264, 'learning_rate': 0.00019860176527134493, 'epoch': 0.12}\n",
      "{'loss': 0.1955, 'learning_rate': 0.00019825220658918117, 'epoch': 0.13}\n",
      "{'loss': 0.1855, 'learning_rate': 0.00019790264790701742, 'epoch': 0.14}\n",
      "{'loss': 0.1639, 'learning_rate': 0.00019755308922485363, 'epoch': 0.15}\n",
      "{'loss': 0.1527, 'learning_rate': 0.00019720353054268987, 'epoch': 0.15}\n",
      "{'loss': 0.1464, 'learning_rate': 0.0001968539718605261, 'epoch': 0.16}\n",
      "{'loss': 0.1404, 'learning_rate': 0.00019650441317836233, 'epoch': 0.17}\n",
      "{'loss': 0.1382, 'learning_rate': 0.00019615485449619855, 'epoch': 0.18}\n",
      "{'loss': 0.1266, 'learning_rate': 0.0001958052958140348, 'epoch': 0.19}\n",
      "{'loss': 0.1298, 'learning_rate': 0.000195455737131871, 'epoch': 0.2}\n",
      "{'loss': 0.1141, 'learning_rate': 0.00019510617844970725, 'epoch': 0.21}\n",
      "{'loss': 0.1154, 'learning_rate': 0.0001947566197675435, 'epoch': 0.21}\n",
      "{'loss': 0.1101, 'learning_rate': 0.0001944070610853797, 'epoch': 0.22}\n",
      "{'loss': 0.1028, 'learning_rate': 0.00019405750240321593, 'epoch': 0.23}\n",
      "{'loss': 0.1068, 'learning_rate': 0.0001937079437210522, 'epoch': 0.24}\n",
      "{'loss': 0.0909, 'learning_rate': 0.00019335838503888842, 'epoch': 0.25}\n",
      "{'loss': 0.0957, 'learning_rate': 0.00019300882635672463, 'epoch': 0.26}\n",
      "{'loss': 0.0952, 'learning_rate': 0.00019265926767456087, 'epoch': 0.27}\n",
      "{'loss': 0.0874, 'learning_rate': 0.00019230970899239712, 'epoch': 0.27}\n",
      "{'loss': 0.091, 'learning_rate': 0.00019196015031023333, 'epoch': 0.28}\n",
      "{'loss': 0.0961, 'learning_rate': 0.00019161059162806958, 'epoch': 0.29}\n",
      "{'loss': 0.0891, 'learning_rate': 0.0001912610329459058, 'epoch': 0.3}\n",
      "{'loss': 0.09, 'learning_rate': 0.00019091147426374204, 'epoch': 0.31}\n",
      "{'loss': 0.0868, 'learning_rate': 0.00019056191558157828, 'epoch': 0.32}\n",
      "{'loss': 0.0914, 'learning_rate': 0.0001902123568994145, 'epoch': 0.33}\n",
      "{'loss': 0.0894, 'learning_rate': 0.0001898627982172507, 'epoch': 0.33}\n",
      "{'loss': 0.0893, 'learning_rate': 0.00018951323953508698, 'epoch': 0.34}\n",
      "{'loss': 0.0949, 'learning_rate': 0.0001891636808529232, 'epoch': 0.35}\n",
      "{'loss': 0.0897, 'learning_rate': 0.00018881412217075942, 'epoch': 0.36}\n",
      "{'loss': 0.0925, 'learning_rate': 0.00018846456348859566, 'epoch': 0.37}\n",
      "{'loss': 0.0895, 'learning_rate': 0.0001881150048064319, 'epoch': 0.38}\n",
      "{'loss': 0.0832, 'learning_rate': 0.00018776544612426812, 'epoch': 0.39}\n",
      "{'loss': 0.0812, 'learning_rate': 0.00018741588744210433, 'epoch': 0.4}\n",
      "{'loss': 0.0828, 'learning_rate': 0.00018706632875994058, 'epoch': 0.4}\n",
      "{'loss': 0.0833, 'learning_rate': 0.00018671677007777682, 'epoch': 0.41}\n",
      "{'loss': 0.0836, 'learning_rate': 0.00018636721139561304, 'epoch': 0.42}\n",
      "{'loss': 0.0836, 'learning_rate': 0.00018601765271344928, 'epoch': 0.43}\n",
      "{'loss': 0.0804, 'learning_rate': 0.00018566809403128552, 'epoch': 0.44}\n",
      "{'loss': 0.0889, 'learning_rate': 0.00018531853534912174, 'epoch': 0.45}\n",
      "{'loss': 0.0814, 'learning_rate': 0.00018496897666695798, 'epoch': 0.46}\n",
      "{'loss': 0.0754, 'learning_rate': 0.0001846194179847942, 'epoch': 0.46}\n",
      "{'loss': 0.083, 'learning_rate': 0.00018426985930263044, 'epoch': 0.47}\n",
      "{'loss': 0.0763, 'learning_rate': 0.00018392030062046669, 'epoch': 0.48}\n",
      "{'loss': 0.0761, 'learning_rate': 0.0001835707419383029, 'epoch': 0.49}\n",
      "{'loss': 0.077, 'learning_rate': 0.00018322118325613912, 'epoch': 0.5}\n",
      "{'loss': 0.0796, 'learning_rate': 0.0001828716245739754, 'epoch': 0.51}\n",
      "{'loss': 0.0767, 'learning_rate': 0.0001825220658918116, 'epoch': 0.52}\n",
      "{'loss': 0.0772, 'learning_rate': 0.00018217250720964782, 'epoch': 0.52}\n",
      "{'loss': 0.0817, 'learning_rate': 0.00018182294852748404, 'epoch': 0.53}\n",
      "{'loss': 0.0804, 'learning_rate': 0.0001814733898453203, 'epoch': 0.54}\n",
      "{'loss': 0.0792, 'learning_rate': 0.00018112383116315652, 'epoch': 0.55}\n",
      "{'loss': 0.0732, 'learning_rate': 0.00018077427248099274, 'epoch': 0.56}\n",
      "{'loss': 0.0746, 'learning_rate': 0.00018042471379882898, 'epoch': 0.57}\n",
      "{'loss': 0.0835, 'learning_rate': 0.00018007515511666523, 'epoch': 0.58}\n",
      "{'loss': 0.0832, 'learning_rate': 0.00017972559643450144, 'epoch': 0.58}\n",
      "{'loss': 0.081, 'learning_rate': 0.00017937603775233769, 'epoch': 0.59}\n",
      "{'loss': 0.0838, 'learning_rate': 0.0001790264790701739, 'epoch': 0.6}\n",
      "{'loss': 0.0779, 'learning_rate': 0.00017867692038801014, 'epoch': 0.61}\n",
      "{'loss': 0.0749, 'learning_rate': 0.0001783273617058464, 'epoch': 0.62}\n",
      "{'loss': 0.0746, 'learning_rate': 0.0001779778030236826, 'epoch': 0.63}\n",
      "{'loss': 0.0722, 'learning_rate': 0.00017762824434151885, 'epoch': 0.64}\n",
      "{'loss': 0.0705, 'learning_rate': 0.0001772786856593551, 'epoch': 0.64}\n",
      "{'loss': 0.0725, 'learning_rate': 0.0001769291269771913, 'epoch': 0.65}\n",
      "{'loss': 0.0719, 'learning_rate': 0.00017657956829502752, 'epoch': 0.66}\n",
      "{'loss': 0.0702, 'learning_rate': 0.00017623000961286377, 'epoch': 0.67}\n",
      "{'loss': 0.0753, 'learning_rate': 0.0001758804509307, 'epoch': 0.68}\n",
      "{'loss': 0.0742, 'learning_rate': 0.00017553089224853623, 'epoch': 0.69}\n",
      "{'loss': 0.0719, 'learning_rate': 0.00017518133356637247, 'epoch': 0.7}\n",
      "{'loss': 0.0714, 'learning_rate': 0.00017483177488420869, 'epoch': 0.7}\n",
      "{'loss': 0.0717, 'learning_rate': 0.00017448221620204493, 'epoch': 0.71}\n",
      "{'loss': 0.0711, 'learning_rate': 0.00017413265751988115, 'epoch': 0.72}\n",
      "{'loss': 0.0758, 'learning_rate': 0.0001737830988377174, 'epoch': 0.73}\n",
      "{'loss': 0.0732, 'learning_rate': 0.00017343354015555363, 'epoch': 0.74}\n",
      "{'loss': 0.07, 'learning_rate': 0.00017308398147338985, 'epoch': 0.75}\n",
      "{'loss': 0.0718, 'learning_rate': 0.0001727344227912261, 'epoch': 0.76}\n",
      "{'loss': 0.0708, 'learning_rate': 0.0001723848641090623, 'epoch': 0.76}\n",
      "{'loss': 0.0703, 'learning_rate': 0.00017203530542689855, 'epoch': 0.77}\n",
      "{'loss': 0.0725, 'learning_rate': 0.0001716857467447348, 'epoch': 0.78}\n",
      "{'loss': 0.0719, 'learning_rate': 0.000171336188062571, 'epoch': 0.79}\n",
      "{'loss': 0.0735, 'learning_rate': 0.00017098662938040723, 'epoch': 0.8}\n",
      "{'loss': 0.0719, 'learning_rate': 0.0001706370706982435, 'epoch': 0.81}\n",
      "{'loss': 0.0758, 'learning_rate': 0.0001702875120160797, 'epoch': 0.82}\n",
      "{'loss': 0.0732, 'learning_rate': 0.00016993795333391593, 'epoch': 0.82}\n",
      "{'loss': 0.0703, 'learning_rate': 0.00016958839465175217, 'epoch': 0.83}\n",
      "{'loss': 0.0721, 'learning_rate': 0.00016923883596958842, 'epoch': 0.84}\n",
      "{'loss': 0.0723, 'learning_rate': 0.00016888927728742463, 'epoch': 0.85}\n",
      "{'loss': 0.0711, 'learning_rate': 0.00016853971860526087, 'epoch': 0.86}\n",
      "{'loss': 0.0684, 'learning_rate': 0.0001681901599230971, 'epoch': 0.87}\n",
      "{'loss': 0.0683, 'learning_rate': 0.00016784060124093333, 'epoch': 0.88}\n",
      "{'loss': 0.0738, 'learning_rate': 0.00016749104255876955, 'epoch': 0.88}\n",
      "{'loss': 0.0662, 'learning_rate': 0.0001671414838766058, 'epoch': 0.89}\n",
      "{'loss': 0.0693, 'learning_rate': 0.000166791925194442, 'epoch': 0.9}\n",
      "{'loss': 0.0669, 'learning_rate': 0.00016644236651227825, 'epoch': 0.91}\n",
      "{'loss': 0.0701, 'learning_rate': 0.0001660928078301145, 'epoch': 0.92}\n",
      "{'loss': 0.0724, 'learning_rate': 0.0001657432491479507, 'epoch': 0.93}\n",
      "{'loss': 0.072, 'learning_rate': 0.00016539369046578696, 'epoch': 0.94}\n",
      "{'loss': 0.0723, 'learning_rate': 0.0001650441317836232, 'epoch': 0.94}\n",
      "{'loss': 0.0712, 'learning_rate': 0.00016469457310145942, 'epoch': 0.95}\n",
      "{'loss': 0.0703, 'learning_rate': 0.00016434501441929563, 'epoch': 0.96}\n",
      "{'loss': 0.0701, 'learning_rate': 0.00016399545573713187, 'epoch': 0.97}\n",
      "{'loss': 0.0726, 'learning_rate': 0.00016364589705496812, 'epoch': 0.98}\n",
      "{'loss': 0.0718, 'learning_rate': 0.00016329633837280433, 'epoch': 0.99}\n",
      "{'loss': 0.072, 'learning_rate': 0.00016294677969064058, 'epoch': 1.0}\n",
      "{'loss': 0.0665, 'learning_rate': 0.00016259722100847682, 'epoch': 1.0}\n",
      "{'loss': 0.0678, 'learning_rate': 0.00016224766232631304, 'epoch': 1.01}\n",
      "{'loss': 0.0674, 'learning_rate': 0.00016189810364414928, 'epoch': 1.02}\n",
      "{'loss': 0.0673, 'learning_rate': 0.0001615485449619855, 'epoch': 1.03}\n",
      "{'loss': 0.0677, 'learning_rate': 0.00016119898627982174, 'epoch': 1.04}\n",
      "{'loss': 0.0685, 'learning_rate': 0.00016084942759765796, 'epoch': 1.05}\n",
      "{'loss': 0.0668, 'learning_rate': 0.0001604998689154942, 'epoch': 1.06}\n",
      "{'loss': 0.0726, 'learning_rate': 0.00016015031023333042, 'epoch': 1.07}\n",
      "{'loss': 0.0721, 'learning_rate': 0.00015980075155116666, 'epoch': 1.07}\n",
      "{'loss': 0.071, 'learning_rate': 0.0001594511928690029, 'epoch': 1.08}\n",
      "{'loss': 0.0682, 'learning_rate': 0.00015910163418683912, 'epoch': 1.09}\n",
      "{'loss': 0.0695, 'learning_rate': 0.00015875207550467533, 'epoch': 1.1}\n",
      "{'loss': 0.0677, 'learning_rate': 0.0001584025168225116, 'epoch': 1.11}\n",
      "{'loss': 0.0651, 'learning_rate': 0.00015805295814034782, 'epoch': 1.12}\n",
      "{'loss': 0.071, 'learning_rate': 0.00015770339945818404, 'epoch': 1.13}\n",
      "{'loss': 0.0682, 'learning_rate': 0.00015735384077602028, 'epoch': 1.13}\n",
      "{'loss': 0.0747, 'learning_rate': 0.00015700428209385652, 'epoch': 1.14}\n",
      "{'loss': 0.0688, 'learning_rate': 0.00015665472341169274, 'epoch': 1.15}\n",
      "{'loss': 0.071, 'learning_rate': 0.00015630516472952898, 'epoch': 1.16}\n",
      "{'loss': 0.0705, 'learning_rate': 0.0001559556060473652, 'epoch': 1.17}\n",
      "{'loss': 0.0739, 'learning_rate': 0.00015560604736520144, 'epoch': 1.18}\n",
      "{'loss': 0.0655, 'learning_rate': 0.00015525648868303769, 'epoch': 1.19}\n",
      "{'loss': 0.0666, 'learning_rate': 0.0001549069300008739, 'epoch': 1.19}\n",
      "{'loss': 0.0673, 'learning_rate': 0.00015455737131871012, 'epoch': 1.2}\n",
      "{'loss': 0.0722, 'learning_rate': 0.0001542078126365464, 'epoch': 1.21}\n",
      "{'loss': 0.0642, 'learning_rate': 0.0001538582539543826, 'epoch': 1.22}\n",
      "{'loss': 0.0683, 'learning_rate': 0.00015350869527221882, 'epoch': 1.23}\n",
      "{'loss': 0.0641, 'learning_rate': 0.00015315913659005506, 'epoch': 1.24}\n",
      "{'loss': 0.0666, 'learning_rate': 0.0001528095779078913, 'epoch': 1.25}\n",
      "{'loss': 0.0654, 'learning_rate': 0.00015246001922572752, 'epoch': 1.25}\n",
      "{'loss': 0.0698, 'learning_rate': 0.00015211046054356374, 'epoch': 1.26}\n",
      "{'loss': 0.0632, 'learning_rate': 0.00015176090186139998, 'epoch': 1.27}\n",
      "{'loss': 0.0702, 'learning_rate': 0.00015141134317923623, 'epoch': 1.28}\n",
      "{'loss': 0.0696, 'learning_rate': 0.00015106178449707244, 'epoch': 1.29}\n",
      "{'loss': 0.0701, 'learning_rate': 0.00015071222581490869, 'epoch': 1.3}\n",
      "{'loss': 0.0687, 'learning_rate': 0.00015036266713274493, 'epoch': 1.31}\n",
      "{'loss': 0.0727, 'learning_rate': 0.00015001310845058115, 'epoch': 1.31}\n",
      "{'loss': 0.0688, 'learning_rate': 0.0001496635497684174, 'epoch': 1.32}\n",
      "{'loss': 0.0685, 'learning_rate': 0.0001493139910862536, 'epoch': 1.33}\n",
      "{'loss': 0.0704, 'learning_rate': 0.00014896443240408985, 'epoch': 1.34}\n",
      "{'loss': 0.0667, 'learning_rate': 0.0001486148737219261, 'epoch': 1.35}\n",
      "{'loss': 0.0667, 'learning_rate': 0.0001482653150397623, 'epoch': 1.36}\n",
      "{'loss': 0.0667, 'learning_rate': 0.00014791575635759852, 'epoch': 1.37}\n",
      "{'loss': 0.0651, 'learning_rate': 0.0001475661976754348, 'epoch': 1.37}\n",
      "{'loss': 0.0635, 'learning_rate': 0.000147216638993271, 'epoch': 1.38}\n",
      "{'loss': 0.0663, 'learning_rate': 0.00014686708031110723, 'epoch': 1.39}\n",
      "{'loss': 0.0707, 'learning_rate': 0.00014651752162894344, 'epoch': 1.4}\n",
      "{'loss': 0.0657, 'learning_rate': 0.0001461679629467797, 'epoch': 1.41}\n",
      "{'loss': 0.0675, 'learning_rate': 0.00014581840426461593, 'epoch': 1.42}\n",
      "{'loss': 0.0658, 'learning_rate': 0.00014546884558245215, 'epoch': 1.43}\n",
      "{'loss': 0.0641, 'learning_rate': 0.0001451192869002884, 'epoch': 1.43}\n",
      "{'loss': 0.0643, 'learning_rate': 0.00014476972821812463, 'epoch': 1.44}\n",
      "{'loss': 0.0678, 'learning_rate': 0.00014442016953596085, 'epoch': 1.45}\n",
      "{'loss': 0.0678, 'learning_rate': 0.0001440706108537971, 'epoch': 1.46}\n",
      "{'loss': 0.072, 'learning_rate': 0.0001437210521716333, 'epoch': 1.47}\n",
      "{'loss': 0.0658, 'learning_rate': 0.00014337149348946955, 'epoch': 1.48}\n",
      "{'loss': 0.0664, 'learning_rate': 0.0001430219348073058, 'epoch': 1.49}\n",
      "{'loss': 0.0682, 'learning_rate': 0.000142672376125142, 'epoch': 1.49}\n",
      "{'loss': 0.0659, 'learning_rate': 0.00014232281744297825, 'epoch': 1.5}\n",
      "{'loss': 0.0635, 'learning_rate': 0.0001419732587608145, 'epoch': 1.51}\n",
      "{'loss': 0.0654, 'learning_rate': 0.0001416237000786507, 'epoch': 1.52}\n",
      "{'loss': 0.0683, 'learning_rate': 0.00014127414139648693, 'epoch': 1.53}\n",
      "{'loss': 0.066, 'learning_rate': 0.00014092458271432317, 'epoch': 1.54}\n",
      "{'loss': 0.0616, 'learning_rate': 0.00014057502403215942, 'epoch': 1.55}\n",
      "{'loss': 0.0641, 'learning_rate': 0.00014022546534999563, 'epoch': 1.55}\n",
      "{'loss': 0.0651, 'learning_rate': 0.00013987590666783188, 'epoch': 1.56}\n",
      "{'loss': 0.0652, 'learning_rate': 0.0001395263479856681, 'epoch': 1.57}\n",
      "{'loss': 0.0619, 'learning_rate': 0.00013917678930350433, 'epoch': 1.58}\n",
      "{'loss': 0.0648, 'learning_rate': 0.00013882723062134055, 'epoch': 1.59}\n",
      "{'loss': 0.0639, 'learning_rate': 0.0001384776719391768, 'epoch': 1.6}\n",
      "{'loss': 0.0625, 'learning_rate': 0.00013812811325701304, 'epoch': 1.61}\n",
      "{'loss': 0.0652, 'learning_rate': 0.00013777855457484925, 'epoch': 1.61}\n",
      "{'loss': 0.0658, 'learning_rate': 0.0001374289958926855, 'epoch': 1.62}\n",
      "{'loss': 0.0676, 'learning_rate': 0.0001370794372105217, 'epoch': 1.63}\n",
      "{'loss': 0.0655, 'learning_rate': 0.00013672987852835796, 'epoch': 1.64}\n",
      "{'loss': 0.0666, 'learning_rate': 0.0001363803198461942, 'epoch': 1.65}\n",
      "{'loss': 0.0658, 'learning_rate': 0.00013603076116403042, 'epoch': 1.66}\n",
      "{'loss': 0.0643, 'learning_rate': 0.00013568120248186663, 'epoch': 1.67}\n",
      "{'loss': 0.0647, 'learning_rate': 0.0001353316437997029, 'epoch': 1.67}\n",
      "{'loss': 0.066, 'learning_rate': 0.00013498208511753912, 'epoch': 1.68}\n",
      "{'loss': 0.0647, 'learning_rate': 0.00013463252643537533, 'epoch': 1.69}\n",
      "{'loss': 0.0682, 'learning_rate': 0.00013428296775321158, 'epoch': 1.7}\n",
      "{'loss': 0.0643, 'learning_rate': 0.00013393340907104782, 'epoch': 1.71}\n",
      "{'loss': 0.0664, 'learning_rate': 0.00013358385038888404, 'epoch': 1.72}\n",
      "{'loss': 0.0662, 'learning_rate': 0.00013323429170672028, 'epoch': 1.73}\n",
      "{'loss': 0.068, 'learning_rate': 0.0001328847330245565, 'epoch': 1.73}\n",
      "{'loss': 0.0638, 'learning_rate': 0.00013253517434239274, 'epoch': 1.74}\n",
      "{'loss': 0.0648, 'learning_rate': 0.00013218561566022896, 'epoch': 1.75}\n",
      "{'loss': 0.0634, 'learning_rate': 0.0001318360569780652, 'epoch': 1.76}\n",
      "{'loss': 0.0674, 'learning_rate': 0.00013148649829590142, 'epoch': 1.77}\n",
      "{'loss': 0.0674, 'learning_rate': 0.00013113693961373766, 'epoch': 1.78}\n",
      "{'loss': 0.0633, 'learning_rate': 0.0001307873809315739, 'epoch': 1.79}\n",
      "{'loss': 0.0635, 'learning_rate': 0.00013043782224941012, 'epoch': 1.8}\n",
      "{'loss': 0.067, 'learning_rate': 0.00013008826356724636, 'epoch': 1.8}\n",
      "{'loss': 0.0638, 'learning_rate': 0.0001297387048850826, 'epoch': 1.81}\n",
      "{'loss': 0.0659, 'learning_rate': 0.00012938914620291882, 'epoch': 1.82}\n",
      "{'loss': 0.0683, 'learning_rate': 0.00012903958752075504, 'epoch': 1.83}\n",
      "{'loss': 0.0669, 'learning_rate': 0.00012869002883859128, 'epoch': 1.84}\n",
      "{'loss': 0.0673, 'learning_rate': 0.00012834047015642752, 'epoch': 1.85}\n",
      "{'loss': 0.0703, 'learning_rate': 0.00012799091147426374, 'epoch': 1.86}\n",
      "{'loss': 0.0625, 'learning_rate': 0.00012764135279209998, 'epoch': 1.86}\n",
      "{'loss': 0.0659, 'learning_rate': 0.00012729179410993623, 'epoch': 1.87}\n",
      "{'loss': 0.0637, 'learning_rate': 0.00012694223542777244, 'epoch': 1.88}\n",
      "{'loss': 0.065, 'learning_rate': 0.00012659267674560869, 'epoch': 1.89}\n",
      "{'loss': 0.0649, 'learning_rate': 0.0001262431180634449, 'epoch': 1.9}\n",
      "{'loss': 0.065, 'learning_rate': 0.00012589355938128115, 'epoch': 1.91}\n",
      "{'loss': 0.0679, 'learning_rate': 0.0001255440006991174, 'epoch': 1.92}\n",
      "{'loss': 0.0642, 'learning_rate': 0.0001251944420169536, 'epoch': 1.92}\n",
      "{'loss': 0.0656, 'learning_rate': 0.00012484488333478982, 'epoch': 1.93}\n",
      "{'loss': 0.0677, 'learning_rate': 0.00012449532465262606, 'epoch': 1.94}\n",
      "{'loss': 0.0614, 'learning_rate': 0.0001241457659704623, 'epoch': 1.95}\n",
      "{'loss': 0.068, 'learning_rate': 0.00012379620728829852, 'epoch': 1.96}\n",
      "{'loss': 0.0654, 'learning_rate': 0.00012344664860613474, 'epoch': 1.97}\n",
      "{'loss': 0.0642, 'learning_rate': 0.000123097089923971, 'epoch': 1.98}\n",
      "{'loss': 0.0651, 'learning_rate': 0.00012274753124180723, 'epoch': 1.98}\n",
      "{'loss': 0.0645, 'learning_rate': 0.00012239797255964344, 'epoch': 1.99}\n",
      "{'loss': 0.0638, 'learning_rate': 0.0001220484138774797, 'epoch': 2.0}\n",
      "{'loss': 0.0665, 'learning_rate': 0.00012169885519531592, 'epoch': 2.01}\n",
      "{'loss': 0.0627, 'learning_rate': 0.00012134929651315215, 'epoch': 2.02}\n",
      "{'loss': 0.0645, 'learning_rate': 0.00012099973783098839, 'epoch': 2.03}\n",
      "{'loss': 0.0619, 'learning_rate': 0.00012065017914882462, 'epoch': 2.04}\n",
      "{'loss': 0.0647, 'learning_rate': 0.00012030062046666083, 'epoch': 2.04}\n",
      "{'loss': 0.0618, 'learning_rate': 0.00011995106178449709, 'epoch': 2.05}\n",
      "{'loss': 0.0694, 'learning_rate': 0.00011960150310233331, 'epoch': 2.06}\n",
      "{'loss': 0.0635, 'learning_rate': 0.00011925194442016954, 'epoch': 2.07}\n",
      "{'loss': 0.0648, 'learning_rate': 0.00011890238573800578, 'epoch': 2.08}\n",
      "{'loss': 0.0634, 'learning_rate': 0.00011855282705584201, 'epoch': 2.09}\n",
      "{'loss': 0.0626, 'learning_rate': 0.00011820326837367823, 'epoch': 2.1}\n",
      "{'loss': 0.0634, 'learning_rate': 0.00011785370969151446, 'epoch': 2.1}\n",
      "{'loss': 0.0632, 'learning_rate': 0.0001175041510093507, 'epoch': 2.11}\n",
      "{'loss': 0.0596, 'learning_rate': 0.00011715459232718693, 'epoch': 2.12}\n",
      "{'loss': 0.0618, 'learning_rate': 0.00011680503364502316, 'epoch': 2.13}\n",
      "{'loss': 0.0602, 'learning_rate': 0.0001164554749628594, 'epoch': 2.14}\n",
      "{'loss': 0.0629, 'learning_rate': 0.00011610591628069563, 'epoch': 2.15}\n",
      "{'loss': 0.0594, 'learning_rate': 0.00011575635759853185, 'epoch': 2.16}\n",
      "{'loss': 0.0617, 'learning_rate': 0.00011540679891636809, 'epoch': 2.16}\n",
      "{'loss': 0.06, 'learning_rate': 0.00011505724023420432, 'epoch': 2.17}\n",
      "{'loss': 0.0628, 'learning_rate': 0.00011470768155204055, 'epoch': 2.18}\n",
      "{'loss': 0.0627, 'learning_rate': 0.0001143581228698768, 'epoch': 2.19}\n",
      "{'loss': 0.0629, 'learning_rate': 0.00011400856418771302, 'epoch': 2.2}\n",
      "{'loss': 0.0616, 'learning_rate': 0.00011365900550554924, 'epoch': 2.21}\n",
      "{'loss': 0.0635, 'learning_rate': 0.00011330944682338548, 'epoch': 2.22}\n",
      "{'loss': 0.0629, 'learning_rate': 0.00011295988814122171, 'epoch': 2.22}\n",
      "{'loss': 0.0646, 'learning_rate': 0.00011261032945905794, 'epoch': 2.23}\n",
      "{'loss': 0.0618, 'learning_rate': 0.00011226077077689419, 'epoch': 2.24}\n",
      "{'loss': 0.0635, 'learning_rate': 0.00011191121209473042, 'epoch': 2.25}\n",
      "{'loss': 0.0634, 'learning_rate': 0.00011156165341256663, 'epoch': 2.26}\n",
      "{'loss': 0.0634, 'learning_rate': 0.00011121209473040289, 'epoch': 2.27}\n",
      "{'loss': 0.0647, 'learning_rate': 0.0001108625360482391, 'epoch': 2.28}\n",
      "{'loss': 0.0644, 'learning_rate': 0.00011051297736607534, 'epoch': 2.28}\n",
      "{'loss': 0.065, 'learning_rate': 0.00011016341868391155, 'epoch': 2.29}\n",
      "{'loss': 0.0656, 'learning_rate': 0.00010981386000174781, 'epoch': 2.3}\n",
      "{'loss': 0.0625, 'learning_rate': 0.00010946430131958402, 'epoch': 2.31}\n",
      "{'loss': 0.0626, 'learning_rate': 0.00010911474263742025, 'epoch': 2.32}\n",
      "{'loss': 0.0627, 'learning_rate': 0.0001087651839552565, 'epoch': 2.33}\n",
      "{'loss': 0.0612, 'learning_rate': 0.00010841562527309273, 'epoch': 2.34}\n",
      "{'loss': 0.0611, 'learning_rate': 0.00010806606659092894, 'epoch': 2.34}\n",
      "{'loss': 0.0631, 'learning_rate': 0.0001077165079087652, 'epoch': 2.35}\n",
      "{'loss': 0.0633, 'learning_rate': 0.00010736694922660142, 'epoch': 2.36}\n",
      "{'loss': 0.0638, 'learning_rate': 0.00010701739054443765, 'epoch': 2.37}\n",
      "{'loss': 0.0649, 'learning_rate': 0.00010666783186227389, 'epoch': 2.38}\n",
      "{'loss': 0.063, 'learning_rate': 0.00010631827318011012, 'epoch': 2.39}\n",
      "{'loss': 0.0618, 'learning_rate': 0.00010596871449794635, 'epoch': 2.4}\n",
      "{'loss': 0.0623, 'learning_rate': 0.00010561915581578259, 'epoch': 2.4}\n",
      "{'loss': 0.0601, 'learning_rate': 0.00010526959713361881, 'epoch': 2.41}\n",
      "{'loss': 0.0573, 'learning_rate': 0.00010492003845145504, 'epoch': 2.42}\n",
      "{'loss': 0.0614, 'learning_rate': 0.00010457047976929128, 'epoch': 2.43}\n",
      "{'loss': 0.0627, 'learning_rate': 0.00010422092108712751, 'epoch': 2.44}\n",
      "{'loss': 0.0668, 'learning_rate': 0.00010387136240496374, 'epoch': 2.45}\n",
      "{'loss': 0.0638, 'learning_rate': 0.00010352180372279996, 'epoch': 2.46}\n",
      "{'loss': 0.0667, 'learning_rate': 0.0001031722450406362, 'epoch': 2.47}\n",
      "{'loss': 0.0628, 'learning_rate': 0.00010282268635847243, 'epoch': 2.47}\n",
      "{'loss': 0.0609, 'learning_rate': 0.00010247312767630866, 'epoch': 2.48}\n",
      "{'loss': 0.0617, 'learning_rate': 0.0001021235689941449, 'epoch': 2.49}\n",
      "{'loss': 0.0632, 'learning_rate': 0.00010177401031198113, 'epoch': 2.5}\n",
      "{'loss': 0.0629, 'learning_rate': 0.00010142445162981735, 'epoch': 2.51}\n",
      "{'loss': 0.0612, 'learning_rate': 0.0001010748929476536, 'epoch': 2.52}\n",
      "{'loss': 0.0619, 'learning_rate': 0.00010072533426548982, 'epoch': 2.53}\n",
      "{'loss': 0.0625, 'learning_rate': 0.00010037577558332605, 'epoch': 2.53}\n",
      "{'loss': 0.0629, 'learning_rate': 0.0001000262169011623, 'epoch': 2.54}\n",
      "{'loss': 0.0649, 'learning_rate': 9.967665821899852e-05, 'epoch': 2.55}\n",
      "{'loss': 0.0627, 'learning_rate': 9.932709953683475e-05, 'epoch': 2.56}\n",
      "{'loss': 0.0597, 'learning_rate': 9.897754085467098e-05, 'epoch': 2.57}\n",
      "{'loss': 0.0635, 'learning_rate': 9.862798217250721e-05, 'epoch': 2.58}\n",
      "{'loss': 0.0637, 'learning_rate': 9.827842349034344e-05, 'epoch': 2.59}\n",
      "{'loss': 0.064, 'learning_rate': 9.792886480817967e-05, 'epoch': 2.59}\n",
      "{'loss': 0.0631, 'learning_rate': 9.757930612601592e-05, 'epoch': 2.6}\n",
      "{'loss': 0.0629, 'learning_rate': 9.722974744385213e-05, 'epoch': 2.61}\n",
      "{'loss': 0.0605, 'learning_rate': 9.688018876168838e-05, 'epoch': 2.62}\n",
      "{'loss': 0.062, 'learning_rate': 9.65306300795246e-05, 'epoch': 2.63}\n",
      "{'loss': 0.063, 'learning_rate': 9.618107139736084e-05, 'epoch': 2.64}\n",
      "{'loss': 0.0619, 'learning_rate': 9.583151271519706e-05, 'epoch': 2.65}\n",
      "{'loss': 0.0631, 'learning_rate': 9.548195403303331e-05, 'epoch': 2.65}\n",
      "{'loss': 0.0635, 'learning_rate': 9.513239535086952e-05, 'epoch': 2.66}\n",
      "{'loss': 0.0652, 'learning_rate': 9.478283666870577e-05, 'epoch': 2.67}\n",
      "{'loss': 0.0611, 'learning_rate': 9.443327798654198e-05, 'epoch': 2.68}\n",
      "{'loss': 0.0618, 'learning_rate': 9.408371930437823e-05, 'epoch': 2.69}\n",
      "{'loss': 0.0605, 'learning_rate': 9.373416062221446e-05, 'epoch': 2.7}\n",
      "{'loss': 0.06, 'learning_rate': 9.338460194005069e-05, 'epoch': 2.71}\n",
      "{'loss': 0.061, 'learning_rate': 9.303504325788692e-05, 'epoch': 2.71}\n",
      "{'loss': 0.0613, 'learning_rate': 9.268548457572316e-05, 'epoch': 2.72}\n",
      "{'loss': 0.0626, 'learning_rate': 9.233592589355939e-05, 'epoch': 2.73}\n",
      "{'loss': 0.0601, 'learning_rate': 9.198636721139562e-05, 'epoch': 2.74}\n",
      "{'loss': 0.0604, 'learning_rate': 9.163680852923185e-05, 'epoch': 2.75}\n",
      "{'loss': 0.0617, 'learning_rate': 9.128724984706808e-05, 'epoch': 2.76}\n",
      "{'loss': 0.059, 'learning_rate': 9.093769116490432e-05, 'epoch': 2.77}\n",
      "{'loss': 0.0612, 'learning_rate': 9.058813248274054e-05, 'epoch': 2.77}\n",
      "{'loss': 0.0632, 'learning_rate': 9.023857380057678e-05, 'epoch': 2.78}\n",
      "{'loss': 0.0625, 'learning_rate': 8.988901511841301e-05, 'epoch': 2.79}\n",
      "{'loss': 0.0606, 'learning_rate': 8.953945643624924e-05, 'epoch': 2.8}\n",
      "{'loss': 0.0626, 'learning_rate': 8.918989775408547e-05, 'epoch': 2.81}\n",
      "{'loss': 0.0633, 'learning_rate': 8.884033907192171e-05, 'epoch': 2.82}\n",
      "{'loss': 0.0585, 'learning_rate': 8.849078038975793e-05, 'epoch': 2.83}\n",
      "{'loss': 0.067, 'learning_rate': 8.814122170759417e-05, 'epoch': 2.83}\n",
      "{'loss': 0.0642, 'learning_rate': 8.779166302543039e-05, 'epoch': 2.84}\n",
      "{'loss': 0.065, 'learning_rate': 8.744210434326663e-05, 'epoch': 2.85}\n",
      "{'loss': 0.0661, 'learning_rate': 8.709254566110286e-05, 'epoch': 2.86}\n",
      "{'loss': 0.0643, 'learning_rate': 8.674298697893909e-05, 'epoch': 2.87}\n",
      "{'loss': 0.0588, 'learning_rate': 8.639342829677532e-05, 'epoch': 2.88}\n",
      "{'loss': 0.0618, 'learning_rate': 8.604386961461157e-05, 'epoch': 2.89}\n",
      "{'loss': 0.0616, 'learning_rate': 8.569431093244778e-05, 'epoch': 2.89}\n",
      "{'loss': 0.0624, 'learning_rate': 8.534475225028402e-05, 'epoch': 2.9}\n",
      "{'loss': 0.0648, 'learning_rate': 8.499519356812025e-05, 'epoch': 2.91}\n",
      "{'loss': 0.0647, 'learning_rate': 8.464563488595648e-05, 'epoch': 2.92}\n",
      "{'loss': 0.0609, 'learning_rate': 8.429607620379271e-05, 'epoch': 2.93}\n",
      "{'loss': 0.0607, 'learning_rate': 8.394651752162894e-05, 'epoch': 2.94}\n",
      "{'loss': 0.0617, 'learning_rate': 8.359695883946517e-05, 'epoch': 2.95}\n",
      "{'loss': 0.0602, 'learning_rate': 8.324740015730142e-05, 'epoch': 2.95}\n",
      "{'loss': 0.0675, 'learning_rate': 8.289784147513763e-05, 'epoch': 2.96}\n",
      "{'loss': 0.0627, 'learning_rate': 8.254828279297388e-05, 'epoch': 2.97}\n",
      "{'loss': 0.0641, 'learning_rate': 8.21987241108101e-05, 'epoch': 2.98}\n",
      "{'loss': 0.062, 'learning_rate': 8.184916542864634e-05, 'epoch': 2.99}\n",
      "{'loss': 0.0602, 'learning_rate': 8.149960674648257e-05, 'epoch': 3.0}\n",
      "{'loss': 0.0631, 'learning_rate': 8.115004806431881e-05, 'epoch': 3.01}\n",
      "{'loss': 0.0633, 'learning_rate': 8.080048938215502e-05, 'epoch': 3.01}\n",
      "{'loss': 0.0616, 'learning_rate': 8.045093069999127e-05, 'epoch': 3.02}\n",
      "{'loss': 0.0618, 'learning_rate': 8.01013720178275e-05, 'epoch': 3.03}\n",
      "{'loss': 0.0599, 'learning_rate': 7.975181333566373e-05, 'epoch': 3.04}\n",
      "{'loss': 0.0641, 'learning_rate': 7.940225465349996e-05, 'epoch': 3.05}\n",
      "{'loss': 0.0602, 'learning_rate': 7.905269597133619e-05, 'epoch': 3.06}\n",
      "{'loss': 0.0617, 'learning_rate': 7.870313728917243e-05, 'epoch': 3.07}\n",
      "{'loss': 0.0624, 'learning_rate': 7.835357860700866e-05, 'epoch': 3.07}\n",
      "{'loss': 0.0616, 'learning_rate': 7.800401992484489e-05, 'epoch': 3.08}\n",
      "{'loss': 0.0638, 'learning_rate': 7.765446124268112e-05, 'epoch': 3.09}\n",
      "{'loss': 0.0616, 'learning_rate': 7.730490256051736e-05, 'epoch': 3.1}\n",
      "{'loss': 0.064, 'learning_rate': 7.695534387835358e-05, 'epoch': 3.11}\n",
      "{'loss': 0.0636, 'learning_rate': 7.660578519618982e-05, 'epoch': 3.12}\n",
      "{'loss': 0.0592, 'learning_rate': 7.625622651402604e-05, 'epoch': 3.13}\n",
      "{'loss': 0.0587, 'learning_rate': 7.590666783186228e-05, 'epoch': 3.13}\n",
      "{'loss': 0.0632, 'learning_rate': 7.555710914969851e-05, 'epoch': 3.14}\n",
      "{'loss': 0.0632, 'learning_rate': 7.520755046753474e-05, 'epoch': 3.15}\n",
      "{'loss': 0.0617, 'learning_rate': 7.485799178537097e-05, 'epoch': 3.16}\n",
      "{'loss': 0.062, 'learning_rate': 7.450843310320721e-05, 'epoch': 3.17}\n",
      "{'loss': 0.0603, 'learning_rate': 7.415887442104343e-05, 'epoch': 3.18}\n",
      "{'loss': 0.0606, 'learning_rate': 7.380931573887967e-05, 'epoch': 3.19}\n",
      "{'loss': 0.0608, 'learning_rate': 7.345975705671589e-05, 'epoch': 3.2}\n",
      "{'loss': 0.0572, 'learning_rate': 7.311019837455213e-05, 'epoch': 3.2}\n",
      "{'loss': 0.0634, 'learning_rate': 7.276063969238836e-05, 'epoch': 3.21}\n",
      "{'loss': 0.0584, 'learning_rate': 7.241108101022459e-05, 'epoch': 3.22}\n",
      "{'loss': 0.0603, 'learning_rate': 7.206152232806082e-05, 'epoch': 3.23}\n",
      "{'loss': 0.0598, 'learning_rate': 7.171196364589707e-05, 'epoch': 3.24}\n",
      "{'loss': 0.0613, 'learning_rate': 7.136240496373328e-05, 'epoch': 3.25}\n",
      "{'loss': 0.0586, 'learning_rate': 7.101284628156952e-05, 'epoch': 3.26}\n",
      "{'loss': 0.0601, 'learning_rate': 7.066328759940575e-05, 'epoch': 3.26}\n",
      "{'loss': 0.0598, 'learning_rate': 7.031372891724198e-05, 'epoch': 3.27}\n",
      "{'loss': 0.061, 'learning_rate': 6.996417023507821e-05, 'epoch': 3.28}\n",
      "{'loss': 0.0613, 'learning_rate': 6.961461155291444e-05, 'epoch': 3.29}\n",
      "{'loss': 0.0595, 'learning_rate': 6.926505287075067e-05, 'epoch': 3.3}\n",
      "{'loss': 0.0604, 'learning_rate': 6.891549418858692e-05, 'epoch': 3.31}\n",
      "{'loss': 0.058, 'learning_rate': 6.856593550642315e-05, 'epoch': 3.32}\n",
      "{'loss': 0.0629, 'learning_rate': 6.821637682425938e-05, 'epoch': 3.32}\n",
      "{'loss': 0.0619, 'learning_rate': 6.78668181420956e-05, 'epoch': 3.33}\n",
      "{'loss': 0.0597, 'learning_rate': 6.751725945993184e-05, 'epoch': 3.34}\n",
      "{'loss': 0.0619, 'learning_rate': 6.716770077776808e-05, 'epoch': 3.35}\n",
      "{'loss': 0.0623, 'learning_rate': 6.681814209560431e-05, 'epoch': 3.36}\n",
      "{'loss': 0.0639, 'learning_rate': 6.646858341344054e-05, 'epoch': 3.37}\n",
      "{'loss': 0.0653, 'learning_rate': 6.611902473127677e-05, 'epoch': 3.38}\n",
      "{'loss': 0.0586, 'learning_rate': 6.5769466049113e-05, 'epoch': 3.38}\n",
      "{'loss': 0.0627, 'learning_rate': 6.541990736694923e-05, 'epoch': 3.39}\n",
      "{'loss': 0.0594, 'learning_rate': 6.507034868478547e-05, 'epoch': 3.4}\n",
      "{'loss': 0.0613, 'learning_rate': 6.472079000262169e-05, 'epoch': 3.41}\n",
      "{'loss': 0.062, 'learning_rate': 6.437123132045793e-05, 'epoch': 3.42}\n",
      "{'loss': 0.0596, 'learning_rate': 6.402167263829416e-05, 'epoch': 3.43}\n",
      "{'loss': 0.0616, 'learning_rate': 6.367211395613039e-05, 'epoch': 3.44}\n",
      "{'loss': 0.0596, 'learning_rate': 6.332255527396662e-05, 'epoch': 3.44}\n",
      "{'loss': 0.0604, 'learning_rate': 6.297299659180285e-05, 'epoch': 3.45}\n",
      "{'loss': 0.0616, 'learning_rate': 6.262343790963908e-05, 'epoch': 3.46}\n",
      "{'loss': 0.0579, 'learning_rate': 6.227387922747532e-05, 'epoch': 3.47}\n",
      "{'loss': 0.0614, 'learning_rate': 6.192432054531154e-05, 'epoch': 3.48}\n",
      "{'loss': 0.0647, 'learning_rate': 6.157476186314778e-05, 'epoch': 3.49}\n",
      "{'loss': 0.0609, 'learning_rate': 6.122520318098401e-05, 'epoch': 3.5}\n",
      "{'loss': 0.064, 'learning_rate': 6.087564449882024e-05, 'epoch': 3.5}\n",
      "{'loss': 0.0644, 'learning_rate': 6.052608581665648e-05, 'epoch': 3.51}\n",
      "{'loss': 0.0596, 'learning_rate': 6.017652713449271e-05, 'epoch': 3.52}\n",
      "{'loss': 0.0592, 'learning_rate': 5.982696845232894e-05, 'epoch': 3.53}\n",
      "{'loss': 0.0592, 'learning_rate': 5.9477409770165174e-05, 'epoch': 3.54}\n",
      "{'loss': 0.0615, 'learning_rate': 5.9127851088001397e-05, 'epoch': 3.55}\n",
      "{'loss': 0.06, 'learning_rate': 5.877829240583763e-05, 'epoch': 3.56}\n",
      "{'loss': 0.0593, 'learning_rate': 5.842873372367387e-05, 'epoch': 3.56}\n",
      "{'loss': 0.061, 'learning_rate': 5.807917504151009e-05, 'epoch': 3.57}\n",
      "{'loss': 0.0578, 'learning_rate': 5.772961635934633e-05, 'epoch': 3.58}\n",
      "{'loss': 0.0592, 'learning_rate': 5.7380057677182565e-05, 'epoch': 3.59}\n",
      "{'loss': 0.0605, 'learning_rate': 5.703049899501879e-05, 'epoch': 3.6}\n",
      "{'loss': 0.061, 'learning_rate': 5.6680940312855025e-05, 'epoch': 3.61}\n",
      "{'loss': 0.0592, 'learning_rate': 5.633138163069126e-05, 'epoch': 3.62}\n",
      "{'loss': 0.0578, 'learning_rate': 5.5981822948527484e-05, 'epoch': 3.62}\n",
      "{'loss': 0.0622, 'learning_rate': 5.563226426636372e-05, 'epoch': 3.63}\n",
      "{'loss': 0.0657, 'learning_rate': 5.5282705584199944e-05, 'epoch': 3.64}\n",
      "{'loss': 0.0589, 'learning_rate': 5.493314690203618e-05, 'epoch': 3.65}\n",
      "{'loss': 0.0586, 'learning_rate': 5.458358821987242e-05, 'epoch': 3.66}\n",
      "{'loss': 0.0601, 'learning_rate': 5.423402953770864e-05, 'epoch': 3.67}\n",
      "{'loss': 0.0588, 'learning_rate': 5.3884470855544876e-05, 'epoch': 3.68}\n",
      "{'loss': 0.0624, 'learning_rate': 5.353491217338111e-05, 'epoch': 3.68}\n",
      "{'loss': 0.062, 'learning_rate': 5.3185353491217336e-05, 'epoch': 3.69}\n",
      "{'loss': 0.0602, 'learning_rate': 5.283579480905357e-05, 'epoch': 3.7}\n",
      "{'loss': 0.0579, 'learning_rate': 5.248623612688981e-05, 'epoch': 3.71}\n",
      "{'loss': 0.0601, 'learning_rate': 5.213667744472603e-05, 'epoch': 3.72}\n",
      "{'loss': 0.0583, 'learning_rate': 5.178711876256227e-05, 'epoch': 3.73}\n",
      "{'loss': 0.0615, 'learning_rate': 5.14375600803985e-05, 'epoch': 3.74}\n",
      "{'loss': 0.0602, 'learning_rate': 5.108800139823473e-05, 'epoch': 3.74}\n",
      "{'loss': 0.0608, 'learning_rate': 5.0738442716070964e-05, 'epoch': 3.75}\n",
      "{'loss': 0.059, 'learning_rate': 5.0388884033907194e-05, 'epoch': 3.76}\n",
      "{'loss': 0.0602, 'learning_rate': 5.0039325351743424e-05, 'epoch': 3.77}\n",
      "{'loss': 0.055, 'learning_rate': 4.968976666957966e-05, 'epoch': 3.78}\n",
      "{'loss': 0.0585, 'learning_rate': 4.934020798741589e-05, 'epoch': 3.79}\n",
      "{'loss': 0.0622, 'learning_rate': 4.8990649305252126e-05, 'epoch': 3.8}\n",
      "{'loss': 0.0611, 'learning_rate': 4.8641090623088356e-05, 'epoch': 3.8}\n",
      "{'loss': 0.0614, 'learning_rate': 4.8291531940924586e-05, 'epoch': 3.81}\n",
      "{'loss': 0.0585, 'learning_rate': 4.794197325876082e-05, 'epoch': 3.82}\n",
      "{'loss': 0.0592, 'learning_rate': 4.759241457659705e-05, 'epoch': 3.83}\n",
      "{'loss': 0.0613, 'learning_rate': 4.724285589443328e-05, 'epoch': 3.84}\n",
      "{'loss': 0.0592, 'learning_rate': 4.689329721226951e-05, 'epoch': 3.85}\n",
      "{'loss': 0.0607, 'learning_rate': 4.654373853010575e-05, 'epoch': 3.86}\n",
      "{'loss': 0.0603, 'learning_rate': 4.619417984794198e-05, 'epoch': 3.86}\n",
      "{'loss': 0.062, 'learning_rate': 4.584462116577821e-05, 'epoch': 3.87}\n",
      "{'loss': 0.0595, 'learning_rate': 4.549506248361444e-05, 'epoch': 3.88}\n",
      "{'loss': 0.0625, 'learning_rate': 4.5145503801450674e-05, 'epoch': 3.89}\n",
      "{'loss': 0.0587, 'learning_rate': 4.4795945119286903e-05, 'epoch': 3.9}\n",
      "{'loss': 0.0605, 'learning_rate': 4.444638643712313e-05, 'epoch': 3.91}\n",
      "{'loss': 0.0615, 'learning_rate': 4.409682775495936e-05, 'epoch': 3.92}\n",
      "{'loss': 0.063, 'learning_rate': 4.37472690727956e-05, 'epoch': 3.93}\n",
      "{'loss': 0.0617, 'learning_rate': 4.339771039063183e-05, 'epoch': 3.93}\n",
      "{'loss': 0.0583, 'learning_rate': 4.304815170846806e-05, 'epoch': 3.94}\n",
      "{'loss': 0.0571, 'learning_rate': 4.2698593026304295e-05, 'epoch': 3.95}\n",
      "{'loss': 0.062, 'learning_rate': 4.2349034344140525e-05, 'epoch': 3.96}\n",
      "{'loss': 0.0619, 'learning_rate': 4.1999475661976755e-05, 'epoch': 3.97}\n",
      "{'loss': 0.0597, 'learning_rate': 4.1649916979812985e-05, 'epoch': 3.98}\n",
      "{'loss': 0.0602, 'learning_rate': 4.130035829764922e-05, 'epoch': 3.99}\n",
      "{'loss': 0.0612, 'learning_rate': 4.095079961548545e-05, 'epoch': 3.99}\n",
      "{'loss': 0.061, 'learning_rate': 4.060124093332168e-05, 'epoch': 4.0}\n",
      "{'loss': 0.062, 'learning_rate': 4.025168225115791e-05, 'epoch': 4.01}\n",
      "{'loss': 0.0593, 'learning_rate': 3.990212356899415e-05, 'epoch': 4.02}\n",
      "{'loss': 0.0602, 'learning_rate': 3.9552564886830377e-05, 'epoch': 4.03}\n",
      "{'loss': 0.0586, 'learning_rate': 3.9203006204666606e-05, 'epoch': 4.04}\n",
      "{'loss': 0.0604, 'learning_rate': 3.885344752250284e-05, 'epoch': 4.05}\n",
      "{'loss': 0.0594, 'learning_rate': 3.850388884033907e-05, 'epoch': 4.05}\n",
      "{'loss': 0.0587, 'learning_rate': 3.81543301581753e-05, 'epoch': 4.06}\n",
      "{'loss': 0.0607, 'learning_rate': 3.780477147601154e-05, 'epoch': 4.07}\n",
      "{'loss': 0.0588, 'learning_rate': 3.745521279384777e-05, 'epoch': 4.08}\n",
      "{'loss': 0.0599, 'learning_rate': 3.7105654111684005e-05, 'epoch': 4.09}\n",
      "{'loss': 0.059, 'learning_rate': 3.6756095429520235e-05, 'epoch': 4.1}\n",
      "{'loss': 0.0614, 'learning_rate': 3.6406536747356464e-05, 'epoch': 4.11}\n",
      "{'loss': 0.0588, 'learning_rate': 3.60569780651927e-05, 'epoch': 4.11}\n",
      "{'loss': 0.061, 'learning_rate': 3.570741938302893e-05, 'epoch': 4.12}\n",
      "{'loss': 0.0576, 'learning_rate': 3.535786070086516e-05, 'epoch': 4.13}\n",
      "{'loss': 0.0611, 'learning_rate': 3.500830201870139e-05, 'epoch': 4.14}\n",
      "{'loss': 0.0569, 'learning_rate': 3.4658743336537627e-05, 'epoch': 4.15}\n",
      "{'loss': 0.0617, 'learning_rate': 3.4309184654373856e-05, 'epoch': 4.16}\n",
      "{'loss': 0.0601, 'learning_rate': 3.3959625972210086e-05, 'epoch': 4.17}\n",
      "{'loss': 0.0583, 'learning_rate': 3.3610067290046316e-05, 'epoch': 4.17}\n",
      "{'loss': 0.0618, 'learning_rate': 3.326050860788255e-05, 'epoch': 4.18}\n",
      "{'loss': 0.0577, 'learning_rate': 3.291094992571878e-05, 'epoch': 4.19}\n",
      "{'loss': 0.0593, 'learning_rate': 3.256139124355501e-05, 'epoch': 4.2}\n",
      "{'loss': 0.0613, 'learning_rate': 3.221183256139125e-05, 'epoch': 4.21}\n",
      "{'loss': 0.0609, 'learning_rate': 3.186227387922748e-05, 'epoch': 4.22}\n",
      "{'loss': 0.0598, 'learning_rate': 3.151271519706371e-05, 'epoch': 4.23}\n",
      "{'loss': 0.0621, 'learning_rate': 3.116315651489994e-05, 'epoch': 4.23}\n",
      "{'loss': 0.0576, 'learning_rate': 3.0813597832736174e-05, 'epoch': 4.24}\n",
      "{'loss': 0.0594, 'learning_rate': 3.0464039150572404e-05, 'epoch': 4.25}\n",
      "{'loss': 0.06, 'learning_rate': 3.0114480468408633e-05, 'epoch': 4.26}\n",
      "{'loss': 0.058, 'learning_rate': 2.9764921786244867e-05, 'epoch': 4.27}\n",
      "{'loss': 0.0603, 'learning_rate': 2.94153631040811e-05, 'epoch': 4.28}\n",
      "{'loss': 0.0598, 'learning_rate': 2.906580442191733e-05, 'epoch': 4.29}\n",
      "{'loss': 0.0634, 'learning_rate': 2.8716245739753562e-05, 'epoch': 4.29}\n",
      "{'loss': 0.06, 'learning_rate': 2.8366687057589796e-05, 'epoch': 4.3}\n",
      "{'loss': 0.0605, 'learning_rate': 2.801712837542603e-05, 'epoch': 4.31}\n",
      "{'loss': 0.0599, 'learning_rate': 2.766756969326226e-05, 'epoch': 4.32}\n",
      "{'loss': 0.0611, 'learning_rate': 2.7318011011098488e-05, 'epoch': 4.33}\n",
      "{'loss': 0.0601, 'learning_rate': 2.6968452328934725e-05, 'epoch': 4.34}\n",
      "{'loss': 0.0599, 'learning_rate': 2.6618893646770954e-05, 'epoch': 4.35}\n",
      "{'loss': 0.059, 'learning_rate': 2.6269334964607184e-05, 'epoch': 4.35}\n",
      "{'loss': 0.0599, 'learning_rate': 2.5919776282443414e-05, 'epoch': 4.36}\n",
      "{'loss': 0.0595, 'learning_rate': 2.557021760027965e-05, 'epoch': 4.37}\n",
      "{'loss': 0.0593, 'learning_rate': 2.522065891811588e-05, 'epoch': 4.38}\n",
      "{'loss': 0.0592, 'learning_rate': 2.487110023595211e-05, 'epoch': 4.39}\n",
      "{'loss': 0.0612, 'learning_rate': 2.4521541553788343e-05, 'epoch': 4.4}\n",
      "{'loss': 0.0605, 'learning_rate': 2.4171982871624573e-05, 'epoch': 4.41}\n",
      "{'loss': 0.0592, 'learning_rate': 2.3822424189460806e-05, 'epoch': 4.41}\n",
      "{'loss': 0.0609, 'learning_rate': 2.347286550729704e-05, 'epoch': 4.42}\n",
      "{'loss': 0.059, 'learning_rate': 2.312330682513327e-05, 'epoch': 4.43}\n",
      "{'loss': 0.0589, 'learning_rate': 2.2773748142969502e-05, 'epoch': 4.44}\n",
      "{'loss': 0.0593, 'learning_rate': 2.2424189460805735e-05, 'epoch': 4.45}\n",
      "{'loss': 0.0577, 'learning_rate': 2.2074630778641968e-05, 'epoch': 4.46}\n",
      "{'loss': 0.0612, 'learning_rate': 2.1725072096478198e-05, 'epoch': 4.47}\n",
      "{'loss': 0.0607, 'learning_rate': 2.137551341431443e-05, 'epoch': 4.47}\n",
      "{'loss': 0.0594, 'learning_rate': 2.102595473215066e-05, 'epoch': 4.48}\n",
      "{'loss': 0.0626, 'learning_rate': 2.0676396049986894e-05, 'epoch': 4.49}\n",
      "{'loss': 0.0581, 'learning_rate': 2.0326837367823123e-05, 'epoch': 4.5}\n",
      "{'loss': 0.0586, 'learning_rate': 1.9977278685659357e-05, 'epoch': 4.51}\n",
      "{'loss': 0.0591, 'learning_rate': 1.9627720003495586e-05, 'epoch': 4.52}\n",
      "{'loss': 0.0607, 'learning_rate': 1.927816132133182e-05, 'epoch': 4.53}\n",
      "{'loss': 0.0609, 'learning_rate': 1.892860263916805e-05, 'epoch': 4.53}\n",
      "{'loss': 0.0595, 'learning_rate': 1.8579043957004282e-05, 'epoch': 4.54}\n",
      "{'loss': 0.0588, 'learning_rate': 1.8229485274840515e-05, 'epoch': 4.55}\n",
      "{'loss': 0.0593, 'learning_rate': 1.7879926592676745e-05, 'epoch': 4.56}\n",
      "{'loss': 0.058, 'learning_rate': 1.7530367910512978e-05, 'epoch': 4.57}\n",
      "{'loss': 0.0577, 'learning_rate': 1.7180809228349208e-05, 'epoch': 4.58}\n",
      "{'loss': 0.0567, 'learning_rate': 1.683125054618544e-05, 'epoch': 4.59}\n",
      "{'loss': 0.0588, 'learning_rate': 1.6481691864021674e-05, 'epoch': 4.6}\n",
      "{'loss': 0.0587, 'learning_rate': 1.6132133181857907e-05, 'epoch': 4.6}\n",
      "{'loss': 0.0586, 'learning_rate': 1.5782574499694137e-05, 'epoch': 4.61}\n",
      "{'loss': 0.0601, 'learning_rate': 1.543301581753037e-05, 'epoch': 4.62}\n",
      "{'loss': 0.0597, 'learning_rate': 1.50834571353666e-05, 'epoch': 4.63}\n",
      "{'loss': 0.0606, 'learning_rate': 1.4733898453202833e-05, 'epoch': 4.64}\n",
      "{'loss': 0.059, 'learning_rate': 1.4384339771039063e-05, 'epoch': 4.65}\n",
      "{'loss': 0.0616, 'learning_rate': 1.4034781088875296e-05, 'epoch': 4.66}\n",
      "{'loss': 0.0582, 'learning_rate': 1.3685222406711529e-05, 'epoch': 4.66}\n",
      "{'loss': 0.0595, 'learning_rate': 1.3335663724547759e-05, 'epoch': 4.67}\n",
      "{'loss': 0.0616, 'learning_rate': 1.2986105042383992e-05, 'epoch': 4.68}\n",
      "{'loss': 0.0598, 'learning_rate': 1.2636546360220221e-05, 'epoch': 4.69}\n",
      "{'loss': 0.056, 'learning_rate': 1.2286987678056455e-05, 'epoch': 4.7}\n",
      "{'loss': 0.0611, 'learning_rate': 1.1937428995892686e-05, 'epoch': 4.71}\n",
      "{'loss': 0.0573, 'learning_rate': 1.1587870313728917e-05, 'epoch': 4.72}\n",
      "{'loss': 0.0597, 'learning_rate': 1.123831163156515e-05, 'epoch': 4.72}\n",
      "{'loss': 0.0565, 'learning_rate': 1.0888752949401382e-05, 'epoch': 4.73}\n",
      "{'loss': 0.0595, 'learning_rate': 1.0539194267237613e-05, 'epoch': 4.74}\n",
      "{'loss': 0.0597, 'learning_rate': 1.0189635585073845e-05, 'epoch': 4.75}\n",
      "{'loss': 0.0599, 'learning_rate': 9.840076902910076e-06, 'epoch': 4.76}\n",
      "{'loss': 0.0585, 'learning_rate': 9.490518220746308e-06, 'epoch': 4.77}\n",
      "{'loss': 0.0585, 'learning_rate': 9.14095953858254e-06, 'epoch': 4.78}\n",
      "{'loss': 0.0594, 'learning_rate': 8.791400856418772e-06, 'epoch': 4.78}\n",
      "{'loss': 0.0592, 'learning_rate': 8.441842174255004e-06, 'epoch': 4.79}\n",
      "{'loss': 0.0577, 'learning_rate': 8.092283492091235e-06, 'epoch': 4.8}\n",
      "{'loss': 0.058, 'learning_rate': 7.742724809927466e-06, 'epoch': 4.81}\n",
      "{'loss': 0.0577, 'learning_rate': 7.393166127763698e-06, 'epoch': 4.82}\n",
      "{'loss': 0.0589, 'learning_rate': 7.04360744559993e-06, 'epoch': 4.83}\n",
      "{'loss': 0.0594, 'learning_rate': 6.6940487634361616e-06, 'epoch': 4.84}\n",
      "{'loss': 0.0605, 'learning_rate': 6.344490081272395e-06, 'epoch': 4.84}\n",
      "{'loss': 0.0597, 'learning_rate': 5.994931399108625e-06, 'epoch': 4.85}\n",
      "{'loss': 0.0585, 'learning_rate': 5.6453727169448575e-06, 'epoch': 4.86}\n",
      "{'loss': 0.0561, 'learning_rate': 5.29581403478109e-06, 'epoch': 4.87}\n",
      "{'loss': 0.06, 'learning_rate': 4.946255352617321e-06, 'epoch': 4.88}\n",
      "{'loss': 0.0596, 'learning_rate': 4.596696670453553e-06, 'epoch': 4.89}\n",
      "{'loss': 0.0598, 'learning_rate': 4.247137988289784e-06, 'epoch': 4.9}\n",
      "{'loss': 0.0589, 'learning_rate': 3.897579306126016e-06, 'epoch': 4.9}\n",
      "{'loss': 0.062, 'learning_rate': 3.5480206239622478e-06, 'epoch': 4.91}\n",
      "{'loss': 0.0575, 'learning_rate': 3.198461941798479e-06, 'epoch': 4.92}\n",
      "{'loss': 0.0584, 'learning_rate': 2.8489032596347115e-06, 'epoch': 4.93}\n",
      "{'loss': 0.0596, 'learning_rate': 2.499344577470943e-06, 'epoch': 4.94}\n",
      "{'loss': 0.0603, 'learning_rate': 2.1497858953071747e-06, 'epoch': 4.95}\n",
      "{'loss': 0.0579, 'learning_rate': 1.8002272131434066e-06, 'epoch': 4.96}\n",
      "{'loss': 0.0584, 'learning_rate': 1.4506685309796382e-06, 'epoch': 4.96}\n",
      "{'loss': 0.0557, 'learning_rate': 1.10110984881587e-06, 'epoch': 4.97}\n",
      "{'loss': 0.0606, 'learning_rate': 7.515511666521018e-07, 'epoch': 4.98}\n",
      "{'loss': 0.0601, 'learning_rate': 4.0199248448833347e-07, 'epoch': 4.99}\n",
      "{'loss': 0.0563, 'learning_rate': 5.243380232456523e-08, 'epoch': 5.0}\n",
      "{'train_runtime': 49310.7754, 'train_samples_per_second': 4.722, 'train_steps_per_second': 1.181, 'train_loss': 0.134495056195633, 'epoch': 5.0}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=58215, training_loss=0.134495056195633, metrics={'train_runtime': 49310.7754, 'train_samples_per_second': 4.722, 'train_steps_per_second': 1.181, 'train_loss': 0.134495056195633, 'epoch': 5.0})"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: ERROR Error while calling W&B API: graphql: panic occurred: runtime error: invalid memory address or nil pointer dereference (<Response [500]>)\n",
      "wandb: ERROR Error while calling W&B API: graphql: panic occurred: runtime error: invalid memory address or nil pointer dereference (<Response [500]>)\n",
      "wandb: ERROR Error while calling W&B API: graphql: panic occurred: runtime error: invalid memory address or nil pointer dereference (<Response [500]>)\n",
      "wandb: ERROR Error while calling W&B API: graphql: panic occurred: runtime error: invalid memory address or nil pointer dereference (<Response [500]>)\n",
      "wandb: ERROR Error while calling W&B API: graphql: panic occurred: runtime error: invalid memory address or nil pointer dereference (<Response [500]>)\n",
      "wandb: ERROR Error while calling W&B API: graphql: panic occurred: runtime error: invalid memory address or nil pointer dereference (<Response [500]>)\n",
      "wandb: ERROR Error while calling W&B API: graphql: panic occurred: runtime error: invalid memory address or nil pointer dereference (<Response [500]>)\n",
      "wandb: ERROR Error while calling W&B API: graphql: panic occurred: runtime error: invalid memory address or nil pointer dereference (<Response [500]>)\n",
      "wandb: ERROR Error while calling W&B API: graphql: panic occurred: runtime error: invalid memory address or nil pointer dereference (<Response [500]>)\n",
      "wandb: ERROR Error while calling W&B API: graphql: panic occurred: runtime error: invalid memory address or nil pointer dereference (<Response [500]>)\n"
     ]
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>train/epoch</td><td></td></tr><tr><td>train/global_step</td><td></td></tr><tr><td>train/learning_rate</td><td></td></tr><tr><td>train/loss</td><td></td></tr><tr><td>train/total_flos</td><td></td></tr><tr><td>train/train_loss</td><td></td></tr><tr><td>train/train_runtime</td><td></td></tr><tr><td>train/train_samples_per_second</td><td></td></tr><tr><td>train/train_steps_per_second</td><td></td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>train/epoch</td><td>5.0</td></tr><tr><td>train/global_step</td><td>58215</td></tr><tr><td>train/learning_rate</td><td>0.0</td></tr><tr><td>train/loss</td><td>0.0563</td></tr><tr><td>train/total_flos</td><td>1.2168631222272e+17</td></tr><tr><td>train/train_loss</td><td>0.1345</td></tr><tr><td>train/train_runtime</td><td>49310.7754</td></tr><tr><td>train/train_samples_per_second</td><td>4.722</td></tr><tr><td>train/train_steps_per_second</td><td>1.181</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">GPT2-short_relation_DocRED-w-ner-5epochs</strong> at: <a href='https://wandb.ai/tian1995/GPT2-intermediate/runs/5sxfyy02' target=\"_blank\">https://wandb.ai/tian1995/GPT2-intermediate/runs/5sxfyy02</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20230925_032334-5sxfyy02/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "('DocRED/GPT_w_ner_short_relation/tokenizer/tokenizer_config.json',\n",
       " 'DocRED/GPT_w_ner_short_relation/tokenizer/special_tokens_map.json',\n",
       " 'DocRED/GPT_w_ner_short_relation/tokenizer/vocab.json',\n",
       " 'DocRED/GPT_w_ner_short_relation/tokenizer/merges.txt',\n",
       " 'DocRED/GPT_w_ner_short_relation/tokenizer/added_tokens.json')"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wandb.finish()\n",
    "trainer.save_model(\"DocRED/GPT_w_ner_short_relation\")\n",
    "\n",
    "# save the tokenizer\n",
    "tokenizer.save_pretrained(\"DocRED/GPT_w_ner_short_relation/tokenizer\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForCausalLM\n",
    "\n",
    "checkpoint = \"DocRED/GPT_w_ner_short_relation\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import GPT2Tokenizer\n",
    "tokenizer = GPT2Tokenizer.from_pretrained(\"DocRED/GPT_w_ner_short_relation/tokenizer\")\n",
    "model = AutoModelForCausalLM.from_pretrained(checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['<|startoftext|>',\n",
       " '<|endoftext|>',\n",
       " '<|pad|>',\n",
       " '[learn1]',\n",
       " '[learn2]',\n",
       " '[learn3]',\n",
       " '[learn4]',\n",
       " '[learn5]',\n",
       " '[learn6]']"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# output all of the special tokens in the tokenizer\n",
    "tokenizer.all_special_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tian/mambaforge/envs/BioRED/lib/python3.10/site-packages/transformers/generation/utils.py:1255: UserWarning: You have modified the pretrained model configuration to control generation. This is a deprecated strategy to control generation and will be removed soon, in a future version. Please use a generation configuration file (see https://huggingface.co/docs/transformers/main_classes/text_generation)\n",
      "  warnings.warn(\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tweet text : @HondaCustSvc Your customer service has been horrible during the recall process. I will never purchase a Honda again. <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> [learn2] entity : honda cravo, type : miscellaneous ; entity : the recall, type\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "model.eval()\n",
    "model.to(\"cpu\")\n",
    "# inputs = tokenizer(\"Tweet text : @HondaCustSvc Your customer service has been horrible during the recall process. I will never purchase a Honda again. [learn1] [learn2] entity :\", return_tensors=\"pt\")\n",
    "\n",
    "inputs = tokenizer(\"Tweet text : @HondaCustSvc Your customer service has been horrible during the recall process. I will never purchase a Honda again.\", return_tensors=\"pt\", padding='max_length', max_length=1000)\n",
    "\n",
    "with torch.no_grad():\n",
    "    outputs = model.generate(input_ids=inputs[\"input_ids\"], max_new_tokens=20, pad_token_id=tokenizer.pad_token_id, eos_token_id=tokenizer.eos_token_id)\n",
    "    print(tokenizer.batch_decode(outputs.detach().cpu().numpy(), skip_special_tokens=False)[0])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "test data pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "from datasets import Dataset\n",
    "\n",
    "ner = 1\n",
    "\n",
    "test_relation_dict = {}\n",
    "if ner:\n",
    "    with open('DocRED/data/bi-sent-pre-process_test.json') as f:\n",
    "        test_relation_dict = json.load(f)\n",
    "\n",
    "    test_dataset = Dataset.from_dict(\n",
    "        {\n",
    "            'text': test_relation_dict['text'],\n",
    "            'entity': test_relation_dict['entity'],\n",
    "            'relation': test_relation_dict['relation']\n",
    "        }\n",
    "    )\n",
    "\n",
    "else:\n",
    "    pass\n",
    "\n",
    "\n",
    "dataset = test_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 269/269 [00:04<00:00, 66.03it/s]\n"
     ]
    }
   ],
   "source": [
    "def pro_processing_ner(example, tokenizer, padding=True):\n",
    "    texts = example['text']\n",
    "    input_texts = []\n",
    "    for index in range(len(texts)):\n",
    "        # entity extraction and NER\n",
    "        text = texts[index].lower().strip() + \" [learn1] [learn2]\"\n",
    "        for entity in example['entity'][index]:\n",
    "            text = text + \" entity : \" + entity[0] + \" , type : \" + entity[1] + \" ;\"\n",
    "        text = text[:-1] + \".\"\n",
    "        # print(\"1\")\n",
    "        # add relation classificaiton\n",
    "        text = text.lower().strip() + \" [learn3] [learn4]\"\n",
    "        for relation_type, relation_pair in example['relation'][index].items():\n",
    "            if relation_pair:\n",
    "                text_w_relation = text + \" for the relation \" + relation_type + \" : 1 .\"\n",
    "                text_w_relation = text_w_relation.lower().strip() + \" [learn5] [learn6]\"\n",
    "                text_w_relation = text_w_relation + \" and the entity for the relation \" + relation_type + \" are :\"\n",
    "                for pair in relation_pair:\n",
    "                    text_w_relation = text_w_relation + \" head entity: \" + pair[0] + \" , tail entity: \" + pair[1] + \";\"\n",
    "                text_w_relation = text_w_relation[:-1] + \".\" + tokenizer.eos_token\n",
    "                input_texts.append(text_w_relation)\n",
    "\n",
    "            else:\n",
    "                text_w_relation = text + \" for the relation \" + relation_type + \" : 0 .\" + tokenizer.eos_token\n",
    "                input_texts.append(text_w_relation)\n",
    "\n",
    "    return {\n",
    "        'input_ids': input_texts\n",
    "        }\n",
    "\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "output = {\"input_texts\": []}\n",
    "\n",
    "for i in tqdm(range(0, len(dataset), 30)):\n",
    "    result = pro_processing_ner(dataset[i:i+30], tokenizer)\n",
    "    output[\"input_texts\"].extend(result[\"input_ids\"])\n",
    "\n",
    "\n",
    "from datasets import Dataset\n",
    "\n",
    "input_text_dataset = Dataset.from_dict(\n",
    "    {\n",
    "        'input_texts': output['input_texts'],\n",
    "    }\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "566574b88f014cc0b86f939b4e7c9d4a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/773472 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5ee49c96878e4482b0f6d3ae0761713e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/9 shards):   0%|          | 0/773472 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokenized_dataset = input_text_dataset.map(lambda example: tokenizer(example['input_texts'], padding='max_length', truncation=True, max_length=1024, pad_to_max_length=True), batched=True)\n",
    "\n",
    "tokenized_dataset.remove_columns('input_texts')\n",
    "\n",
    "tokenized_dataset.save_to_disk('DocRED/GPT_w_ner_short_relation/test_data_ner_short_relation')\n",
    "# with open('DocRED/data/train_ner_short_relation.json', 'w') as f:\n",
    "#     json.dump(tokenized_dataset, f)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "randomly select test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import Dataset\n",
    "\n",
    "tokenized_test_dataset = Dataset.load_from_disk('DocRED/GPT_w_ner_short_relation/test_data_ner_short_relation')\n",
    "tokenized_test_dataset = tokenized_test_dataset.remove_columns('input_texts')\n",
    "\n",
    "tokenized_test_dataset.set_format(type='torch', columns=['input_ids', 'attention_mask'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_texts': 'besides digital terrestrial transmission , it is available on the subscription - based encrypted services of nova and cosmote tv . skai tv is also a member of digea , a consortium of private television networks introducing digital terrestrial transmission in greece . [learn1] [learn2] entity : nova , type : organization ; entity : cosmote tv , type : organization ; entity : skai tv , type : organization ; entity : digea , type : organization ; entity : greece , type : location . [learn3] [learn4] for the relation applies to jurisdiction : 0 .<|endoftext|>'}"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_text_dataset[288]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8057.0"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tokenized_dataset) / 96"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "index:  242016  -  242111\n",
      "index:  2521\n",
      "durgada is a rural village in gollaprolu mandal, east godavari district, andhra pradesh, india. the village was formerly known as durga ooda, durga vaahini. [learn1] [learn2] entity : durgada, type : location ; entity : gollaprolu, type : location ; entity : east godavari, type : location ; entity : andhra pradesh, type : location ; entity : india, type : location ; entity : durga ooda, type : location ; entity : durga vaahini, type : location. [learn3] [learn4] for the relation applies to jurisdiction : 0.<|endoftext|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|>\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8ad1c87d42ca4b53ab300aedf7d68145",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/96 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# random sample 1 example from the test_dataset\n",
    "import random\n",
    "# have a random seed\n",
    "random.seed(60)\n",
    "\n",
    "random_test_index = random.randint(0, 8056)\n",
    "print(\"index: \", random_test_index * 96, \" - \", random_test_index * 96 + 95)\n",
    "print(\"index: \", random_test_index)\n",
    "print(tokenizer.decode(tokenized_test_dataset[random_test_index * 96]['input_ids']))\n",
    "\n",
    "# output the length of tokenized_test_dataset[index]['input_ids'] except the padding tokens. the tokenized_test_dataset[index]['input_ids'] is tensor\n",
    "\n",
    "input_ids_lists = tokenized_test_dataset[random_test_index * 96 : random_test_index * 96 + 96]['input_ids'].tolist()\n",
    "\n",
    "all_actually_inputs = {\"learn2_index\": [], \"valid_length\": []}\n",
    "all_gold_truths = []\n",
    "\n",
    "for input_ids_list in tqdm(input_ids_lists):\n",
    "    \n",
    "    valid_length = len(input_ids_list) - input_ids_list.count(tokenizer.pad_token_id)\n",
    "\n",
    "    # print(tokenizer.decode(tokenized_test_dataset[index]['input_ids'][:valid_length]))\n",
    "\n",
    "    # generate a lower triangle matrix of 1s with the shape is (valid_length, valid_length), using torch\n",
    "\n",
    "    low_triangle_matrix = torch.tril(torch.ones((valid_length, valid_length), dtype=torch.long))\n",
    "\n",
    "    # find the index of the token id of \"[learn2]\" in the tokenized_test_dataset[index]['input_ids'] tensor\n",
    "\n",
    "    learn2_index = input_ids_list.index(tokenizer.convert_tokens_to_ids(\"[learn2]\"))\n",
    "\n",
    "    # have a vector to store the token of okenized_test_dataset[index]['input_ids'][learn2_index + 1:valid_length]\n",
    "\n",
    "    gold_truth = input_ids_list[learn2_index + 1:valid_length]\n",
    "\n",
    "    all_actually_inputs[\"learn2_index\"].append(learn2_index)\n",
    "\n",
    "    all_actually_inputs[\"valid_length\"].append(valid_length)\n",
    "\n",
    "    all_gold_truths.append(gold_truth)\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "quick inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1  / 96\n",
      "2  / 96\n",
      "3  / 96\n",
      "4  / 96\n",
      "5  / 96\n",
      "6  / 96\n",
      "7  / 96\n",
      "8  / 96\n",
      "9  / 96\n",
      "10  / 96\n",
      "11  / 96\n",
      "12  / 96\n",
      "13  / 96\n",
      "14  / 96\n",
      "15  / 96\n",
      "16  / 96\n",
      "17  / 96\n",
      "18  / 96\n",
      "19  / 96\n",
      "20  / 96\n",
      "21  / 96\n",
      "22  / 96\n",
      "23  / 96\n",
      "24  / 96\n",
      "25  / 96\n",
      "26  / 96\n",
      "27  / 96\n",
      "28  / 96\n",
      "29  / 96\n",
      "30  / 96\n",
      "31  / 96\n",
      "32  / 96\n",
      "33  / 96\n",
      "34  / 96\n",
      "35  / 96\n",
      "36  / 96\n",
      "37  / 96\n",
      "38  / 96\n",
      "39  / 96\n",
      "40  / 96\n",
      "41  / 96\n",
      "42  / 96\n",
      "43  / 96\n",
      "44  / 96\n",
      "45  / 96\n",
      "46  / 96\n",
      "47  / 96\n",
      "48  / 96\n",
      "49  / 96\n",
      "50  / 96\n",
      "51  / 96\n",
      "52  / 96\n",
      "53  / 96\n",
      "54  / 96\n",
      "55  / 96\n",
      "56  / 96\n",
      "57  / 96\n",
      "58  / 96\n",
      "59  / 96\n",
      "60  / 96\n",
      "61  / 96\n",
      "62  / 96\n",
      "63  / 96\n",
      "64  / 96\n",
      "65  / 96\n",
      "66  / 96\n",
      "67  / 96\n",
      "68  / 96\n",
      "69  / 96\n",
      "70  / 96\n",
      "71  / 96\n",
      "72  / 96\n",
      "73  / 96\n",
      "74  / 96\n",
      "75  / 96\n",
      "76  / 96\n",
      "77  / 96\n",
      "78  / 96\n",
      "79  / 96\n",
      "80  / 96\n",
      "81  / 96\n",
      "82  / 96\n",
      "83  / 96\n",
      "84  / 96\n",
      "85  / 96\n",
      "86  / 96\n",
      "87  / 96\n",
      "88  / 96\n",
      "89  / 96\n",
      "90  / 96\n",
      "91  / 96\n",
      "92  / 96\n",
      "93  / 96\n",
      "94  / 96\n",
      "95  / 96\n",
      "96  / 96\n"
     ]
    }
   ],
   "source": [
    "from tqdm.notebook import trange, tqdm\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "model.eval()\n",
    "outputs = []\n",
    "model.to(\"cuda\")\n",
    "\n",
    "batch_output = []\n",
    "all_batch_output = []\n",
    "all_accuracy = []\n",
    "\n",
    "\n",
    "with torch.no_grad():\n",
    "    # feed the actually_input to the model by 10 examples each time\n",
    "    for input_index, input_ids_list in enumerate(input_ids_lists):\n",
    "        print(input_index + 1, \" / 96\")\n",
    "        for i in range(all_actually_inputs['learn2_index'][input_index] + 1, all_actually_inputs['valid_length'][input_index]):\n",
    "            output = model(input_ids=torch.tensor(input_ids_list[:i]).to(\"cuda\"))\n",
    "            current_output = np.array(output['logits'].cpu())\n",
    "            max_index = np.argmax(current_output[-1, :], axis=0)\n",
    "            batch_output.append(max_index)\n",
    "            # break\n",
    "        if len(batch_output) == len(all_gold_truths[input_index]):\n",
    "            accuracy = sum(np.array(batch_output) == np.array(all_gold_truths[input_index])) / len(batch_output)\n",
    "            all_accuracy.append(accuracy)\n",
    "            all_batch_output.append(batch_output)\n",
    "            batch_output = []\n",
    "        else:\n",
    "            print(\"error\")\n",
    "        \n",
    "    # print(tokenizer.batch_decode(max_index, skip_special_tokens=False)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.768768807756679\n"
     ]
    }
   ],
   "source": [
    "# have the average accuracy\n",
    "if len(all_accuracy) == 96:\n",
    "\n",
    "    print(sum(all_accuracy) / len(all_accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {},
   "outputs": [],
   "source": [
    "# have the max accuracy and the index of the max accuracy\n",
    "\n",
    "max_accuracy = max(all_accuracy)\n",
    "max_accuracy_index = all_accuracy.index(max_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 :  entity\n",
      "1 :   :\n",
      "4 :  ada\n",
      "5 :  ,\n",
      "6 :   type\n",
      "7 :   :\n",
      "8 :   location\n",
      "9 :   ;\n",
      "10 :   entity\n",
      "11 :   :\n",
      "13 :  ll\n",
      "18 :   type\n",
      "19 :   :\n",
      "20 :   location\n",
      "21 :   ;\n",
      "22 :   entity\n",
      "23 :   :\n",
      "24 :   east\n",
      "25 :   god\n",
      "28 :  ,\n",
      "29 :   type\n",
      "30 :   :\n",
      "31 :   location\n",
      "32 :   ;\n",
      "33 :   entity\n",
      "34 :   :\n",
      "36 :  hra\n",
      "38 :  adesh\n",
      "40 :   type\n",
      "41 :   :\n",
      "42 :   location\n",
      "43 :   ;\n",
      "44 :   entity\n",
      "45 :   :\n",
      "47 :  ia\n",
      "48 :  ,\n",
      "49 :   type\n",
      "50 :   :\n",
      "51 :   location\n",
      "52 :   ;\n",
      "53 :   entity\n",
      "54 :   :\n",
      "55 :   d\n",
      "57 :   o\n",
      "59 :  ,\n",
      "60 :   type\n",
      "61 :   :\n",
      "62 :   location\n",
      "64 :   entity\n",
      "65 :   :\n",
      "66 :   d\n",
      "68 :   v\n",
      "70 :  ini\n",
      "71 :  ,\n",
      "72 :   type\n",
      "73 :   :\n",
      "75 :  .\n",
      "76 :  [learn3]\n",
      "77 :  [learn4]\n",
      "78 :  for\n",
      "79 :   the\n",
      "80 :   relation\n",
      "81 :   member\n",
      "82 :   of\n",
      "83 :   sports\n",
      "84 :   team\n",
      "85 :   :\n",
      "86 :   0\n",
      "87 :  .\n",
      "88 :  <|endoftext|>\n"
     ]
    }
   ],
   "source": [
    "# output the index of the correct prediction\n",
    "\n",
    "for index, item in enumerate(zip(all_batch_output[max_accuracy_index], all_gold_truths[max_accuracy_index])):\n",
    "    if item[0] == item[1]:\n",
    "        print(index, \": \", tokenizer.decode(item[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'durgada is a rural village in gollaprolu mandal, east godavari district, andhra pradesh, india. the village was formerly known as durga ooda, durga vaahini. [learn1] [learn2] entity : durgada, type : location ; entity : gollaprolu, type : location ; entity : east godavari, type : location ; entity : andhra pradesh, type : location ; entity : india, type : location ; entity : durga ooda, type : location ; entity : durga vaahini, type : location. [learn3] [learn4] for the relation member of sports team : 0.<|endoftext|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|>'"
      ]
     },
     "execution_count": 285,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(input_ids_lists[max_accuracy_index])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "whole inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "def for_the_relation (index, input,tokenizer=tokenizer):\n",
    "    rel_info = {}\n",
    "    with open('DocRED/data/relation-index.json') as f:\n",
    "        rel_info = json.load(f)\n",
    "    rel_info_list = [relation for relation in rel_info.keys()]\n",
    "    relation_input = \"for the relation \" + rel_info_list[index].lower() + \" : \"\n",
    "    tokenized_relation_input = tokenizer.encode(relation_input, add_special_tokens=False, return_tensors=\"pt\")\n",
    "    # print(\"before relation classification: \", tokenizer.decode(input))\n",
    "    return (torch.cat((input, tokenized_relation_input[0]), dim=0))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1  / 96\n",
      "zero_possibility:  14.324283\n",
      "one_possibility:  20.368336\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_193756/1603700701.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  input_ids = torch.cat((input_ids, torch.tensor(tokenizer.encode(next_input, add_special_tokens=False, return_tensors=\"pt\")[0]).to(\"cuda\")), dim=0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "entity : italy, type : location ; entity : greece, type : location ; entity : st. louis, type : location ; entity : india, type : location ; entity : daimaru, type : location ; entity : cowichan lake, type : location ; entity : kahlo, type : head of government. [learn3] [learn4] for the relation applies to jurisdiction : 1. [learn5] [learn6] and the entity for the relation applies to jurisdiction are : head entity: italy, tail entity: india; head entity: italy, tail entity: india; head entity: italy, tail entity: india; head entity: italy, tail entity: india; head entity: italy, tail entity: india; head entity: italy, tail entity: india; head entity: italy, tail entity: india; head entity: italy, tail entity: india; head entity: italy, tail entity: india; head entity: italy, tail entity: india; head entity: italy, tail entity: india.<|endoftext|>\n",
      "2  / 96\n",
      "zero_possibility:  -3.2559252\n",
      "one_possibility:  3.9837303\n",
      "entity : italy, type : location ; entity : greece, type : location ; entity : st. louis, type : location ; entity : india, type : location ; entity : daimaru, type : location ; entity : cowichan lake, type : location ; entity : kahlo, type : head of government. [learn3] [learn4] for the relation author : 1. [learn5] [learn6] and the entity for the relation author are : head entity: italy, tail entity: wilson; head entity: italy, tail entity: wilson; head entity: italy, tail entity: wilson; head entity: italy, tail entity: wilson; head entity: italy, tail entity: wilson.<|endoftext|>\n",
      "3  / 96\n",
      "zero_possibility:  12.269523\n",
      "one_possibility:  15.097278\n",
      "entity : italy, type : location ; entity : greece, type : location ; entity : st. louis, type : location ; entity : india, type : location ; entity : daimaru, type : location ; entity : cowichan lake, type : location ; entity : kahlo, type : head of government. [learn3] [learn4] for the relation award received : 1. [learn5] [learn6] and the entity for the relation award received are : head entity: italy, tail entity: godflesh; head entity: italy, tail entity: godflesh; head entity: italy, tail entity: godflesh; head entity: italy, tail entity: godflesh; head entity: italy, tail entity: godflesh; head entity: italy, tail entity: godflesh; head entity: italy, tail entity: godflesh; head entity: italy, tail entity: godflesh.<|endoftext|>\n",
      "4  / 96\n",
      "zero_possibility:  16.715754\n",
      "one_possibility:  18.449326\n",
      "entity : italy, type : location ; entity : greece, type : location ; entity : st. louis, type : location ; entity : india, type : location ; entity : daimaru, type : location ; entity : cowichan lake, type : location ; entity : kahlo, type : head of government. [learn3] [learn4] for the relation basin country : 1. [learn5] [learn6] and the entity for the relation basin country are : head entity: british columbia, tail entity: canada; head entity: british columbia, tail entity: canada.<|endoftext|>\n",
      "5  / 96\n",
      "zero_possibility:  12.448668\n",
      "one_possibility:  14.537892\n",
      "entity : italy, type : location ; entity : greece, type : location ; entity : st. louis, type : location ; entity : india, type : location ; entity : daimaru, type : location ; entity : cowichan lake, type : location ; entity : kahlo, type : head of government. [learn3] [learn4] for the relation capital : 1. [learn5] [learn6] and the entity for the relation capital are : head entity: bharatiya, tail entity: india; head entity: cowichan lake, tail entity: india; head entity: cowichan lake, tail entity: india; head entity: cowichan lake, tail entity: india; head entity: cowichan lake, tail entity: india; head entity: cowichan lake, tail entity: india; head entity: cowichan lake, tail entity: india; head entity: cowichan lake, tail entity: india; head entity: cowichan lake, tail entity: india; head entity: cowichan lake, tail entity: india; head entity: cowichan lake, tail entity: india; head entity: cowichan lake, tail entity: india; head entity: cowichan lake, tail entity: india; head entity: cowichan lake, tail entity: india; head entity: cowichan lake, tail entity: india; head entity: cowichan lake, tail entity: india; head entity: cowichan lake, tail entity: india; head entity: cowichan lake, tail entity: india; head entity: cowichan lake, tail entity: india; head entity: cowichan lake, tail entity: india; head entity: cowichan lake, tail entity: india; head entity: cowichan lake, tail entity: india; head entity: cowichan lake, tail entity: india; head entity: cowichan lake, tail entity: india; head entity: cowichan lake, tail entity: india; head entity: cowichan lake, tail entity: india; head entity: cowichan lake, tail entity: india; head entity: cowichan lake, tail entity: india.<|endoftext|>\n",
      "6  / 96\n",
      "zero_possibility:  12.983972\n",
      "one_possibility:  15.413063\n",
      "entity : italy, type : location ; entity : greece, type : location ; entity : st. louis, type : location ; entity : india, type : location ; entity : daimaru, type : location ; entity : cowichan lake, type : location ; entity : kahlo, type : head of government. [learn3] [learn4] for the relation capital of : 1. [learn5] [learn6] and the entity for the relation capital of are : head entity: bharatiya, tail entity: india; head entity: cowichan lake, tail entity: india; head entity: cowichan lake, tail entity: india; head entity: cowichan lake, tail entity: india; head entity: cowichan lake, tail entity: india; head entity: cowichan lake, tail entity: india; head entity: cowichan lake, tail entity: india; head entity: cowichan lake, tail entity: india; head entity: cowichan lake, tail entity: india; head entity: cowichan lake, tail entity: india; head entity: cowichan lake, tail entity: india; head entity: cowichan lake, tail entity: india; head entity: cowichan lake, tail entity: india; head entity: cowichan lake, tail entity: india; head entity: cowichan lake, tail entity: india; head entity: cowichan lake, tail entity: india; head entity: cowichan lake, tail entity: india; head entity: cowichan lake, tail entity: india; head entity: cowichan lake, tail entity: india; head entity: cowichan lake, tail entity: india; head entity: cowichan lake, tail entity: india; head entity: cowichan lake, tail entity: india; head entity: cowichan lake, tail entity: india; head entity: cowichan lake, tail entity: india; head entity: cowichan lake, tail entity: india; head entity: cowichan lake, tail entity: india; head entity: cowichan lake, tail entity: india.<|endoftext|>\n",
      "7  / 96\n",
      "zero_possibility:  16.708027\n",
      "one_possibility:  25.658287\n",
      "entity : italy, type : location ; entity : greece, type : location ; entity : st. louis, type : location ; entity : india, type : location ; entity : daimaru, type : location ; entity : cowichan lake, type : location ; entity : kahlo, type : head of government. [learn3] [learn4] for the relation cast member : 1. [learn5] [learn6] and the entity for the relation cast member are : head entity: italy, tail entity: cowichan lake; head entity: italy, tail entity: cowichan lake; head entity: italy, tail entity: cowichan lake.<|endoftext|>\n",
      "8  / 96\n",
      "zero_possibility:  1.0361074\n",
      "one_possibility:  6.634903\n",
      "entity : italy, type : location ; entity : greece, type : location ; entity : st. louis, type : location ; entity : india, type : location ; entity : daimaru, type : location ; entity : cowichan lake, type : location ; entity : kahlo, type : head of government. [learn3] [learn4] for the relation chairperson : 1. [learn5] [learn6] and the entity for the relation chairperson are : head entity: luigi balocchi, tail entity: cowichan lake; head entity: bharati, tail entity: cowichan lake.<|endoftext|>\n",
      "9  / 96\n",
      "zero_possibility:  17.563128\n",
      "one_possibility:  23.008877\n",
      "entity : italy, type : location ; entity : greece, type : location ; entity : st. louis, type : location ; entity : india, type : location ; entity : daimaru, type : location ; entity : cowichan lake, type : location ; entity : kahlo, type : head of government. [learn3] [learn4] for the relation characters : 1. [learn5] [learn6] and the entity for the relation characters are : head entity: cowichan lake, tail entity: daimaru; head entity: cowichan lake, tail entity: daimaru.<|endoftext|>\n",
      "10  / 96\n",
      "zero_possibility:  4.775619\n",
      "one_possibility:  9.122417\n",
      "entity : italy, type : location ; entity : greece, type : location ; entity : st. louis, type : location ; entity : india, type : location ; entity : daimaru, type : location ; entity : cowichan lake, type : location ; entity : kahlo, type : head of government. [learn3] [learn4] for the relation child : 1. [learn5] [learn6] and the entity for the relation child are : head entity: cowichan lake, tail entity: italy; head entity: cowichan lake, tail entity: italy; head entity: cowichan lake, tail entity: italy; head entity: cowichan lake, tail entity: italy.<|endoftext|>\n",
      "11  / 96\n",
      "zero_possibility:  2.0682395\n",
      "one_possibility:  7.2524405\n",
      "entity : italy, type : location ; entity : greece, type : location ; entity : st. louis, type : location ; entity : india, type : location ; entity : daimaru, type : location ; entity : cowichan lake, type : location ; entity : kahlo, type : head of government. [learn3] [learn4] for the relation composer : 1. [learn5] [learn6] and the entity for the relation composer are : head entity: mose et pharaon, tail entity: wilson; head entity: guillaume tell, tail entity: wilson; head entity: it is the fourth, tail entity: wilson; head entity: it is the last, tail entity: wilson; head entity: it is the last, tail entity: wilson; head entity: it is the last, tail entity: wilson.<|endoftext|>\n",
      "12  / 96\n",
      "zero_possibility:  25.395176\n",
      "one_possibility:  29.521074\n",
      "entity : italy, type : location ; entity : greece, type : location ; entity : st. louis, type : location ; entity : india, type : location ; entity : daimaru, type : location ; entity : cowichan lake, type : location ; entity : kahlo, type : head of government. [learn3] [learn4] for the relation conflict : 1. [learn5] [learn6] and the entity for the relation conflict are : head entity: cowichan lake, tail entity: italy; head entity: cowichan lake, tail entity: italy.<|endoftext|>\n",
      "13  / 96\n",
      "zero_possibility:  17.193983\n",
      "one_possibility:  20.255463\n",
      "entity : italy, type : location ; entity : greece, type : location ; entity : st. louis, type : location ; entity : india, type : location ; entity : daimaru, type : location ; entity : cowichan lake, type : location ; entity : kahlo, type : head of government. [learn3] [learn4] for the relation contains administrative territorial entity : 1. [learn5] [learn6] and the entity for the relation contains administrative territorial entity are : head entity: india, tail entity: kahlo.<|endoftext|>\n",
      "14  / 96\n",
      "zero_possibility:  21.863106\n",
      "one_possibility:  22.641502\n",
      "entity : italy, type : location ; entity : greece, type : location ; entity : st. louis, type : location ; entity : india, type : location ; entity : daimaru, type : location ; entity : cowichan lake, type : location ; entity : kahlo, type : head of government. [learn3] [learn4] for the relation continent : 1. [learn5] [learn6] and the entity for the relation continent are : head entity: cowichan lake, tail entity: india; head entity: cowichan lake, tail entity: india; head entity: cowichan lake, tail entity: india; head entity: cowichan lake, tail entity: india; head entity: cowichan lake, tail entity: india; head entity: cowichan lake, tail entity: india; head entity: cowichan lake, tail entity: india; head entity: cowichan lake, tail entity: india; head entity: cowichan lake, tail entity: india; head entity: cowichan lake, tail entity: india; head entity: cowichan lake, tail entity: india; head entity: cowichan lake, tail entity: india; head entity: cowichan lake, tail entity: india; head entity: cowichan lake, tail entity: india; head entity: cowichan lake, tail entity: india; head entity: cowichan lake, tail entity: india; head entity: cowichan lake, tail entity: india; head entity: cowichan lake, tail entity: india; head entity: cowichan lake, tail entity: india; head entity: cowichan lake, tail entity: india; head entity: cowichan lake, tail entity: india; head entity: cowichan lake, tail entity: india; head entity: cowichan lake, tail entity: india; head entity: cowichan lake, tail entity: india; head entity: cowichan lake, tail entity: india; head entity: cowichan lake, tail entity: india; head entity: cowichan lake, tail entity: india.<|endoftext|>\n",
      "15  / 96\n",
      "zero_possibility:  12.285294\n",
      "one_possibility:  17.240965\n",
      "entity : italy, type : location ; entity : greece, type : location ; entity : st. louis, type : location ; entity : india, type : location ; entity : daimaru, type : location ; entity : cowichan lake, type : location ; entity : kahlo, type : head of government. [learn3] [learn4] for the relation country : 1. [learn5] [learn6] and the entity for the relation country are : head entity: bharatiya, tail entity: india; head entity: cowichan lake, tail entity: india; head entity: cowichan lake, tail entity: india; head entity: bharatiya, tail entity: india; head entity: bharatiya, tail entity: india; head entity: bharatiya, tail entity: india; head entity: bharatiya, tail entity: india; head entity: bharatiya, tail entity: india; head entity: bharatiya, tail entity: india; head entity: bharatiya, tail entity: india; head entity: bharatiya, tail entity: india; head entity: bharatiya, tail entity: india; head entity: bharatiya, tail entity: india; head entity: bharatiya, tail entity: india; head entity: bharatiya, tail entity: india; head entity: bharatiya, tail entity: india; head entity: bharatiya, tail entity: india; head entity: bharatiya, tail entity: india; head entity: bharatiya, tail entity: india; head entity: bharatiya, tail entity: india; head entity: bharatiya, tail entity: india; head entity: bharatiya, tail entity: india; head entity: bharatiya, tail entity: india; head entity: bharatiya, tail entity: india; head entity: bharatiya, tail entity: india; head entity: bharatiya; head entity: bharatiya, tail entity: india; head entity: bharatiya.<|endoftext|>\n",
      "16  / 96\n",
      "zero_possibility:  16.11521\n",
      "one_possibility:  17.943066\n",
      "entity : italy, type : location ; entity : greece, type : location ; entity : st. louis, type : location ; entity : india, type : location ; entity : daimaru, type : location ; entity : cowichan lake, type : location ; entity : kahlo, type : head of government. [learn3] [learn4] for the relation country of citizenship : 1. [learn5] [learn6] and the entity for the relation country of citizenship are : head entity: luigi balocchi, tail entity: india; head entity: brazilian, tail entity: india; head entity: guzmn, tail entity: india; head entity: guzmn, tail entity: india; head entity: guzmn, tail entity: india; head entity: guzmn, tail entity: india; head entity: guzmn, tail entity: india; head entity: guzmn, tail entity: india; head entity: guzmn, tail entity: india; head entity: guzmn, tail entity: india; head entity: guzmn, tail entity: india; head entity: guzmn, tail entity: india; head entity: guzmn, tail entity: india; head entity: guzmn, tail entity: india; head entity: guzmn, tail entity: india; head entity: guzmn, tail entity: india; head entity: guzmn, tail entity: india; head entity: guzmn, tail entity: india; head entity: guzmn, tail entity: india; head entity: guzmn, tail entity: india; head entity: guzmn, tail entity: india; head entity: guzmn, tail entity: india; head entity: guzmn, tail entity: india; head entity: guzmn, tail entity: india; head entity: guzmn, tail entity: india; head entity: guzmn, tail entity: india; head entity: guzmn, tail entity: india; head entity: guzmn, tail entity: india; head entity: guzmn.<|endoftext|>\n",
      "17  / 96\n",
      "zero_possibility:  20.57042\n",
      "one_possibility:  23.899382\n",
      "entity : italy, type : location ; entity : greece, type : location ; entity : st. louis, type : location ; entity : india, type : location ; entity : daimaru, type : location ; entity : cowichan lake, type : location ; entity : kahlo, type : head of government. [learn3] [learn4] for the relation country of origin : 1. [learn5] [learn6] and the entity for the relation country of origin are : head entity: italy, tail entity: india; head entity: italy, tail entity: india; head entity: italy, tail entity: india; head entity: italy, tail entity: india; head entity: italy, tail entity: india; head entity: italy, tail entity: india; head entity: italy, tail entity: india; head entity: italy, tail entity: india; head entity: italy, tail entity: india; head entity: italy, tail entity: india; head entity: italy, tail entity: india; head entity: italy, tail entity: india; head entity: italy, tail entity: india; head entity: italy, tail entity: india; head entity: italy, tail entity: india; head entity: italy, tail entity: india; head entity: italy, tail entity: india; head entity: italy, tail entity: india; head entity: italy, tail entity: india; head entity: italy, tail entity: india; head entity: italy, tail entity: india; head entity: italy, tail entity: india; head entity: italy, tail entity: india; head entity: italy, tail entity: india; head entity: italy, tail entity: india; head entity: italy, tail entity: india; head entity: italy, tail entity: india; head entity: italy, tail entity: india; head entity: italy, tail entity: india; head entity: italy.<|endoftext|>\n",
      "18  / 96\n",
      "zero_possibility:  0.64816403\n",
      "one_possibility:  3.811729\n",
      "entity : italy, type : location ; entity : greece, type : location ; entity : st. louis, type : location ; entity : india, type : location ; entity : daimaru, type : location ; entity : cowichan lake, type : location ; entity : kahlo, type : head of government. [learn3] [learn4] for the relation creator : 1. [learn5] [learn6] and the entity for the relation creator are : head entity: mose et pharaon, tail entity: david leitch.<|endoftext|>\n",
      "19  / 96\n",
      "zero_possibility:  18.04485\n",
      "one_possibility:  17.710009\n",
      "entity : italy, type : location ; entity : greece, type : location ; entity : st. louis, type : location ; entity : india, type : location ; entity : daimaru, type : location ; entity : cowichan lake, type : location ; entity : kahlo, type : head of government. [learn3] [learn4] for the relation date of birth : 0. <|endoftext|>\n",
      "20  / 96\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_193756/1603700701.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  input_ids = torch.cat((input_ids, torch.tensor(tokenizer.encode(next_input, add_special_tokens=False, return_tensors=\"pt\")[0]).to(\"cuda\")), dim=0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "zero_possibility:  19.808475\n",
      "one_possibility:  19.078203\n",
      "entity : italy, type : location ; entity : greece, type : location ; entity : st. louis, type : location ; entity : india, type : location ; entity : daimaru, type : location ; entity : cowichan lake, type : location ; entity : kahlo, type : head of government. [learn3] [learn4] for the relation date of death : 0. <|endoftext|>\n",
      "21  / 96\n",
      "zero_possibility:  1.3002384\n",
      "one_possibility:  6.9767156\n",
      "entity : italy, type : location ; entity : greece, type : location ; entity : st. louis, type : location ; entity : india, type : location ; entity : daimaru, type : location ; entity : cowichan lake, type : location ; entity : kahlo, type : head of government. [learn3] [learn4] for the relation developer : 1. [learn5] [learn6] and the entity for the relation developer are : head entity: cowichan lake, tail entity: kahlo; head entity: cowichan lake, tail entity: kahlo.<|endoftext|>\n",
      "22  / 96\n",
      "zero_possibility:  2.1231802\n",
      "one_possibility:  7.5675793\n",
      "entity : italy, type : location ; entity : greece, type : location ; entity : st. louis, type : location ; entity : india, type : location ; entity : daimaru, type : location ; entity : cowichan lake, type : location ; entity : kahlo, type : head of government. [learn3] [learn4] for the relation director : 1. [learn5] [learn6] and the entity for the relation director are : head entity: cowichan lake, tail entity: david leitch.<|endoftext|>\n",
      "23  / 96\n",
      "zero_possibility:  27.733208\n",
      "one_possibility:  30.42037\n",
      "entity : italy, type : location ; entity : greece, type : location ; entity : st. louis, type : location ; entity : india, type : location ; entity : daimaru, type : location ; entity : cowichan lake, type : location ; entity : kahlo, type : head of government. [learn3] [learn4] for the relation dissolved, abolished or demolished : 1. [learn5] [learn6] and the entity for the relation dissolved, abolished or demolished are : head entity: italy, tail entity: godavatar.<|endoftext|>\n",
      "24  / 96\n",
      "zero_possibility:  6.7194934\n",
      "one_possibility:  12.039326\n",
      "entity : italy, type : location ; entity : greece, type : location ; entity : st. louis, type : location ; entity : india, type : location ; entity : daimaru, type : location ; entity : cowichan lake, type : location ; entity : kahlo, type : head of government. [learn3] [learn4] for the relation educated at : 1. [learn5] [learn6] and the entity for the relation educated at are : head entity: luigi balocchi, tail entity: bharatiya; head entity: guzmn, tail entity: bharatiya; head entity: hoddle, tail entity: bharatiya; head entity: hoddle, tail entity: bharatiya; head entity: hoddle, tail entity: bharatiya; head entity: hoddle, tail entity: bharatiya; head entity: hoddle, tail entity: bharatiya; head entity: hoddle, tail entity: bharatiya; head entity: hoddle, tail entity: bharatiya.<|endoftext|>\n",
      "25  / 96\n",
      "zero_possibility:  3.4557369\n",
      "one_possibility:  10.683144\n",
      "entity : italy, type : location ; entity : greece, type : location ; entity : st. louis, type : location ; entity : india, type : location ; entity : daimaru, type : location ; entity : cowichan lake, type : location ; entity : kahlo, type : head of government. [learn3] [learn4] for the relation employer : 1. [learn5] [learn6] and the entity for the relation employer are : head entity: bens, tail entity: vern raburn.<|endoftext|>\n",
      "26  / 96\n",
      "zero_possibility:  14.633259\n",
      "one_possibility:  14.994492\n",
      "entity : italy, type : location ; entity : greece, type : location ; entity : st. louis, type : location ; entity : india, type : location ; entity : daimaru, type : location ; entity : cowichan lake, type : location ; entity : kahlo, type : head of government. [learn3] [learn4] for the relation end time : 1. [learn5] [learn6] and the entity for the relation end time are : head entity: cowichan lake, tail entity: 0.<|endoftext|>\n",
      "27  / 96\n",
      "zero_possibility:  12.019016\n",
      "one_possibility:  14.613502\n",
      "entity : italy, type : location ; entity : greece, type : location ; entity : st. louis, type : location ; entity : india, type : location ; entity : daimaru, type : location ; entity : cowichan lake, type : location ; entity : kahlo, type : head of government. [learn3] [learn4] for the relation ethnic group : 1. [learn5] [learn6] and the entity for the relation ethnic group are : head entity: bahlo, tail entity: india; head entity: cowichan lake, tail entity: india; head entity: bahlo, tail entity: india; head entity: bahlo, tail entity: india; head entity: bahlo, tail entity: india; head entity: bahlo, tail entity: india; head entity: bahlo, tail entity: india; head entity: bahlo, tail entity: india; head entity: bahlo, tail entity: india; head entity: bahlo, tail entity: india; head entity: bahlo, tail entity: india; head entity: bahlo, tail entity: india; head entity: bahlo, tail entity: india; head entity: bahlo, tail entity: india; head entity: bahlo, tail entity: india; head entity: bahlo, tail entity: india; head entity: bahlo, tail entity: india; head entity: bahlo, tail entity: india; head entity: bahlo, tail entity: india; head entity: bahlo, tail entity: india; head entity: bahlo, tail entity: india; head entity: bahlo, tail entity: india; head entity: bahlo, tail entity: india; head entity: bahlo, tail entity: india; head entity: bahlo, tail entity: india; head entity: bahlo, tail entity: india; head entity: bahlo, tail entity: india.<|endoftext|>\n",
      "28  / 96\n",
      "zero_possibility:  2.292141\n",
      "one_possibility:  7.631013\n",
      "entity : italy, type : location ; entity : greece, type : location ; entity : st. louis, type : location ; entity : india, type : location ; entity : daimaru, type : location ; entity : cowichan lake, type : location ; entity : kahlo, type : head of government. [learn3] [learn4] for the relation father : 1. [learn5] [learn6] and the entity for the relation father are : head entity: cowichan lake, tail entity: diego rivera; head entity: cowichan lake, tail entity: diego rivera; head entity: cowichan lake, tail entity: diego rivera; head entity: cowichan lake, tail entity: diego rivera; head entity: cowichan lake, tail entity: diego rivera; head entity: cowichan lake, tail entity: diego rivera; head entity: cowichan lake, tail entity: diego rivera; head entity: cowichan lake, tail entity: diego rivera; head entity: cowichan lake, tail entity: diego rivera; head entity: cowichan lake, tail entity: diego rivera; head entity: cowichan lake, tail entity: diego rivera; head entity: honduras, tail entity: diego rivera; head entity: honduras, tail entity: diego rivera; head entity: honduras, tail entity: diego rivera; head entity: honduras, tail entity: diego rivera; head entity: honduras, tail entity: diego rivera; head entity: honduras, tail entity: diego rivera; head entity: honduras, tail entity: diego rivera; head entity: honduras, tail entity: diego rivera; head entity: honduras, tail entity: diego rivera; head entity: honduras, tail entity: diego rivera; head entity: honduras, tail entity: diego rivera; head entity: honduras, tail entity: diego rivera; head entity: honduras, tail entity: diego rivera; head entity: honduras; head entity: honduras, tail entity: diego rivera; head entity: honduras; head entity: honduras, tail entity: diego rivera; head entity: honduras; head entity: honduras, tail entity: honduras; head entity: honduras; head entity: honduras; head entity: honduras, tail entity: honduras; head entity: honduras; head entity: honduras; head entity: honduras, tail entity: honduras; head entity: honduras; head entity: honduras; head entity: honduras; head entity: honduras; head entity: honduras; head entity: honduras; head entity: honduras; head entity: honduras; head entity: honduras; head entity: honduras; head entity: honduras; head entity: honduras; head entity: honduras; head entity: honduras; head entity: honduras; head entity: honduras; head entity: honduras; head entity: honduras; head entity: honduras; head entity: honduras; head entity: honduras; head entity: honduras; head entity: honduras; head entity: honduras; head entity: honduras; head entity: honduras; head entity: honduras; head entity: honduras; head entity: honduras; head entity: honduras; head entity: honduras; head entity: honduras; head entity: honduras; head entity: honduras; head entity: honduras; head entity: honduras; head entity: honduras; head entity: honduras; head entity: honduras; head entity: honduras; head entity: honduras; head entity: honduras; head entity: honduras; head entity: honduras; head entity: honduras; head entity: honduras; head entity: honduras; head entity: honduras; head entity: honduras; head entity: honduras; head entity: honduras; head entity: honduras; head entity: honduras; head entity: honduras; head entity: honduras, tail entity: hond\n",
      "29  / 96\n",
      "zero_possibility:  11.819021\n",
      "one_possibility:  17.55316\n",
      "entity : italy, type : location ; entity : greece, type : location ; entity : st. louis, type : location ; entity : india, type : location ; entity : daimaru, type : location ; entity : cowichan lake, type : location ; entity : kahlo, type : head of government. [learn3] [learn4] for the relation followed by : 1. [learn5] [learn6] and the entity for the relation followed by are : head entity: bahlo, tail entity: cowichan lake; head entity: bahlo, tail entity: cowichan lake.<|endoftext|>\n",
      "30  / 96\n",
      "zero_possibility:  10.564098\n",
      "one_possibility:  17.727863\n",
      "entity : italy, type : location ; entity : greece, type : location ; entity : st. louis, type : location ; entity : india, type : location ; entity : daimaru, type : location ; entity : cowichan lake, type : location ; entity : kahlo, type : head of government. [learn3] [learn4] for the relation follows : 1. [learn5] [learn6] and the entity for the relation follows are : head entity: italy, tail entity: godavatar.<|endoftext|>\n",
      "31  / 96\n",
      "zero_possibility:  12.39059\n",
      "one_possibility:  14.72347\n",
      "entity : italy, type : location ; entity : greece, type : location ; entity : st. louis, type : location ; entity : india, type : location ; entity : daimaru, type : location ; entity : cowichan lake, type : location ; entity : kahlo, type : head of government. [learn3] [learn4] for the relation founded by : 1. [learn5] [learn6] and the entity for the relation founded by are : head entity: italy, tail entity: godavatar.<|endoftext|>\n",
      "32  / 96\n",
      "zero_possibility:  18.67553\n",
      "one_possibility:  21.836304\n",
      "entity : italy, type : location ; entity : greece, type : location ; entity : st. louis, type : location ; entity : india, type : location ; entity : daimaru, type : location ; entity : cowichan lake, type : location ; entity : kahlo, type : head of government. [learn3] [learn4] for the relation genre : 1. [learn5] [learn6] and the entity for the relation genre are : head entity: italy, tail entity: cowichan lake; head entity: italy, tail entity: cowichan lake.<|endoftext|>\n",
      "33  / 96\n",
      "zero_possibility:  10.961144\n",
      "one_possibility:  14.635993\n",
      "entity : italy, type : location ; entity : greece, type : location ; entity : st. louis, type : location ; entity : india, type : location ; entity : daimaru, type : location ; entity : cowichan lake, type : location ; entity : kahlo, type : head of government. [learn3] [learn4] for the relation has part : 1. [learn5] [learn6] and the entity for the relation has part are : head entity: bahlo, tail entity: cowichan lake; head entity: bahlo, tail entity: cowichan lake.<|endoftext|>\n",
      "34  / 96\n",
      "zero_possibility:  21.230042\n",
      "one_possibility:  24.712704\n",
      "entity : italy, type : location ; entity : greece, type : location ; entity : st. louis, type : location ; entity : india, type : location ; entity : daimaru, type : location ; entity : cowichan lake, type : location ; entity : kahlo, type : head of government. [learn3] [learn4] for the relation head of government : 1. [learn5] [learn6] and the entity for the relation head of government are : head entity: italy, tail entity: godavataros; head entity: italy, tail entity: godflesh; head entity: italy, tail entity: godflesh; head entity: italy, tail entity: godflesh; head entity: italy, tail entity: godflesh; head entity: italy, tail entity: godflesh; head entity: italy, tail entity: godflesh; head entity: italy, tail entity: godflesh; head entity: italy, tail entity: godflesh; head entity: italy, tail entity: godflesh; head entity: italy, tail entity: godflesh; head entity: italy, tail entity: godflesh.<|endoftext|>\n",
      "35  / 96\n",
      "zero_possibility:  17.154524\n",
      "one_possibility:  17.907244\n",
      "entity : italy, type : location ; entity : greece, type : location ; entity : st. louis, type : location ; entity : india, type : location ; entity : daimaru, type : location ; entity : cowichan lake, type : location ; entity : kahlo, type : head of government. [learn3] [learn4] for the relation head of state : 1. [learn5] [learn6] and the entity for the relation head of state are : head entity: italy, tail entity: godavataros.<|endoftext|>\n",
      "36  / 96\n",
      "zero_possibility:  14.495176\n",
      "one_possibility:  19.36076\n",
      "entity : italy, type : location ; entity : greece, type : location ; entity : st. louis, type : location ; entity : india, type : location ; entity : daimaru, type : location ; entity : cowichan lake, type : location ; entity : kahlo, type : head of government. [learn3] [learn4] for the relation headquarters location : 1. [learn5] [learn6] and the entity for the relation headquarters location are : head entity: cowichan lake, tail entity: kahlo.<|endoftext|>\n",
      "37  / 96\n",
      "zero_possibility:  16.267141\n",
      "one_possibility:  17.438726\n",
      "entity : italy, type : location ; entity : greece, type : location ; entity : st. louis, type : location ; entity : india, type : location ; entity : daimaru, type : location ; entity : cowichan lake, type : location ; entity : kahlo, type : head of government. [learn3] [learn4] for the relation inception : 1. [learn5] [learn6] and the entity for the relation inception are : head entity: italy, tail entity: 1998.<|endoftext|>\n",
      "38  / 96\n",
      "zero_possibility:  15.243822\n",
      "one_possibility:  19.232798\n",
      "entity : italy, type : location ; entity : greece, type : location ; entity : st. louis, type : location ; entity : india, type : location ; entity : daimaru, type : location ; entity : cowichan lake, type : location ; entity : kahlo, type : head of government. [learn3] [learn4] for the relation influenced by : 1. [learn5] [learn6] and the entity for the relation influenced by are : head entity: cowichan lake, tail entity: paulo.<|endoftext|>\n",
      "39  / 96\n",
      "zero_possibility:  13.230375\n",
      "one_possibility:  15.757855\n",
      "entity : italy, type : location ; entity : greece, type : location ; entity : st. louis, type : location ; entity : india, type : location ; entity : daimaru, type : location ; entity : cowichan lake, type : location ; entity : kahlo, type : head of government. [learn3] [learn4] for the relation instance of : 1. [learn5] [learn6] and the entity for the relation instance of are : head entity: italy, tail entity: cowichan lake; head entity: italy, tail entity: cowichan lake.<|endoftext|>\n",
      "40  / 96\n",
      "zero_possibility:  14.685629\n",
      "one_possibility:  19.00317\n",
      "entity : italy, type : location ; entity : greece, type : location ; entity : st. louis, type : location ; entity : india, type : location ; entity : daimaru, type : location ; entity : cowichan lake, type : location ; entity : kahlo, type : head of government. [learn3] [learn4] for the relation languages spoken, written or signed : 1. [learn5] [learn6] and the entity for the relation languages spoken, written or signed are : head entity: italy, tail entity: india; head entity: italy, tail entity: india; head entity: italy, tail entity: india; head entity: italy, tail entity: india; head entity: italy, tail entity: india; head entity: italy, tail entity: india; head entity: italy, tail entity: india; head entity: italy, tail entity: india; head entity: italy, tail entity: india; head entity: italy, tail entity: india; head entity: italy, tail entity: india; head entity: italy, tail entity: india; head entity: italy, tail entity: india; head entity: italy, tail entity: india; head entity: italy, tail entity: india; head entity: italy, tail entity: india; head entity: italy, tail entity: india; head entity: italy, tail entity: india; head entity: italy, tail entity: india; head entity: italy, tail entity: india; head entity: italy, tail entity: india; head entity: italy, tail entity: india; head entity: italy, tail entity: india; head entity: italy, tail entity: india; head entity: italy, tail entity: india; head entity: italy, tail entity: india; head entity: italy, tail entity: india.<|endoftext|>\n",
      "41  / 96\n",
      "zero_possibility:  17.351522\n",
      "one_possibility:  19.261105\n",
      "entity : italy, type : location ; entity : greece, type : location ; entity : st. louis, type : location ; entity : india, type : location ; entity : daimaru, type : location ; entity : cowichan lake, type : location ; entity : kahlo, type : head of government. [learn3] [learn4] for the relation league : 1. [learn5] [learn6] and the entity for the relation league are : head entity: cowichan lake, tail entity: brazilian.<|endoftext|>\n",
      "42  / 96\n",
      "zero_possibility:  10.413529\n",
      "one_possibility:  11.729517\n",
      "entity : italy, type : location ; entity : greece, type : location ; entity : st. louis, type : location ; entity : india, type : location ; entity : daimaru, type : location ; entity : cowichan lake, type : location ; entity : kahlo, type : head of government. [learn3] [learn4] for the relation legislative body : 1. [learn5] [learn6] and the entity for the relation legislative body are : head entity: india, tail entity: unioniva.<|endoftext|>\n",
      "43  / 96\n",
      "zero_possibility:  15.932453\n",
      "one_possibility:  19.772879\n",
      "entity : italy, type : location ; entity : greece, type : location ; entity : st. louis, type : location ; entity : india, type : location ; entity : daimaru, type : location ; entity : cowichan lake, type : location ; entity : kahlo, type : head of government. [learn3] [learn4] for the relation located in or next to body of water : 1. [learn5] [learn6] and the entity for the relation located in or next to body of water are : head entity: bens, tail entity: italy; head entity: cowichan lake, tail entity: italy; head entity: bens, tail entity: italy.<|endoftext|>\n",
      "44  / 96\n",
      "zero_possibility:  10.032718\n",
      "one_possibility:  14.494117\n",
      "entity : italy, type : location ; entity : greece, type : location ; entity : st. louis, type : location ; entity : india, type : location ; entity : daimaru, type : location ; entity : cowichan lake, type : location ; entity : kahlo, type : head of government. [learn3] [learn4] for the relation located in the administrative territorial entity : 1. [learn5] [learn6] and the entity for the relation located in the administrative territorial entity are : head entity: greece, tail entity: india; head entity: british columbia, tail entity: italy.<|endoftext|>\n",
      "45  / 96\n",
      "zero_possibility:  14.859098\n",
      "one_possibility:  19.586622\n",
      "entity : italy, type : location ; entity : greece, type : location ; entity : st. louis, type : location ; entity : india, type : location ; entity : daimaru, type : location ; entity : cowichan lake, type : location ; entity : kahlo, type : head of government. [learn3] [learn4] for the relation located on terrain feature : 1. [learn5] [learn6] and the entity for the relation located on terrain feature are : head entity: kahlo, tail entity: india; head entity: cowichan lake, tail entity: india; head entity: bahlo, tail entity: india; head entity: bahlo, tail entity: india; head entity: bahlo, tail entity: india.<|endoftext|>\n",
      "46  / 96\n",
      "zero_possibility:  10.602066\n",
      "one_possibility:  13.801819\n",
      "entity : italy, type : location ; entity : greece, type : location ; entity : st. louis, type : location ; entity : india, type : location ; entity : daimaru, type : location ; entity : cowichan lake, type : location ; entity : kahlo, type : head of government. [learn3] [learn4] for the relation location : 1. [learn5] [learn6] and the entity for the relation location are : head entity: bharatiya, tail entity: italy; head entity: cowichan lake, tail entity: italy.<|endoftext|>\n",
      "47  / 96\n",
      "zero_possibility:  27.89899\n",
      "one_possibility:  29.33163\n",
      "entity : italy, type : location ; entity : greece, type : location ; entity : st. louis, type : location ; entity : india, type : location ; entity : daimaru, type : location ; entity : cowichan lake, type : location ; entity : kahlo, type : head of government. [learn3] [learn4] for the relation location of formation : 1. [learn5] [learn6] and the entity for the relation location of formation are : head entity: italy, tail entity: east godavataros.<|endoftext|>\n",
      "48  / 96\n",
      "zero_possibility:  10.9897375\n",
      "one_possibility:  13.880551\n",
      "entity : italy, type : location ; entity : greece, type : location ; entity : st. louis, type : location ; entity : india, type : location ; entity : daimaru, type : location ; entity : cowichan lake, type : location ; entity : kahlo, type : head of government. [learn3] [learn4] for the relation lyrics by : 1. [learn5] [learn6] and the entity for the relation lyrics by are : head entity: italy, tail entity: cowichan lake; head entity: italy, tail entity: cowichan lake.<|endoftext|>\n",
      "49  / 96\n",
      "zero_possibility:  0.39860678\n",
      "one_possibility:  4.6036158\n",
      "entity : italy, type : location ; entity : greece, type : location ; entity : st. louis, type : location ; entity : india, type : location ; entity : daimaru, type : location ; entity : cowichan lake, type : location ; entity : kahlo, type : head of government. [learn3] [learn4] for the relation manufacturer : 1. [learn5] [learn6] and the entity for the relation manufacturer are : head entity: cowichan lake, tail entity: cbs.<|endoftext|>\n",
      "50  / 96\n",
      "zero_possibility:  13.602692\n",
      "one_possibility:  17.448416\n",
      "entity : italy, type : location ; entity : greece, type : location ; entity : st. louis, type : location ; entity : india, type : location ; entity : daimaru, type : location ; entity : cowichan lake, type : location ; entity : kahlo, type : head of government. [learn3] [learn4] for the relation member of : 1. [learn5] [learn6] and the entity for the relation member of are : head entity: luigi balocchi, tail entity: godavataros; head entity: cowichan lake, tail entity: godavataros; head entity: british columbia, tail entity: godavataros.<|endoftext|>\n",
      "51  / 96\n",
      "zero_possibility:  19.41831\n",
      "one_possibility:  22.478197\n",
      "entity : italy, type : location ; entity : greece, type : location ; entity : st. louis, type : location ; entity : india, type : location ; entity : daimaru, type : location ; entity : cowichan lake, type : location ; entity : kahlo, type : head of government. [learn3] [learn4] for the relation member of political party : 1. [learn5] [learn6] and the entity for the relation member of political party are : head entity: bharatiya, tail entity: rpf; head entity: cowichan lake, tail entity: bharatiya; head entity: bharatiya, tail entity: bharatiya; head entity: bharatiya, tail entity: bharatiya; head entity: bharatiya, tail entity: bharatiya; head entity: bharatiya, tail entity: bharatiya; head entity: bharatiya, tail entity: bharatiya.<|endoftext|>\n",
      "52  / 96\n",
      "zero_possibility:  18.762163\n",
      "one_possibility:  22.116793\n",
      "entity : italy, type : location ; entity : greece, type : location ; entity : st. louis, type : location ; entity : india, type : location ; entity : daimaru, type : location ; entity : cowichan lake, type : location ; entity : kahlo, type : head of government. [learn3] [learn4] for the relation member of sports team : 1. [learn5] [learn6] and the entity for the relation member of sports team are : head entity: kahlo, tail entity: godavataro.<|endoftext|>\n",
      "53  / 96\n",
      "zero_possibility:  22.24676\n",
      "one_possibility:  25.800932\n",
      "entity : italy, type : location ; entity : greece, type : location ; entity : st. louis, type : location ; entity : india, type : location ; entity : daimaru, type : location ; entity : cowichan lake, type : location ; entity : kahlo, type : head of government. [learn3] [learn4] for the relation military branch : 1. [learn5] [learn6] and the entity for the relation military branch are : head entity: bahlo, tail entity: spanish civil war.<|endoftext|>\n",
      "54  / 96\n",
      "zero_possibility:  -5.0156283\n",
      "one_possibility:  -4.2113857\n",
      "entity : italy, type : location ; entity : greece, type : location ; entity : st. louis, type : location ; entity : india, type : location ; entity : daimaru, type : location ; entity : cowichan lake, type : location ; entity : kahlo, type : head of government. [learn3] [learn4] for the relation mother : 1. [learn5] [learn6] and the entity for the relation mother are : head entity: cowichan lake, tail entity: bharatiya; head entity: cowichan lake, tail entity: bharatiya; head entity: bharatiya, tail entity: bharatiya.<|endoftext|>\n",
      "55  / 96\n",
      "zero_possibility:  5.677166\n",
      "one_possibility:  7.953433\n",
      "entity : italy, type : location ; entity : greece, type : location ; entity : st. louis, type : location ; entity : india, type : location ; entity : daimaru, type : location ; entity : cowichan lake, type : location ; entity : kahlo, type : head of government. [learn3] [learn4] for the relation mouth of the watercourse : 1. [learn5] [learn6] and the entity for the relation mouth of the watercourse are : head entity: kahlo, tail entity: cowichan lake; head entity: kahlo, tail entity: cowichan lake.<|endoftext|>\n",
      "56  / 96\n",
      "zero_possibility:  19.97269\n",
      "one_possibility:  25.941933\n",
      "entity : italy, type : location ; entity : greece, type : location ; entity : st. louis, type : location ; entity : india, type : location ; entity : daimaru, type : location ; entity : cowichan lake, type : location ; entity : kahlo, type : head of government. [learn3] [learn4] for the relation narrative location : 1. [learn5] [learn6] and the entity for the relation narrative location are : head entity: it is also the head entity: italy, tail entity: cowichan lake; head entity: italy, tail entity: cowichan lake.<|endoftext|>\n",
      "57  / 96\n",
      "zero_possibility:  9.176149\n",
      "one_possibility:  14.666817\n",
      "entity : italy, type : location ; entity : greece, type : location ; entity : st. louis, type : location ; entity : india, type : location ; entity : daimaru, type : location ; entity : cowichan lake, type : location ; entity : kahlo, type : head of government. [learn3] [learn4] for the relation notable work : 1. [learn5] [learn6] and the entity for the relation notable work are : head entity: abramo, tail entity: godavataros.<|endoftext|>\n",
      "58  / 96\n",
      "zero_possibility:  10.186162\n",
      "one_possibility:  11.72407\n",
      "entity : italy, type : location ; entity : greece, type : location ; entity : st. louis, type : location ; entity : india, type : location ; entity : daimaru, type : location ; entity : cowichan lake, type : location ; entity : kahlo, type : head of government. [learn3] [learn4] for the relation official language : 1. [learn5] [learn6] and the entity for the relation official language are : head entity: italy, tail entity: india; head entity: italy, tail entity: india; head entity: italy, tail entity: india; head entity: italy, tail entity: india; head entity: italy, tail entity: india; head entity: italy, tail entity: india; head entity: italy, tail entity: india; head entity: italy, tail entity: india; head entity: italy, tail entity: india; head entity: italy, tail entity: india; head entity: italy, tail entity: india; head entity: italy, tail entity: india.<|endoftext|>\n",
      "59  / 96\n",
      "zero_possibility:  4.225747\n",
      "one_possibility:  8.557092\n",
      "entity : italy, type : location ; entity : greece, type : location ; entity : st. louis, type : location ; entity : india, type : location ; entity : daimaru, type : location ; entity : cowichan lake, type : location ; entity : kahlo, type : head of government. [learn3] [learn4] for the relation operator : 1. [learn5] [learn6] and the entity for the relation operator are : head entity: cowichan lake, tail entity: cbs.<|endoftext|>\n",
      "60  / 96\n",
      "zero_possibility:  12.985752\n",
      "one_possibility:  16.225695\n",
      "entity : italy, type : location ; entity : greece, type : location ; entity : st. louis, type : location ; entity : india, type : location ; entity : daimaru, type : location ; entity : cowichan lake, type : location ; entity : kahlo, type : head of government. [learn3] [learn4] for the relation original language of work : 1. [learn5] [learn6] and the entity for the relation original language of work are : head entity: italy, tail entity: india; head entity: italy, tail entity: india; head entity: italy, tail entity: india; head entity: italy, tail entity: india; head entity: italy, tail entity: india; head entity: italy, tail entity: india; head entity: italy, tail entity: india; head entity: italy, tail entity: india; head entity: italy, tail entity: india; head entity: italy, tail entity: india; head entity: italy, tail entity: india; head entity: italy, tail entity: india; head entity: italy, tail entity: india; head entity: italy, tail entity: india; head entity: italy, tail entity: india; head entity: italy, tail entity: india; head entity: italy, tail entity: india; head entity: italy, tail entity: india; head entity: italy, tail entity: india; head entity: italy, tail entity: india; head entity: italy, tail entity: india; head entity: italy, tail entity: india; head entity: italy, tail entity: india; head entity: italy, tail entity: india; head entity: italy, tail entity: india; head entity: italy, tail entity: india; head entity: italy, tail entity: india.<|endoftext|>\n",
      "61  / 96\n",
      "zero_possibility:  12.52698\n",
      "one_possibility:  18.19774\n",
      "entity : italy, type : location ; entity : greece, type : location ; entity : st. louis, type : location ; entity : india, type : location ; entity : daimaru, type : location ; entity : cowichan lake, type : location ; entity : kahlo, type : head of government. [learn3] [learn4] for the relation original network : 1. [learn5] [learn6] and the entity for the relation original network are : head entity: cowichan lake, tail entity: bbc1.<|endoftext|>\n",
      "62  / 96\n",
      "zero_possibility:  5.074468\n",
      "one_possibility:  7.821684\n",
      "entity : italy, type : location ; entity : greece, type : location ; entity : st. louis, type : location ; entity : india, type : location ; entity : daimaru, type : location ; entity : cowichan lake, type : location ; entity : kahlo, type : head of government. [learn3] [learn4] for the relation owned by : 1. [learn5] [learn6] and the entity for the relation owned by are : head entity: cowichan lake, tail entity: godavataros; head entity: cowichan lake, tail entity: godavataros; head entity: cowichan lake, tail entity: godavataros; head entity: cowichan lake, tail entity: godavataros.<|endoftext|>\n",
      "63  / 96\n",
      "zero_possibility:  9.04733\n",
      "one_possibility:  13.568166\n",
      "entity : italy, type : location ; entity : greece, type : location ; entity : st. louis, type : location ; entity : india, type : location ; entity : daimaru, type : location ; entity : cowichan lake, type : location ; entity : kahlo, type : head of government. [learn3] [learn4] for the relation parent organization : 1. [learn5] [learn6] and the entity for the relation parent organization are : head entity: bahlo, tail entity: godavatar.<|endoftext|>\n",
      "64  / 96\n",
      "zero_possibility:  11.530745\n",
      "one_possibility:  11.869206\n",
      "entity : italy, type : location ; entity : greece, type : location ; entity : st. louis, type : location ; entity : india, type : location ; entity : daimaru, type : location ; entity : cowichan lake, type : location ; entity : kahlo, type : head of government. [learn3] [learn4] for the relation parent taxon : 1. [learn5] [learn6] and the entity for the relation parent taxon are : head entity: bens, tail entity: taxon.<|endoftext|>\n",
      "65  / 96\n",
      "zero_possibility:  15.04363\n",
      "one_possibility:  17.93742\n",
      "entity : italy, type : location ; entity : greece, type : location ; entity : st. louis, type : location ; entity : india, type : location ; entity : daimaru, type : location ; entity : cowichan lake, type : location ; entity : kahlo, type : head of government. [learn3] [learn4] for the relation part of : 1. [learn5] [learn6] and the entity for the relation part of are : head entity: bahlo, tail entity: italy; head entity: cowichan lake, tail entity: italy.<|endoftext|>\n",
      "66  / 96\n",
      "zero_possibility:  11.445528\n",
      "one_possibility:  12.956898\n",
      "entity : italy, type : location ; entity : greece, type : location ; entity : st. louis, type : location ; entity : india, type : location ; entity : daimaru, type : location ; entity : cowichan lake, type : location ; entity : kahlo, type : head of government. [learn3] [learn4] for the relation participant : 1. [learn5] [learn6] and the entity for the relation participant of are : head entity: italy, tail entity: cowichan lake; head entity: italy, tail entity: cowichan lake.<|endoftext|>\n",
      "67  / 96\n",
      "zero_possibility:  15.713934\n",
      "one_possibility:  16.683468\n",
      "entity : italy, type : location ; entity : greece, type : location ; entity : st. louis, type : location ; entity : india, type : location ; entity : daimaru, type : location ; entity : cowichan lake, type : location ; entity : kahlo, type : head of government. [learn3] [learn4] for the relation participant of : 1. [learn5] [learn6] and the entity for the relation participant of are : head entity: italy, tail entity: cowichan lake; head entity: italy, tail entity: cowichan lake.<|endoftext|>\n",
      "68  / 96\n",
      "zero_possibility:  9.520928\n",
      "one_possibility:  13.692425\n",
      "entity : italy, type : location ; entity : greece, type : location ; entity : st. louis, type : location ; entity : india, type : location ; entity : daimaru, type : location ; entity : cowichan lake, type : location ; entity : kahlo, type : head of government. [learn3] [learn4] for the relation performer : 1. [learn5] [learn6] and the entity for the relation performer are : head entity: cowichan lake, tail entity: godflesh; head entity: cowichan lake, tail entity: godflesh; head entity: cowichan lake, tail entity: godflesh; head entity: cowichan lake, tail entity: godflesh; head entity: cowichan lake, tail entity: godflesh; head entity: cowichan lake, tail entity: godflesh; head entity: cowichan lake, tail entity: godflesh; head entity: cowichan lake, tail entity: godflesh; head entity: cowichan lake, tail entity: godflesh; head entity: cowichan lake, tail entity: godflesh; head entity: cowichan lake, tail entity: godflesh; head entity: cowichan lake, tail entity: godflesh; head entity: cowichan lake, tail entity: godflesh; head entity: cowichan lake, tail entity: godflesh; head entity: cowichan lake, tail entity: godflesh; head entity: cowichan lake, tail entity: godflesh; head entity: cowichan lake, tail entity: godflesh; head entity: cowichan lake, tail entity: godflesh; head entity: cowichan lake, tail entity: godflesh; head entity: cowichan lake, tail entity: godflesh; head entity: cowichan lake, tail entity: godflesh; head entity: cowichan lake, tail entity: godflesh; head entity: cowichan lake, tail entity: godflesh.<|endoftext|>\n",
      "69  / 96\n",
      "zero_possibility:  16.56138\n",
      "one_possibility:  17.685907\n",
      "entity : italy, type : location ; entity : greece, type : location ; entity : st. louis, type : location ; entity : india, type : location ; entity : daimaru, type : location ; entity : cowichan lake, type : location ; entity : kahlo, type : head of government. [learn3] [learn4] for the relation place of birth : 1. [learn5] [learn6] and the entity for the relation place of birth are : head entity: italy, tail entity: boston.<|endoftext|>\n",
      "70  / 96\n",
      "zero_possibility:  20.19783\n",
      "one_possibility:  20.376104\n",
      "entity : italy, type : location ; entity : greece, type : location ; entity : st. louis, type : location ; entity : india, type : location ; entity : daimaru, type : location ; entity : cowichan lake, type : location ; entity : kahlo, type : head of government. [learn3] [learn4] for the relation place of death : 1. [learn5] [learn6] and the entity for the relation place of death are : head entity: italy, tail entity: kahlo.<|endoftext|>\n",
      "71  / 96\n",
      "zero_possibility:  16.485016\n",
      "one_possibility:  17.398129\n",
      "entity : italy, type : location ; entity : greece, type : location ; entity : st. louis, type : location ; entity : india, type : location ; entity : daimaru, type : location ; entity : cowichan lake, type : location ; entity : kahlo, type : head of government. [learn3] [learn4] for the relation platform : 1. [learn5] [learn6] and the entity for the relation platform are : head entity: bens, tail entity: 0.<|endoftext|>\n",
      "72  / 96\n",
      "zero_possibility:  17.367653\n",
      "one_possibility:  19.806108\n",
      "entity : italy, type : location ; entity : greece, type : location ; entity : st. louis, type : location ; entity : india, type : location ; entity : daimaru, type : location ; entity : cowichan lake, type : location ; entity : kahlo, type : head of government. [learn3] [learn4] for the relation point in time : 1. [learn5] [learn6] and the entity for the relation point in time are : head entity: italy, tail entity: 1932.<|endoftext|>\n",
      "73  / 96\n",
      "zero_possibility:  12.605845\n",
      "one_possibility:  18.864515\n",
      "entity : italy, type : location ; entity : greece, type : location ; entity : st. louis, type : location ; entity : india, type : location ; entity : daimaru, type : location ; entity : cowichan lake, type : location ; entity : kahlo, type : head of government. [learn3] [learn4] for the relation position held : 1. [learn5] [learn6] and the entity for the relation position held are : head entity: luigi balocchi, tail entity: cowichan lake; head entity: bahlo, tail entity: cowichan lake.<|endoftext|>\n",
      "74  / 96\n",
      "zero_possibility:  20.114338\n",
      "one_possibility:  26.504807\n",
      "entity : italy, type : location ; entity : greece, type : location ; entity : st. louis, type : location ; entity : india, type : location ; entity : daimaru, type : location ; entity : cowichan lake, type : location ; entity : kahlo, type : head of government. [learn3] [learn4] for the relation present in work : 1. [learn5] [learn6] and the entity for the relation present in work are : head entity: bahlo, tail entity: godavataro.<|endoftext|>\n",
      "75  / 96\n",
      "zero_possibility:  2.1882365\n",
      "one_possibility:  6.7441235\n",
      "entity : italy, type : location ; entity : greece, type : location ; entity : st. louis, type : location ; entity : india, type : location ; entity : daimaru, type : location ; entity : cowichan lake, type : location ; entity : kahlo, type : head of government. [learn3] [learn4] for the relation producer : 1. [learn5] [learn6] and the entity for the relation producer are : head entity: cowichan lake, tail entity: vern raburn; head entity: cowichan lake, tail entity: vern raburn.<|endoftext|>\n",
      "76  / 96\n",
      "zero_possibility:  15.068708\n",
      "one_possibility:  13.604145\n",
      "entity : italy, type : location ; entity : greece, type : location ; entity : st. louis, type : location ; entity : india, type : location ; entity : daimaru, type : location ; entity : cowichan lake, type : location ; entity : kahlo, type : head of government. [learn3] [learn4] for the relation product or material produced : 0. <|endoftext|>\n",
      "77  / 96\n",
      "zero_possibility:  13.617243\n",
      "one_possibility:  19.135704\n",
      "entity : italy, type : location ; entity : greece, type : location ; entity : st. louis, type : location ; entity : india, type : location ; entity : daimaru, type : location ; entity : cowichan lake, type : location ; entity : kahlo, type : head of government. [learn3] [learn4] for the relation production company : 1. [learn5] [learn6] and the entity for the relation production company are : head entity: cowichan lake, tail entity: cbs.<|endoftext|>\n",
      "78  / 96\n",
      "zero_possibility:  17.988026\n",
      "one_possibility:  20.686594\n",
      "entity : italy, type : location ; entity : greece, type : location ; entity : st. louis, type : location ; entity : india, type : location ; entity : daimaru, type : location ; entity : cowichan lake, type : location ; entity : kahlo, type : head of government. [learn3] [learn4] for the relation publication date : 1. [learn5] [learn6] and the entity for the relation publication date are : head entity: italy, tail entity: april 1858; head entity: italy, tail entity: april 1858.<|endoftext|>\n",
      "79  / 96\n",
      "zero_possibility:  -3.2019536\n",
      "one_possibility:  0.6767023\n",
      "entity : italy, type : location ; entity : greece, type : location ; entity : st. louis, type : location ; entity : india, type : location ; entity : daimaru, type : location ; entity : cowichan lake, type : location ; entity : kahlo, type : head of government. [learn3] [learn4] for the relation publisher : 1. [learn5] [learn6] and the entity for the relation publisher are : head entity: mose et pharaon, tail entity: vern raburn; head entity: cowichan lake, tail entity: vern raburn.<|endoftext|>\n",
      "80  / 96\n",
      "zero_possibility:  10.337646\n",
      "one_possibility:  12.609765\n",
      "entity : italy, type : location ; entity : greece, type : location ; entity : st. louis, type : location ; entity : india, type : location ; entity : daimaru, type : location ; entity : cowichan lake, type : location ; entity : kahlo, type : head of government. [learn3] [learn4] for the relation record label : 1. [learn5] [learn6] and the entity for the relation record label are : head entity: cowichan lake, tail entity: bharatiya; head entity: cowichan lake, tail entity: bharatiya; head entity: bharatiya, tail entity: bharatiya; head entity: bharatiya, tail entity: cowichan lake.<|endoftext|>\n",
      "81  / 96\n",
      "zero_possibility:  10.422751\n",
      "one_possibility:  12.553684\n",
      "entity : italy, type : location ; entity : greece, type : location ; entity : st. louis, type : location ; entity : india, type : location ; entity : daimaru, type : location ; entity : cowichan lake, type : location ; entity : kahlo, type : head of government. [learn3] [learn4] for the relation religion : 1. [learn5] [learn6] and the entity for the relation religion are : head entity: abramo, tail entity: godflesh; head entity: abramo, tail entity: godflesh; head entity: abramo, tail entity: godflesh; head entity: abramo, tail entity: godflesh; head entity: abramo, tail entity: godflesh; head entity: abramo, tail entity: godflesh; head entity: abramo, tail entity: godflesh; head entity: abramo, tail entity: godflesh; head entity: abramo, tail entity: godflesh; head entity: abramo, tail entity: godflesh; head entity: abramo, tail entity: godflesh; head entity: abramo, tail entity: godflesh; head entity: abramo, tail entity: godflesh; head entity: abramo, tail entity: godflesh; head entity: abramo, tail entity: godflesh; head entity: abramo, tail entity: godflesh; head entity: abramo, tail entity: godflesh; head entity: abramo, tail entity: godflesh; head entity: abramo, tail entity: godflesh; head entity: abramo, tail entity: godflesh; head entity: abramo, tail entity: godflesh; head entity: abramo, tail entity: godflesh; head entity: abramo, tail entity: godflesh; head entity: abramo, tail entity: godflesh; head entity: abramo, tail entity: godflesh.<|endoftext|>\n",
      "82  / 96\n",
      "zero_possibility:  13.7156315\n",
      "one_possibility:  16.345402\n",
      "entity : italy, type : location ; entity : greece, type : location ; entity : st. louis, type : location ; entity : india, type : location ; entity : daimaru, type : location ; entity : cowichan lake, type : location ; entity : kahlo, type : head of government. [learn3] [learn4] for the relation replaced by : 1. [learn5] [learn6] and the entity for the relation replaced by are : head entity: abraham lincoln, tail entity: cowichan lake; head entity: abraham lincoln, tail entity: cowichan lake.<|endoftext|>\n",
      "83  / 96\n",
      "zero_possibility:  17.087524\n",
      "one_possibility:  18.128134\n",
      "entity : italy, type : location ; entity : greece, type : location ; entity : st. louis, type : location ; entity : india, type : location ; entity : daimaru, type : location ; entity : cowichan lake, type : location ; entity : kahlo, type : head of government. [learn3] [learn4] for the relation replaces : 1. [learn5] [learn6] and the entity for the relation replaces are : head entity: italy, tail entity: cowichan lake; head entity: italy, tail entity: cowichan lake.<|endoftext|>\n",
      "84  / 96\n",
      "zero_possibility:  6.201118\n",
      "one_possibility:  8.210333\n",
      "entity : italy, type : location ; entity : greece, type : location ; entity : st. louis, type : location ; entity : india, type : location ; entity : daimaru, type : location ; entity : cowichan lake, type : location ; entity : kahlo, type : head of government. [learn3] [learn4] for the relation residence : 1. [learn5] [learn6] and the entity for the relation residence are : head entity: kahlo, tail entity: godavatar.<|endoftext|>\n",
      "85  / 96\n",
      "zero_possibility:  13.488253\n",
      "one_possibility:  18.926811\n",
      "entity : italy, type : location ; entity : greece, type : location ; entity : st. louis, type : location ; entity : india, type : location ; entity : daimaru, type : location ; entity : cowichan lake, type : location ; entity : kahlo, type : head of government. [learn3] [learn4] for the relation screenwriter : 1. [learn5] [learn6] and the entity for the relation screenwriter are : head entity: cowichan lake, tail entity: kahlo.<|endoftext|>\n",
      "86  / 96\n",
      "zero_possibility:  14.982738\n",
      "one_possibility:  18.209068\n",
      "entity : italy, type : location ; entity : greece, type : location ; entity : st. louis, type : location ; entity : india, type : location ; entity : daimaru, type : location ; entity : cowichan lake, type : location ; entity : kahlo, type : head of government. [learn3] [learn4] for the relation separated from : 1. [learn5] [learn6] and the entity for the relation separated from are : head entity: bahlo, tail entity: cowichan lake; head entity: bahlo, tail entity: cowichan lake.<|endoftext|>\n",
      "87  / 96\n",
      "zero_possibility:  16.23392\n",
      "one_possibility:  21.87309\n",
      "entity : italy, type : location ; entity : greece, type : location ; entity : st. louis, type : location ; entity : india, type : location ; entity : daimaru, type : location ; entity : cowichan lake, type : location ; entity : kahlo, type : head of government. [learn3] [learn4] for the relation series : 1. [learn5] [learn6] and the entity for the relation series are : head entity: cowichan lake, tail entity: italy; head entity: cowichan lake, tail entity: italy; head entity: cowichan lake, tail entity: italy; head entity: cowichan lake, tail entity: italy.<|endoftext|>\n",
      "88  / 96\n",
      "zero_possibility:  2.3919187\n",
      "one_possibility:  8.707856\n",
      "entity : italy, type : location ; entity : greece, type : location ; entity : st. louis, type : location ; entity : india, type : location ; entity : daimaru, type : location ; entity : cowichan lake, type : location ; entity : kahlo, type : head of government. [learn3] [learn4] for the relation sibling : 1. [learn5] [learn6] and the entity for the relation sibling are : head entity: cowichan lake, tail entity: daimaru; head entity: cowichan lake, tail entity: daimaru.<|endoftext|>\n",
      "89  / 96\n",
      "zero_possibility:  4.488885\n",
      "one_possibility:  3.9200313\n",
      "entity : italy, type : location ; entity : greece, type : location ; entity : st. louis, type : location ; entity : india, type : location ; entity : daimaru, type : location ; entity : cowichan lake, type : location ; entity : kahlo, type : head of government. [learn3] [learn4] for the relation sister city : 0. <|endoftext|>\n",
      "90  / 96\n",
      "zero_possibility:  2.0832584\n",
      "one_possibility:  6.003507\n",
      "entity : italy, type : location ; entity : greece, type : location ; entity : st. louis, type : location ; entity : india, type : location ; entity : daimaru, type : location ; entity : cowichan lake, type : location ; entity : kahlo, type : head of government. [learn3] [learn4] for the relation spouse : 1. [learn5] [learn6] and the entity for the relation spouse are : head entity: cowichan lake, tail entity: diego rivera; head entity: cowichan lake, tail entity: diego rivera; head entity: cowichan lake, tail entity: diego rivera; head entity: cowichan lake, tail entity: diego rivera; head entity: cowichan lake, tail entity: diego rivera; head entity: british columbia, tail entity: diego rivera; head entity: british columbia, tail entity: diego rivera; head entity: british columbia, tail entity: diego rivera; head entity: british columbia, tail entity: diego rivera; head entity: british columbia, tail entity: diego rivera; head entity: british columbia, tail entity: diego rivera; head entity: british columbia, tail entity: diego rivera; head entity: british columbia, tail entity: diego rivera; head entity: british columbia, tail entity: diego rivera; head entity: british columbia, tail entity: diego rivera; head entity: british columbia, tail entity: diego rivera; head entity: british columbia, tail entity: diego rivera; head entity: british columbia, tail entity: diego rivera; head entity: british columbia, tail entity: diego rivera; head entity: british columbia, tail entity: diego rivera; head entity: british columbia, tail entity: diego rivera; head entity: british columbia, tail entity: diego rivera; head entity: british columbia.<|endoftext|>\n",
      "91  / 96\n",
      "zero_possibility:  16.357193\n",
      "one_possibility:  17.824825\n",
      "entity : italy, type : location ; entity : greece, type : location ; entity : st. louis, type : location ; entity : india, type : location ; entity : daimaru, type : location ; entity : cowichan lake, type : location ; entity : kahlo, type : head of government. [learn3] [learn4] for the relation start time : 1. [learn5] [learn6] and the entity for the relation start time are : head entity: cowichan lake, tail entity: 0.<|endoftext|>\n",
      "92  / 96\n",
      "zero_possibility:  11.682563\n",
      "one_possibility:  13.736777\n",
      "entity : italy, type : location ; entity : greece, type : location ; entity : st. louis, type : location ; entity : india, type : location ; entity : daimaru, type : location ; entity : cowichan lake, type : location ; entity : kahlo, type : head of government. [learn3] [learn4] for the relation subclass of : 1. [learn5] [learn6] and the entity for the relation subclass of are : head entity: italy, tail entity: cowichan lake; head entity: italy, tail entity: cowichan lake.<|endoftext|>\n",
      "93  / 96\n",
      "zero_possibility:  7.954374\n",
      "one_possibility:  9.901575\n",
      "entity : italy, type : location ; entity : greece, type : location ; entity : st. louis, type : location ; entity : india, type : location ; entity : daimaru, type : location ; entity : cowichan lake, type : location ; entity : kahlo, type : head of government. [learn3] [learn4] for the relation subsidiary : 1. [learn5] [learn6] and the entity for the relation subsidiary are : head entity: cowichan lake, tail entity: bharatiya; head entity: cowichan lake, tail entity: bharatiya; head entity: cowichan lake, tail entity: bharatiya; head entity: cowichan lake, tail entity: bharatiya; head entity: cowichan lake, tail entity: bharatiya; head entity: cowichan lake, tail entity: bharatiya; head entity: cowichan lake, tail entity: bharatiya.<|endoftext|>\n",
      "94  / 96\n",
      "zero_possibility:  17.663486\n",
      "one_possibility:  19.89142\n",
      "entity : italy, type : location ; entity : greece, type : location ; entity : st. louis, type : location ; entity : india, type : location ; entity : daimaru, type : location ; entity : cowichan lake, type : location ; entity : kahlo, type : head of government. [learn3] [learn4] for the relation territory claimed by : 1. [learn5] [learn6] and the entity for the relation territory claimed by are : head entity: llia, tail entity: india; head entity: cowichan lake, tail entity: india; head entity: cowichan lake, tail entity: india; head entity: cowichan lake, tail entity: india; head entity: cowichan lake, tail entity: india; head entity: cowichan lake, tail entity: india; head entity: cowichan lake, tail entity: india; head entity: cowichan lake, tail entity: india; head entity: cowichan lake, tail entity: india; head entity: cowichan lake, tail entity: india; head entity: cowichan lake, tail entity: india.<|endoftext|>\n",
      "95  / 96\n",
      "zero_possibility:  8.235493\n",
      "one_possibility:  10.715104\n",
      "entity : italy, type : location ; entity : greece, type : location ; entity : st. louis, type : location ; entity : india, type : location ; entity : daimaru, type : location ; entity : cowichan lake, type : location ; entity : kahlo, type : head of government. [learn3] [learn4] for the relation unemployment rate : 1. [learn5] [learn6] and the entity for the relation unemployment rate are : head entity: bens, tail entity: 0.<|endoftext|>\n",
      "96  / 96\n",
      "zero_possibility:  18.20173\n",
      "one_possibility:  24.880768\n",
      "entity : italy, type : location ; entity : greece, type : location ; entity : st. louis, type : location ; entity : india, type : location ; entity : daimaru, type : location ; entity : cowichan lake, type : location ; entity : kahlo, type : head of government. [learn3] [learn4] for the relation work location : 1. [learn5] [learn6] and the entity for the relation work location are : head entity: bahlo, tail entity: godavatar.<|endoftext|>\n"
     ]
    }
   ],
   "source": [
    "from tqdm.notebook import trange, tqdm\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "model.eval()\n",
    "outputs = []\n",
    "model.to(\"cuda\")\n",
    "output_texts = []\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "with torch.no_grad():\n",
    "    # feed the actually_input to the model by 10 examples each time\n",
    "    for input_index, input_ids_list in enumerate(input_ids_lists):\n",
    "        print(input_index + 1, \" / 96\")\n",
    "        start = all_actually_inputs['learn2_index'][input_index] + 1\n",
    "        input_ids = torch.tensor(input_ids_list[:start]).to(\"cuda\")\n",
    "        relation_classfication = False\n",
    "        relation_extraction = False\n",
    "\n",
    "        while((input_ids[-1].item() != tokenizer.eos_token_id) and (len(input_ids) < 1024)):\n",
    "            output = model(input_ids=input_ids)\n",
    "            current_output = np.array(output['logits'].cpu())\n",
    "            max_index = np.argmax(current_output[-1, :], axis=0)\n",
    "\n",
    "            if max_index == tokenizer.convert_tokens_to_ids(\"[learn4]\") and (not relation_classfication):\n",
    "                input_ids = torch.cat((input_ids, torch.tensor(max_index).unsqueeze(0).to(\"cuda\")), dim=0)\n",
    "                input_ids = for_the_relation(input_index, input_ids.to(\"cpu\"))\n",
    "                input_ids = input_ids.to(\"cuda\")\n",
    "                relation_classfication = True\n",
    "                continue\n",
    "\n",
    "            if relation_classfication and (not relation_extraction):\n",
    "\n",
    "                # find the possibilities for token id tokenizer.conver_token_to_id(\"0\") and tokenizer.conver_token_to_id(\"1\") in the current_output\n",
    "\n",
    "                zero_index = tokenizer.convert_tokens_to_ids(\"0\")\n",
    "                one_index = tokenizer.convert_tokens_to_ids(\"1\")\n",
    "                zero_possibility = current_output[-1, zero_index]\n",
    "                print(\"zero_possibility: \", zero_possibility)\n",
    "                one_possibility = current_output[-1, one_index]\n",
    "                print(\"one_possibility: \", one_possibility)\n",
    "\n",
    "\n",
    "                if zero_possibility > one_possibility:\n",
    "                    relation_extraction = True\n",
    "                    next_input = \"0 . <|endoftext|>\"\n",
    "                    input_ids = torch.cat((input_ids, torch.tensor(tokenizer.encode(next_input, add_special_tokens=False, return_tensors=\"pt\")[0]).to(\"cuda\")), dim=0)\n",
    "                    continue\n",
    "                else:\n",
    "                    relation_extraction = True\n",
    "                    next_input = \"1 . [learn5] [learn6]\"\n",
    "                    input_ids = torch.cat((input_ids, torch.tensor(tokenizer.encode(next_input, add_special_tokens=False, return_tensors=\"pt\")[0]).to(\"cuda\")), dim=0)\n",
    "                    relation_extraction = True\n",
    "                    # print(tokenizer.decode(input_ids[start:]))\n",
    "                    continue\n",
    "\n",
    "            # if relation_extraction:\n",
    "            #     print(tokenizer.decode(input_ids[start:]))\n",
    "                \n",
    "            input_ids = torch.cat((input_ids, torch.tensor(max_index).unsqueeze(0).to(\"cuda\")), dim=0)\n",
    "\n",
    "        # break\n",
    "        print(tokenizer.decode(input_ids[start:]))\n",
    "        output_texts.append(tokenizer.decode(input_ids[start:]))\n",
    "        \n",
    "    # print(tokenizer.batch_decode(max_index, skip_special_tokens=False)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "from datasets import Dataset\n",
    "\n",
    "ner = 1\n",
    "\n",
    "test_relation_dict = {}\n",
    "if ner:\n",
    "    with open('DocRED/data/bi-sent-pre-process_test.json') as f:\n",
    "        test_relation_dict = json.load(f)\n",
    "\n",
    "    test_dataset = Dataset.from_dict(\n",
    "        {\n",
    "            'text': test_relation_dict['text'],\n",
    "            'entity': test_relation_dict['entity'],\n",
    "            'relation': test_relation_dict['relation']\n",
    "        }\n",
    "    )\n",
    "\n",
    "else:\n",
    "    pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the output_texts to a json file\n",
    "\n",
    "with open(f'DocRED/GPT_w_ner_short_relation/test_output_texts_for_test_dataset_{random_test_index}.json', 'w') as f:\n",
    "    json.dump(output_texts, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {},
   "outputs": [],
   "source": [
    "rel_info = {}\n",
    "with open('DocRED/data/relation-index.json') as f:\n",
    "    rel_info = json.load(f)\n",
    "rel_info_list = [relation for relation in rel_info.keys()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'text': 'durgada is a rural village in gollaprolu mandal , east godavari district , andhra pradesh , india . the village was formerly known as durga ooda , durga vaahini .',\n",
       " 'entity': [['durgada', 'location'],\n",
       "  ['gollaprolu', 'location'],\n",
       "  ['east godavari', 'location'],\n",
       "  ['andhra pradesh', 'location'],\n",
       "  ['india', 'location'],\n",
       "  ['durga ooda', 'location'],\n",
       "  ['durga vaahini', 'location']],\n",
       " 'relation': {'applies to jurisdiction': None,\n",
       "  'author': None,\n",
       "  'award received': None,\n",
       "  'basin country': None,\n",
       "  'capital': None,\n",
       "  'capital of': None,\n",
       "  'cast member': None,\n",
       "  'chairperson': None,\n",
       "  'characters': None,\n",
       "  'child': None,\n",
       "  'composer': None,\n",
       "  'conflict': None,\n",
       "  'contains administrative territorial entity': [['india', 'andhra pradesh']],\n",
       "  'continent': None,\n",
       "  'country': [['east godavari', 'india'],\n",
       "   ['durga ooda', 'india'],\n",
       "   ['durga vaahini', 'india'],\n",
       "   ['andhra pradesh', 'india'],\n",
       "   ['gollaprolu', 'india'],\n",
       "   ['durgada', 'india']],\n",
       "  'country of citizenship': None,\n",
       "  'country of origin': None,\n",
       "  'creator': None,\n",
       "  'date of birth': None,\n",
       "  'date of death': None,\n",
       "  'developer': None,\n",
       "  'director': None,\n",
       "  'dissolved, abolished or demolished': None,\n",
       "  'educated at': None,\n",
       "  'employer': None,\n",
       "  'end time': None,\n",
       "  'ethnic group': None,\n",
       "  'father': None,\n",
       "  'followed by': None,\n",
       "  'follows': None,\n",
       "  'founded by': None,\n",
       "  'genre': None,\n",
       "  'has part': None,\n",
       "  'head of government': None,\n",
       "  'head of state': None,\n",
       "  'headquarters location': None,\n",
       "  'inception': None,\n",
       "  'influenced by': None,\n",
       "  'instance of': None,\n",
       "  'languages spoken, written or signed': None,\n",
       "  'league': None,\n",
       "  'legislative body': None,\n",
       "  'located in or next to body of water': None,\n",
       "  'located in the administrative territorial entity': [['east godavari',\n",
       "    'andhra pradesh'],\n",
       "   ['andhra pradesh', 'india'],\n",
       "   ['gollaprolu', 'east godavari'],\n",
       "   ['gollaprolu', 'andhra pradesh'],\n",
       "   ['durgada', 'gollaprolu']],\n",
       "  'located on terrain feature': None,\n",
       "  'location': None,\n",
       "  'location of formation': None,\n",
       "  'lyrics by': None,\n",
       "  'manufacturer': None,\n",
       "  'member of': None,\n",
       "  'member of political party': None,\n",
       "  'member of sports team': None,\n",
       "  'military branch': None,\n",
       "  'mother': None,\n",
       "  'mouth of the watercourse': None,\n",
       "  'narrative location': None,\n",
       "  'notable work': None,\n",
       "  'official language': None,\n",
       "  'operator': None,\n",
       "  'original language of work': None,\n",
       "  'original network': None,\n",
       "  'owned by': None,\n",
       "  'parent organization': None,\n",
       "  'parent taxon': None,\n",
       "  'part of': None,\n",
       "  'participant': None,\n",
       "  'participant of': None,\n",
       "  'performer': None,\n",
       "  'place of birth': None,\n",
       "  'place of death': None,\n",
       "  'platform': None,\n",
       "  'point in time': None,\n",
       "  'position held': None,\n",
       "  'present in work': None,\n",
       "  'producer': None,\n",
       "  'product or material produced': None,\n",
       "  'production company': None,\n",
       "  'publication date': None,\n",
       "  'publisher': None,\n",
       "  'record label': None,\n",
       "  'religion': None,\n",
       "  'replaced by': None,\n",
       "  'replaces': None,\n",
       "  'residence': None,\n",
       "  'screenwriter': None,\n",
       "  'separated from': None,\n",
       "  'series': None,\n",
       "  'sibling': None,\n",
       "  'sister city': None,\n",
       "  'spouse': None,\n",
       "  'start time': None,\n",
       "  'subclass of': None,\n",
       "  'subsidiary': None,\n",
       "  'territory claimed by': None,\n",
       "  'unemployment rate': None,\n",
       "  'work location': None}}"
      ]
     },
     "execution_count": 291,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_dataset[random_test_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'entity : italy, type : location ; entity : greece, type : location ; entity : st. louis, type : location ; entity : india, type : location ; entity : daimaru, type : location ; entity : cowichan lake, type : location ; entity : kahlo, type : head of government. [learn3] [learn4] for the relation applies to jurisdiction : 1. [learn5] [learn6] and the entity for the relation applies to jurisdiction are : head entity: italy, tail entity: india; head entity: italy, tail entity: india; head entity: italy, tail entity: india; head entity: italy, tail entity: india; head entity: italy, tail entity: india; head entity: italy, tail entity: india; head entity: italy, tail entity: india; head entity: italy, tail entity: india; head entity: italy, tail entity: india; head entity: italy, tail entity: india; head entity: italy, tail entity: india.<|endoftext|>'"
      ]
     },
     "execution_count": 292,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_texts[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "relation :  contains administrative territorial entity\n",
      "[['india', 'andhra pradesh']]\n",
      "head entity:  india\n",
      "tail entity:  kahlo\n",
      "relation :  country\n",
      "[['east godavari', 'india'], ['durga ooda', 'india'], ['durga vaahini', 'india'], ['andhra pradesh', 'india'], ['gollaprolu', 'india'], ['durgada', 'india']]\n",
      "head entity:  bharatiya\n",
      "tail entity:  india\n",
      "relation :  located in the administrative territorial entity\n",
      "[['east godavari', 'andhra pradesh'], ['andhra pradesh', 'india'], ['gollaprolu', 'east godavari'], ['gollaprolu', 'andhra pradesh'], ['durgada', 'gollaprolu']]\n",
      "head entity:  greece\n",
      "tail entity:  india\n"
     ]
    }
   ],
   "source": [
    "right_relation_1 = []\n",
    "right_relation_0 = []\n",
    "wrong_relation_1 = []\n",
    "wrong_relation_0 = []\n",
    "entity_pairs = []\n",
    "\n",
    "# text = output_texts[0]\n",
    "\n",
    "# rel_index = 0\n",
    "\n",
    "for rel_index in range(len(rel_info_list)):\n",
    "    text = output_texts[rel_index]\n",
    "    relation_text = \"for the relation \" + rel_info_list[rel_index].lower() + \" : \"\n",
    "    relation_classfication = text.split(relation_text)[1].split(\".\")[0].strip()\n",
    "\n",
    "    if \"1\" in relation_classfication:\n",
    "        if test_dataset[random_test_index]['relation'][rel_info_list[rel_index]]:\n",
    "            print(\"relation : \", rel_info_list[rel_index])\n",
    "            print(\"gold truth: \", test_dataset[random_test_index]['relation'][rel_info_list[rel_index]])\n",
    "            right_relation_1.append(rel_index)\n",
    "\n",
    "            entity_pair_for_this_relation = []\n",
    "            remain_text = text\n",
    "            while(\"tail entity\" in remain_text):\n",
    "                if \";\" in remain_text.split(\"tail entity\")[1]:\n",
    "                    head_entity = remain_text.split(\"head entity: \")[1].split(\", tail entity: \")[0].strip()\n",
    "                    tail_entity = remain_text.split(\"tail entity: \")[1].split(\";\")[0].strip()\n",
    "                    if [head_entity, tail_entity] not in entity_pair_for_this_relation:\n",
    "                        entity_pair_for_this_relation.append([head_entity, tail_entity])\n",
    "                        print(\"head entity: \", head_entity)\n",
    "                        print(\"tail entity: \", tail_entity)\n",
    "                    remain_text = remain_text.split(\";\")[1].strip()\n",
    "                else:\n",
    "                    head_entity = remain_text.split(\"head entity: \")[1].split(\", tail entity: \")[0].strip()\n",
    "                    tail_entity = remain_text.split(\"tail entity: \")[1].split(\".<|endoftext|>\")[0].strip()\n",
    "                    if [head_entity, tail_entity] not in entity_pair_for_this_relation:\n",
    "                        entity_pair_for_this_relation.append([head_entity, tail_entity])\n",
    "                        print(\"head entity: \", head_entity)\n",
    "                        print(\"tail entity: \", tail_entity)\n",
    "                    break\n",
    "            entity_pairs.append(entity_pair_for_this_relation)\n",
    "\n",
    "        else:\n",
    "            wrong_relation_1.append(rel_index)\n",
    "    else:\n",
    "        if test_dataset[random_test_index]['relation'][rel_info_list[rel_index]]:\n",
    "            wrong_relation_0.append(rel_index)\n",
    "        else:\n",
    "            right_relation_0.append(rel_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "right_relation_1:  3\n",
      "right_relation_0:  4\n",
      "wrong_relation_1:  89\n",
      "wrong_relation_0:  0\n"
     ]
    }
   ],
   "source": [
    "print(\"right_relation_1: \", len(right_relation_1))\n",
    "print(\"right_relation_0: \", len(right_relation_0))\n",
    "print(\"wrong_relation_1: \", len(wrong_relation_1))\n",
    "print(\"wrong_relation_0: \", len(wrong_relation_0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[['india', 'kahlo']], [['bharatiya', 'india']], [['greece', 'india']]]"
      ]
     },
     "execution_count": 307,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "entity_pairs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "play ground"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50263"
      ]
     },
     "execution_count": 315,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.convert_tokens_to_ids(\"[learn5]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'durgada is a rural village in gollaprolu mandal, east godavari district, andhra pradesh, india. the village was formerly known as durga ooda, durga vaahini. [learn1] [learn2] entity : durgada, type : location ; entity : gollaprolu, type : location ; entity : east godavari, type : location ; entity : andhra pradesh, type : location ; entity : india, type : location ; entity : durga ooda, type : location ; entity : durga vaahini, type : location. [learn3] [learn4] for the relation contains administrative territorial entity :'"
      ]
     },
     "execution_count": 316,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# find the index of 50262 in input_ids_lists[12]\n",
    "\n",
    "tokenizer.decode(input_ids_lists[12][:input_ids_lists[12].index(50263) - 2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 440,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_ids = torch.tensor(input_ids_lists[12][:input_ids_lists[12].index(50263) - 2]).to(\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 434,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "atar\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    output = model(input_ids=input_ids)\n",
    "    current_output = np.array(output['logits'].cpu())\n",
    "    max_index = np.argmax(current_output[-1, :], axis=0)\n",
    "    sorted_index = np.argsort(current_output[-1, :])[::-1]\n",
    "    print(tokenizer.decode(max_index))\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 439,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ito'"
      ]
     },
     "execution_count": 439,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(sorted_index[5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 433,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "durgada is a rural village in gollaprolu mandal, east godavari district, andhra pradesh, india. the village was formerly known as durga ooda, durga vaahini. [learn1] [learn2] entity : durgada, type : location ; entity : gollaprolu, type : location ; entity : east godavari, type : location ; entity : andhra pradesh, type : location ; entity : india, type : location ; entity : durga ooda, type : location ; entity : durga vaahini, type : location. [learn3] [learn4] for the relation contains administrative territorial entity : 1. [learn5] [learn6] and the entity for the relation contains administrative administrative territorial entity are : head entity: india, tail entity: godav\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    input_ids = torch.cat((input_ids, torch.tensor(sorted_index [0]).unsqueeze(0).to(\"cuda\")), dim=0)\n",
    "    print(tokenizer.decode(input_ids))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "BioRED",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
